{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32cd155d",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"../../images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span>\n",
    "\n",
    "<span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 01: Feature Backfill</span>\n",
    "\n",
    "**Note**: This tutorial does not support Google Colab.\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into the following sections:\n",
    "\n",
    "1. Fetch historical data.\n",
    "2. Connect to the Hopsworks feature store.\n",
    "3. Create feature groups and insert them to the feature store.\n",
    "\n",
    "![tutorial-flow](../../images/01_featuregroups.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce71c0b2",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f92001bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "ray 2.0.0 requires protobuf<4.0.0,>=3.15.3, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U hopsworks --quiet\n",
    "!pip install geopy folium streamlit-folium --q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e974d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import folium\n",
    "\n",
    "from features import air_quality\n",
    "from functions.common_functions import convert_date_to_unix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d519dd",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç Representing the Target cities </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0f7a26b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open the 'target_cities.json' file in read mode\n",
    "with open('target_cities.json') as json_file:\n",
    "    # Load the JSON data from the file into a Python dictionary\n",
    "    target_cities = json.load(json_file)\n",
    "\n",
    "# Now, 'target_cities' contains the data from the JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8063796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folium map centered on the first location in the list\n",
    "my_map = folium.Map(location=[42.57, -44.092], zoom_start=3)\n",
    "\n",
    "for continent in target_cities:\n",
    "        for city_name, coords in target_cities[continent].items():\n",
    "            folium.CircleMarker(\n",
    "                location=coords,\n",
    "                popup=city_name,\n",
    "            ).add_to(my_map)\n",
    "#my_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcde29f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the map to an HTML file\n",
    "# my_map.save(\"map_all_target_cities.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2d3674",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå´ Processing Air Quality data</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b081d3f2",
   "metadata": {},
   "source": [
    "### [üá™üá∫ EEA](https://discomap.eea.europa.eu/map/fme/AirQualityExport.htm)\n",
    "#### EEA means European Environmental Agency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "986686f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Amsterdam': [52.37, 4.89],\n",
       " 'Athina': [37.98, 23.73],\n",
       " 'Berlin': [52.52, 13.39],\n",
       " 'Gdansk': [54.37, 18.61],\n",
       " 'Krak√≥w': [50.06, 19.94],\n",
       " 'London': [51.51, -0.13],\n",
       " 'Madrid': [40.42, -3.7],\n",
       " 'Marseille': [43.3, 5.37],\n",
       " 'Milano': [45.46, 9.19],\n",
       " 'M√ºnchen': [48.14, 11.58],\n",
       " 'Napoli': [40.84, 14.25],\n",
       " 'Paris': [48.85, 2.35],\n",
       " 'Sevilla': [37.39, -6.0],\n",
       " 'Stockholm': [59.33, 18.07],\n",
       " 'Tallinn': [59.44, 24.75],\n",
       " 'Varna': [43.21, 27.92],\n",
       " 'Wien': [48.21, 16.37]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EU Cities \n",
    "target_cities[\"EU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be358330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õ≥Ô∏è Size of this dataframe: (63548, 3)\n",
      "‚õ≥Ô∏è Missing Values: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>date</th>\n",
       "      <th>pm2_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11887</th>\n",
       "      <td>Gdansk</td>\n",
       "      <td>2014-09-21</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17498</th>\n",
       "      <td>Krak√≥w</td>\n",
       "      <td>2019-10-23</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42593</th>\n",
       "      <td>Paris</td>\n",
       "      <td>2016-08-04</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      city_name        date  pm2_5\n",
       "11887    Gdansk  2014-09-21   23.0\n",
       "17498    Krak√≥w  2019-10-23   56.0\n",
       "42593     Paris  2016-08-04    7.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file from the specified URL into a pandas DataFrame\n",
    "df_eu = pd.read_csv(\"https://repo.hops.works/dev/davit/air_quality/backfill_pm2_5_eu.csv\")\n",
    "\n",
    "# Print the size of the 'df_eu' DataFrame (number of rows and columns)\n",
    "print(\"‚õ≥Ô∏è Size of this dataframe:\", df_eu.shape)\n",
    "\n",
    "# Check for missing values in the 'df_eu' DataFrame\n",
    "print(f'‚õ≥Ô∏è Missing Values: {df_eu.isna().sum().sum()}')\n",
    "\n",
    "# Display a random sample of three rows from the 'df_eu' DataFrame\n",
    "df_eu.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02141bd",
   "metadata": {},
   "source": [
    "### [üá∫üá∏ USEPA](https://aqs.epa.gov/aqsweb/documents/data_api.html#daily)\n",
    "#### USEPA means United States Environmental Protection Agency\n",
    "[Manual downloading](https://www.epa.gov/outdoor-air-quality-data/download-daily-data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87c439b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Albuquerque': [35.08, -106.65],\n",
       " 'Atlanta': [33.75, -84.39],\n",
       " 'Chicago': [41.88, -87.62],\n",
       " 'Columbus': [39.96, -83.0],\n",
       " 'Dallas': [32.78, -96.8],\n",
       " 'Denver': [39.74, -104.98],\n",
       " 'Houston': [29.76, -95.37],\n",
       " 'Los Angeles': [34.05, -118.24],\n",
       " 'New York': [40.71, -74.01],\n",
       " 'Phoenix-Mesa': [33.66, -112.04],\n",
       " 'Salt Lake City': [40.76, -111.89],\n",
       " 'San Francisco': [37.78, -122.42],\n",
       " 'Tampa': [27.95, -82.46]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# US Cities \n",
    "target_cities[\"US\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3429aebd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õ≥Ô∏è Size of this dataframe: (46037, 3)\n",
      "‚õ≥Ô∏è Missing Values: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>city_name</th>\n",
       "      <th>pm2_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21476</th>\n",
       "      <td>2015-01-14</td>\n",
       "      <td>Houston</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26321</th>\n",
       "      <td>2018-11-28</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43002</th>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date    city_name  pm2_5\n",
       "21476  2015-01-14      Houston   11.3\n",
       "26321  2018-11-28  Los Angeles    7.8\n",
       "43002  2014-09-01        Tampa   11.8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file from the specified URL into a pandas DataFrame\n",
    "df_us = pd.read_csv(\"https://repo.hops.works/dev/davit/air_quality/backfill_pm2_5_us.csv\")\n",
    "\n",
    "# Print the size of the 'df_us' DataFrame (number of rows and columns)\n",
    "print(\"‚õ≥Ô∏è Size of this dataframe:\", df_us.shape)\n",
    "\n",
    "# Check for missing values in the 'df_us' DataFrame\n",
    "print(f'‚õ≥Ô∏è Missing Values: {df_us.isna().sum().sum()}')\n",
    "\n",
    "# Display a random sample of three rows from the 'df_us' DataFrame\n",
    "df_us.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee7b660",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">üè¢ Processing special city - `Seattle`</span>\n",
    "#### We need different stations across the Seattle. \n",
    "I downloaded daily `PM2.5` data manually [here](https://www.epa.gov/outdoor-air-quality-data/download-daily-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f401130e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bellevue-SE 12th St': [47.60086, -122.1484],\n",
       " 'DARRINGTON - FIR ST (Darrington High School)': [48.2469, -121.6031],\n",
       " 'KENT - JAMES & CENTRAL': [47.38611, -122.23028],\n",
       " 'LAKE FOREST PARK TOWNE CENTER': [47.755, -122.2806],\n",
       " 'MARYSVILLE - 7TH AVE (Marysville Junior High)': [48.05432, -122.17153],\n",
       " 'NORTH BEND - NORTH BEND WAY': [47.49022, -121.77278],\n",
       " 'SEATTLE - BEACON HILL': [47.56824, -122.30863],\n",
       " 'SEATTLE - DUWAMISH': [47.55975, -122.33827],\n",
       " 'SEATTLE - SOUTH PARK #2': [47.53091, -122.3208],\n",
       " 'Seattle-10th & Weller': [47.59722, -122.31972],\n",
       " 'TACOMA - ALEXANDER AVE': [47.2656, -122.3858],\n",
       " 'TACOMA - L STREET': [47.1864, -122.4517],\n",
       " 'Tacoma-S 36th St': [47.22634, -122.46256],\n",
       " 'Tukwila Allentown': [47.49854, -122.27839],\n",
       " 'Tulalip-Totem Beach Rd': [48.06534, -122.28519]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_cities[\"Seattle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ac26217",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õ≥Ô∏è Size of this dataframe: (46479, 3)\n",
      "‚õ≥Ô∏è Missing Values: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>date</th>\n",
       "      <th>pm2_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8709</th>\n",
       "      <td>SEATTLE - BEACON HILL</td>\n",
       "      <td>2015-11-05</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6634</th>\n",
       "      <td>DARRINGTON - FIR ST (Darrington High School)</td>\n",
       "      <td>2014-06-24</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45134</th>\n",
       "      <td>NORTH BEND - NORTH BEND WAY</td>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          city_name        date  pm2_5\n",
       "8709                          SEATTLE - BEACON HILL  2015-11-05    9.5\n",
       "6634   DARRINGTON - FIR ST (Darrington High School)  2014-06-24    1.7\n",
       "45134                   NORTH BEND - NORTH BEND WAY  2023-01-12    0.3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file from the specified URL into a pandas DataFrame\n",
    "df_seattle = pd.read_csv(\"https://repo.hops.works/dev/davit/air_quality/backfill_pm2_5_seattle.csv\")\n",
    "\n",
    "# Print the size of the 'df_seattle' DataFrame (number of rows and columns)\n",
    "print(\"‚õ≥Ô∏è Size of this dataframe:\", df_seattle.shape)\n",
    "\n",
    "# Check for missing values in the 'df_seattle' DataFrame\n",
    "print(f'‚õ≥Ô∏è Missing Values: {df_seattle.isna().sum().sum()}')\n",
    "\n",
    "# Display a random sample of three rows\n",
    "df_seattle.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23a6e68",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">üåü All together</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d913087f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õ≥Ô∏è DF shape: (156064, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>date</th>\n",
       "      <th>pm2_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106487</th>\n",
       "      <td>Tampa</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12453</th>\n",
       "      <td>Gdansk</td>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101342</th>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46538</th>\n",
       "      <td>Sevilla</td>\n",
       "      <td>2017-02-12</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117821</th>\n",
       "      <td>Seattle-10th &amp; Weller</td>\n",
       "      <td>2015-12-12</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    city_name        date  pm2_5\n",
       "106487                  Tampa  2014-06-30    9.3\n",
       "12453                  Gdansk  2016-04-09    9.0\n",
       "101342         Salt Lake City  2020-04-29    5.8\n",
       "46538                 Sevilla  2017-02-12    8.0\n",
       "117821  Seattle-10th & Weller  2015-12-12    5.7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the DataFrames df_eu, df_us, and df_seattle along the rows and reset the index\n",
    "df_air_quality = pd.concat(\n",
    "    [df_eu, df_us, df_seattle],\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Print the shape of the df_air_quality DataFrame\n",
    "print(f'‚õ≥Ô∏è DF shape: {df_air_quality.shape}')\n",
    "\n",
    "# Display a random sample of five rows from the df_air_quality DataFrame\n",
    "df_air_quality.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268791c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#ff5f27;\">üõ† Feature Engineering</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aff7a97b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the 'date' column in the df_air_quality DataFrame to datetime format\n",
    "df_air_quality['date'] = pd.to_datetime(df_air_quality['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d45e480",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply feature engineering to the df_air_quality DataFrame using the air_quality.feature_engineer_aq() function\n",
    "df_air_quality = air_quality.feature_engineer_aq(df_air_quality)\n",
    "\n",
    "# Drop rows with missing values in the df_air_quality DataFrame\n",
    "df_air_quality = df_air_quality.dropna()\n",
    "\n",
    "# Check and print the total number of missing values in the df_air_quality DataFrame\n",
    "df_air_quality.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02c8e1e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154533, 31)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the shape (number of rows and columns) of the df_air_quality DataFrame\n",
    "df_air_quality.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c627429",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['city_name', 'date', 'pm2_5', 'pm_2_5_previous_1_day',\n",
       "       'pm_2_5_previous_2_day', 'pm_2_5_previous_3_day',\n",
       "       'pm_2_5_previous_4_day', 'pm_2_5_previous_5_day',\n",
       "       'pm_2_5_previous_6_day', 'pm_2_5_previous_7_day', 'mean_7_days',\n",
       "       'mean_14_days', 'mean_28_days', 'std_7_days', 'exp_mean_7_days',\n",
       "       'exp_std_7_days', 'std_14_days', 'exp_mean_14_days', 'exp_std_14_days',\n",
       "       'std_28_days', 'exp_mean_28_days', 'exp_std_28_days', 'year',\n",
       "       'day_of_month', 'month', 'day_of_week', 'is_weekend', 'sin_day_of_year',\n",
       "       'cos_day_of_year', 'sin_day_of_week', 'cos_day_of_week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve and display the column names of the df_air_quality DataFrame\n",
    "df_air_quality.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4296b629",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style='color:#ff5f27'> üå¶ Loading Weather Data from [Open Meteo](https://open-meteo.com/en/docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52e4eb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_max</th>\n",
       "      <th>temperature_min</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>rain_sum</th>\n",
       "      <th>snowfall_sum</th>\n",
       "      <th>precipitation_hours</th>\n",
       "      <th>wind_speed_max</th>\n",
       "      <th>wind_gusts_max</th>\n",
       "      <th>wind_direction_dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>10.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>62.6</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.9</td>\n",
       "      <td>39.6</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>10.3</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>39.2</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_name        date  temperature_max  temperature_min  precipitation_sum  \\\n",
       "0  Amsterdam  2013-01-01              9.2              5.5               10.2   \n",
       "1  Amsterdam  2013-01-02              7.8              5.6                0.5   \n",
       "2  Amsterdam  2013-01-03             10.3              8.2                2.0   \n",
       "\n",
       "   rain_sum  snowfall_sum  precipitation_hours  wind_speed_max  \\\n",
       "0      10.2           0.0                 14.0            32.0   \n",
       "1       0.5           0.0                  2.0            22.9   \n",
       "2       2.0           0.0                  6.0            22.2   \n",
       "\n",
       "   wind_gusts_max  wind_direction_dominant  \n",
       "0            62.6                      255  \n",
       "1            39.6                      251  \n",
       "2            39.2                      255  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file from the specified URL into a pandas DataFrame for weather data\n",
    "df_weather = pd.read_csv(\"https://repo.hops.works/dev/davit/air_quality/backfill_weather.csv\")\n",
    "\n",
    "# Display the first three rows of the df_weather DataFrame\n",
    "df_weather.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0d4d7b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec1e91c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the 'convert_date_to_unix' function to create a new 'unix_time' column in df_air_quality\n",
    "df_air_quality[\"unix_time\"] = pd.to_datetime(df_air_quality.date).apply(convert_date_to_unix)\n",
    "\n",
    "# Apply the 'convert_date_to_unix' function to create a new 'unix_time' column in df_weather\n",
    "df_weather[\"unix_time\"] = pd.to_datetime(df_weather.date).apply(convert_date_to_unix)\n",
    "\n",
    "# Convert the 'date' column in the df_air_quality DataFrame back to string format\n",
    "df_air_quality.date = df_air_quality.date.astype(str)\n",
    "\n",
    "# Convert the 'date' column in the df_weather DataFrame back to string format\n",
    "df_weather.date = df_weather.date.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472f7eb5",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üîÆ Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "410f0b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/5242\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6176991c",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">ü™Ñ Creating Feature Groups</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370bbf0b",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üå´ Air Quality Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5a58bfc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: Providing event_time as a single-element list is deprecated and will be dropped in future versions. Provide the feature_name string instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://snurran.hops.works/p/5242/fs/5190/fg/5194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6677d288bc0746a48faf802be7032e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/154533 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://snurran.hops.works/p/5242/jobs/named/air_quality_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x7f9a243e3f70>, None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get or create feature group\n",
    "air_quality_fg = fs.get_or_create_feature_group(\n",
    "    name='air_quality',\n",
    "    description='Air Quality characteristics of each day',\n",
    "    version=1,\n",
    "    primary_key=['unix_time','city_name'],\n",
    "    event_time=[\"unix_time\"],\n",
    ")   \n",
    "# Insert data\n",
    "air_quality_fg.insert(df_air_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cbe8aa",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üå¶ Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "089f45b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://snurran.hops.works/p/5242/fs/5190/fg/5195\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7328db1bd3b84e769e7b4ac88c1416a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/168975 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://snurran.hops.works/p/5242/jobs/named/weather_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x7f9a243e0190>, None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get or create feature group\n",
    "weather_fg = fs.get_or_create_feature_group(\n",
    "    name='weather',\n",
    "    description='Weather characteristics of each day',\n",
    "    version=1,\n",
    "    primary_key=['unix_time','city_name'],\n",
    "    event_time=[\"unix_time\"],\n",
    ") \n",
    "# Insert data\n",
    "weather_fg.insert(df_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f5ffec",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 02: Feature Pipeline \n",
    " </span> \n",
    "\n",
    "In the following notebook you will parse data and insert it into Feature Groups."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
