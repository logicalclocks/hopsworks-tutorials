{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21217380-867c-415d-a025-5e35a88fb8f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing spark session...\n",
      "Spark session available as `spark`.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.devnet.hops.works/p/4217\n",
      "2025-10-09 19:30:59,942 WARNING: VersionWarning: No version provided for getting feature group `user_clicks`, defaulting to `1`.\n",
      "\n",
      "✅ Created Feature Group: user_clicks v1 with explicit schema\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: bigint, event_time: bigint]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 49926)\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/envs/hopsworks_environment/lib/python3.10/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/srv/hops/anaconda/envs/hopsworks_environment/lib/python3.10/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/srv/hops/anaconda/envs/hopsworks_environment/lib/python3.10/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/srv/hops/anaconda/envs/hopsworks_environment/lib/python3.10/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/srv/hops/spark/python/pyspark/accumulators.py\", line 262, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/srv/hops/spark/python/pyspark/accumulators.py\", line 235, in poll\n",
      "    if func():\n",
      "  File \"/srv/hops/spark/python/pyspark/accumulators.py\", line 239, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/srv/hops/spark/python/pyspark/serializers.py\", line 564, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "import hopsworks\n",
    "from hsfs.feature import Feature\n",
    "\n",
    "fs = hopsworks.login().get_feature_store()\n",
    "clicks_fg = fs.get_feature_group(\"user_clicks\")\n",
    "\n",
    "print(\"✅ Created Feature Group: user_clicks v1 with explicit schema\") \n",
    "df = clicks_fg.read()\n",
    "df = df.drop(\"click_id\") # not needed in our new feature group with aggregates\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99ec42da-dc22-4bfb-b3c0-ad74174fcf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicit schema definition\n",
    "schema = [\n",
    "    Feature(name=\"user_id\", type=\"bigint\"),\n",
    "    Feature(name=\"event_time\", type=\"bigint\"),\n",
    "    Feature(name=\"click_count_1_min\", type=\"bigint\"),\n",
    "    Feature(name=\"click_count_10_min\", type=\"bigint\"),\n",
    "    Feature(name=\"click_count_30_min\", type=\"bigint\"),\n",
    "    Feature(name=\"click_count_1_hour\", type=\"bigint\"),\n",
    "]\n",
    "\n",
    "# Create or get the feature group with schema\n",
    "window_fg = fs.get_or_create_feature_group(\n",
    "    name=\"windowed_click_counts\",\n",
    "    version=1,\n",
    "    description=\"Aggregated user clickstream data (1 min, 10/30/60 min windows)\",\n",
    "    primary_key=[\"user_id\", \"event_time\"],\n",
    "    event_time=\"event_time\",\n",
    "    online_enabled=True,\n",
    "    features=schema\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e76e29c-5765-4d66-a624-58adf015b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "w1   = Window.partitionBy(\"user_id\").orderBy(F.col(\"event_time\")).rangeBetween(-60, 0)      # 1 min\n",
    "w10  = Window.partitionBy(\"user_id\").orderBy(F.col(\"event_time\")).rangeBetween(-600, 0)     # 10 min\n",
    "w30  = Window.partitionBy(\"user_id\").orderBy(F.col(\"event_time\")).rangeBetween(-1800, 0)    # 30 min\n",
    "w60  = Window.partitionBy(\"user_id\").orderBy(F.col(\"event_time\")).rangeBetween(-3600, 0)    # 1 hour\n",
    "\n",
    "# Add columns\n",
    "df = (\n",
    "    df.withColumn(\"click_count_1_min\",  F.count(\"*\").over(w1))\n",
    "      .withColumn(\"click_count_10_min\", F.count(\"*\").over(w10))\n",
    "      .withColumn(\"click_count_30_min\", F.count(\"*\").over(w30))\n",
    "      .withColumn(\"click_count_1_hour\", F.count(\"*\").over(w60))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a605e06f-4b0c-470b-a527-104c476a092d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----------------+------------------+------------------+------------------+\n",
      "|user_id|event_time|click_count_1_min|click_count_10_min|click_count_30_min|click_count_1_hour|\n",
      "+-------+----------+-----------------+------------------+------------------+------------------+\n",
      "|     26|1760036400|                1|                 1|                 1|                 1|\n",
      "|     26|1760036402|                2|                 2|                 2|                 2|\n",
      "|     26|1760036406|                3|                 3|                 3|                 3|\n",
      "|     26|1760036407|                4|                 4|                 4|                 4|\n",
      "|     26|1760036411|                5|                 5|                 5|                 5|\n",
      "|     26|1760036413|                6|                 6|                 6|                 6|\n",
      "|     26|1760036418|                7|                 7|                 7|                 7|\n",
      "|     26|1760036424|                8|                 8|                 8|                 8|\n",
      "|     26|1760036431|                9|                 9|                 9|                 9|\n",
      "|     26|1760036436|               10|                10|                10|                10|\n",
      "|     26|1760036439|               11|                11|                11|                11|\n",
      "|     26|1760036443|               12|                12|                12|                12|\n",
      "|     26|1760036450|               13|                13|                13|                13|\n",
      "|     26|1760036462|               13|                14|                14|                14|\n",
      "|     26|1760036467|               12|                15|                15|                15|\n",
      "|     26|1760036471|               12|                16|                16|                16|\n",
      "|     26|1760036473|               12|                17|                17|                17|\n",
      "|     26|1760036474|               12|                18|                18|                18|\n",
      "|     26|1760036479|               12|                19|                19|                19|\n",
      "|     26|1760036480|               13|                20|                20|                20|\n",
      "+-------+----------+-----------------+------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6291adb2-90b1-49b0-b269-d0fdd5065eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://snurran.devnet.hops.works/p/4217/fs/4165/fg/5146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_fg.insert(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c11c66-e91e-4a11-b899-68c8c02fa06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
