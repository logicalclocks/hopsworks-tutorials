{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2768c6ed",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"../../images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 01: Load, Engineer & Connect</span>\n",
    "\n",
    "<span style=\"font-width:bold; font-size: 1.4rem;\"> This is the first part of the AML tutorial. As part of this first module, you will work with data related to credit card transactions. \n",
    "The objective of this tutorial is to demonstrate how to work with the **Hopworks Feature Store** with a goal of training and deploying a model that can predict fraudulent transactions.</span>\n",
    "\n",
    "## **üóíÔ∏è This notebook is divided into the following sections:** \n",
    "1. **Data Loading**: Load the data. \n",
    "2. **Feature Engineering**.\n",
    "2. **Hopsworks Feature Store Connection**.\n",
    "3. **Feature Groups Creation**: Create feature groups and upload them to the feature store.\n",
    "4. **Explore feature groups from the UI**.\n",
    "\n",
    "![tutorial-flow](../../images/01_featuregroups.png)\n",
    "\n",
    "First of all we will load the data and do some feature engineering on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a080c46",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üìù Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from features.transactions import get_in_out_transactions\n",
    "from features.party import get_transaction_labels, get_party_labels\n",
    "from features.graph_embeddings import construct_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f1d96b",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üíΩ Loading the Data </span>\n",
    "\n",
    "The data you will use comes from three different CSV files:\n",
    "\n",
    "- `transactions.csv`: Transaction information such as timestamp, location, and the amount. \n",
    "- `alert_transactions.csv`: Suspicious Activity Report (SAR) transactions.\n",
    "- `party.csv`: User profile information.\n",
    "\n",
    "In a production system, these CSV files would originate from separate data sources or tables, and probably separate data pipelines. **All three files have a customer id column `id` in common, which we can use for joins.**\n",
    "\n",
    "Let's go ahead and load the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99116f96",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> ‚õ≥Ô∏è Transactions dataset </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a81073",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.read_csv(\n",
    "    \"https://repo.hops.works/master/hopsworks-tutorials/data/aml/transactions.csv\", \n",
    "    parse_dates = ['tran_timestamp'],\n",
    ")\n",
    "transactions_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30215a9f",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> ‚õ≥Ô∏è Alert Transactions dataset </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c7628",
   "metadata": {},
   "outputs": [],
   "source": [
    "alert_transactions = pd.read_csv(\n",
    "    \"https://repo.hops.works/master/hopsworks-tutorials/data/aml/alert_transactions.csv\",\n",
    ")\n",
    "alert_transactions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73471c8",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> ‚õ≥Ô∏è Party dataset </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47153ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "party = pd.read_csv(\n",
    "    \"https://repo.hops.works/master/hopsworks-tutorials/data/aml/party.csv\",\n",
    ")\n",
    "party.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17f91ea",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üõ†Ô∏è Feature Engineering </span>\n",
    "\n",
    "To investigate patterns of suspicious activities you will make time window aggregates such monthly frequency, total, mean and standard deviation of amount of incoming and outgoing transasactions.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b036749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns for clarity\n",
    "transactions_df.columns = ['tran_id', 'tx_type', 'base_amt', 'tran_timestamp', 'source', 'target']\n",
    "\n",
    "# Reordering columns for better readability\n",
    "transactions_df = transactions_df[[\"source\", \"target\", \"tran_timestamp\", \"tran_id\", \"base_amt\"]]\n",
    "\n",
    "# Displaying the first few rows of the DataFrame\n",
    "transactions_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3877ecea",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">‚õ≥Ô∏è Incoming and Outgoing transactions </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98608cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a DataFrame with monthly incoming and outgoing transaction statistics\n",
    "in_out_df = get_in_out_transactions(transactions_df)\n",
    "\n",
    "# Displaying the first few rows of the resulting DataFrame\n",
    "in_out_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3502fab3",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> ‚õ≥Ô∏è Transactions identified as suspicious activity </span>\n",
    "\n",
    "Assign labels to transactions that were identified as suspicius activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5dccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the first few rows of the 'alert_transactions' DataFrame\n",
    "alert_transactions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b862b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating transaction labels based on transaction and alert transaction data\n",
    "transaction_labels = get_transaction_labels(\n",
    "    transactions_df, \n",
    "    alert_transactions,\n",
    ")\n",
    "\n",
    "# Displaying the first three rows of the resulting DataFrame\n",
    "transaction_labels.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5cf91f",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> ‚õ≥Ô∏è Party dataset </span>\n",
    "\n",
    "Now lets prepare profile (party) dataset and assign lables whether they have been reported for suspicius activity or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f812069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns for clarity\n",
    "party.columns = [\"id\", \"type\"]\n",
    "\n",
    "# Mapping 'type' values to numerical values for better representation\n",
    "party.type = party.type.map({\"Individual\": 0, \"Organization\": 1})\n",
    "\n",
    "# Displaying the first three rows of the DataFrame\n",
    "party.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be307af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering transactions with SAR(Suspicious Activity Reports) labels from the generated transaction labels DataFrame\n",
    "alert_transactions = transaction_labels[transaction_labels.is_sar == 1]\n",
    "\n",
    "# Displaying the first few rows of transactions flagged as SAR\n",
    "alert_transactions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eee83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating party labels based on transaction labels and party information\n",
    "party_labels = get_party_labels(\n",
    "    transaction_labels, \n",
    "    party,\n",
    ")\n",
    "\n",
    "# Displaying the first three rows of the resulting DataFrame\n",
    "party_labels.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1534d0db",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üß¨ Graph representational learning using Graph Neural Network</span>\n",
    "\n",
    "Finanial transactions can be represented as a dynamic network graph. Using technique of graph representation \n",
    "give as opportunity to represent transaction with a broader context. In this example you will perfom node \n",
    "representation learning. \n",
    "\n",
    "Network architecture of the graph convolution layer for learning node represantion learning  was taken from \n",
    "[this Keras example](https://keras.io/examples/graph/gnn_citations/).  It performs the following steps:\n",
    "\n",
    "1. **Prepare**: The input node representations are processed using a FFN to produce a *message*. You can simplify\n",
    "the processing by only applying linear transformation to the representations.\n",
    "2. **Aggregate**: The messages of the neighbours of each node are aggregated with\n",
    "respect to the `edge_weights` using a *permutation invariant* pooling operation, such as *sum*, *mean*, and *max*,\n",
    "to prepare a single aggregated message for each node. See, for example, [tf.math.unsorted_segment_sum](https://www.tensorflow.org/api_docs/python/tf/math/unsorted_segment_sum)\n",
    "APIs used to aggregate neighbour messages.\n",
    "3. **Update**: The `node_repesentations` and `aggregated_messages`‚Äîboth of shape `[num_nodes, representation_dim]`‚Äî\n",
    "are combined and processed to produce the new state of the node representations (node embeddings).\n",
    "If `combination_type` is `gru`, the `node_repesentations` and `aggregated_messages` are stacked to create a sequence,\n",
    "then processed by a GRU layer. Otherwise, the `node_repesentations` and `aggregated_messages` are added\n",
    "or concatenated, then processed using a FFN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c001c",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">üîÆ Compute time evolving graph embeddings</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e66a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping transaction labels by month using pandas Grouper\n",
    "transaction_graphs_by_month = transaction_labels.groupby(\n",
    "    pd.Grouper(key='tran_timestamp', freq='M')\n",
    ").apply(lambda x: construct_graph(x, party_labels))\n",
    "\n",
    "# The resulting variable 'transaction_graphs_by_month' is a pandas DataFrame\n",
    "# where each row corresponds to a month, and the 'graph_embeddings' column contains\n",
    "# the node embeddings generated for each month using the 'construct_graph' function.\n",
    "# The embeddings capture the graph structure of transactions during that month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cb5e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting timestamps and graph embeddings\n",
    "timestamps = transaction_graphs_by_month.index.values\n",
    "graph_embeddings = transaction_graphs_by_month.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76882c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty DataFrame to store graph embeddings\n",
    "graph_embeddings_df = pd.DataFrame()\n",
    "\n",
    "# Iterating through timestamps and corresponding graph embeddings\n",
    "for timestamp, graph_embedding in zip(timestamps, graph_embeddings):\n",
    "    # Creating a temporary DataFrame for each month's graph embeddings\n",
    "    df_tmp = pd.DataFrame(graph_embedding)\n",
    "    \n",
    "    # Adding a 'tran_timestamp' column to store the timestamp for each row\n",
    "    df_tmp[\"tran_timestamp\"] = timestamp\n",
    "    \n",
    "    # Concatenating the temporary DataFrame to the main DataFrame\n",
    "    graph_embeddings_df = pd.concat([graph_embeddings_df, df_tmp])\n",
    "\n",
    "# Displaying the first three rows of the resulting DataFrame\n",
    "graph_embeddings_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a247a981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'tran_timestamp' values to milliseconds for consistency\n",
    "transaction_labels.tran_timestamp = transaction_labels.tran_timestamp.values.astype(np.int64) // 10 ** 6\n",
    "graph_embeddings_df.tran_timestamp = graph_embeddings_df.tran_timestamp.values.astype(np.int64) // 10 ** 6\n",
    "\n",
    "# Converting 'tran_timestamp' values in 'party_labels' to milliseconds\n",
    "party_labels.tran_timestamp = party_labels.tran_timestamp.map(lambda x: datetime.datetime.timestamp(x) * 1000)\n",
    "party_labels.tran_timestamp = party_labels.tran_timestamp.values.astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d4654e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üëÆüèª‚Äç‚ôÇÔ∏è Data Validation</span>\n",
    "\n",
    "Before you define [feature groups](https://docs.hopsworks.ai/latest/generated/feature_group/) lets define [validation rules](https://docs.hopsworks.ai/latest/generated/feature_validation/) for features. You do expect some of the features to comply with certain *rules* or *expectations*. For example: a transacted amount must be a positive value. In the case of a transacted amount arriving as a negative value you can decide whether to stop it to `write` into a feature group and throw an error or allow it to be written but provide a warning. In the next section you will create feature store `expectations`, attach them to feature groups, and apply them to dataframes being appended to said feature group.\n",
    "\n",
    "#### Data validation with Greate Expectations in Hopsworks\n",
    "You can use GE library for validation in Hopsworks features store. \n",
    "\n",
    "##  <img src=\"../../images/icon102.png\" width=\"18px\"></img> Hopsworks feature store\n",
    "\n",
    "The Hopsworks feature feature store library is Apache V2 licensed and available [here](https://github.com/logicalclocks/feature-store-api). The library is currently available for Python and JVM languages such as Scala and Java.\n",
    "In this notebook, we are going to cover Python part.\n",
    "\n",
    "You can find the complete documentation of the library here: \n",
    "\n",
    "The first step is to establish a connection with your Hopsworks feature store instance and retrieve the object that represents the feature store you'll be working with. \n",
    "\n",
    "> By default `project.get_feature_store()` returns the feature store of the project we are working with. However, it accepts also a project name as parameter to select a different feature store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76afb55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367782dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ed49fa",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üî¨ Expectations suite</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d210009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca968941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an Expectation Suite named \"aml_project_validations\"\n",
    "expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"aml_project_validations\",\n",
    ")\n",
    "\n",
    "# Displaying the JSON representation of the Expectation Suite\n",
    "pprint(expectation_suite.to_json_dict(), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe358b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding an expectation to the Expectation Suite\n",
    "expectation_suite.add_expectation(\n",
    "    ge.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_max_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\": \"monthly_in_count\", \n",
    "            \"min_value\": 0, \n",
    "            \"max_value\": 10000000,\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# Displaying the updated Expectation Suite\n",
    "pprint(expectation_suite.to_json_dict(), indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f3ea2c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> ü™Ñ Feature Groups Creation</span>\n",
    "\n",
    "### Feature Groups\n",
    "\n",
    "A `Feature Groups` is a logical grouping of features, and experience has shown, that this grouping generally originates from the features being derived from the same data source. The `Feature Group` lets you save metadata along features, which defines how the Feature Store interprets them, combines them and reproduces training datasets created from them.\n",
    "\n",
    "Generally, the features in a feature group are engineered together in an ingestion job. However, it is possible to have additional jobs to append features to an existing feature group. Furthermore, `feature groups` provide a way of defining a namespace for features, such that you can define features with the same name multiple times, but uniquely identified by the group they are contained in.\n",
    "\n",
    "> It is important to note that `feature groups` are not groupings of features for immediate training of Machine Learning models. Instead, to ensure reusability of features, it is possible to combine features from any number of groups into training datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872c2456",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">‚õ≥Ô∏è Transactions monthly aggregates Feature Group</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b797fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create the 'transactions_monthly' feature group\n",
    "transactions_fg = fs.get_or_create_feature_group(\n",
    "    name=\"transactions_monthly\",\n",
    "    version=1,\n",
    "    primary_key=[\"id\"],\n",
    "    partition_key=[\"tran_timestamp\"],   \n",
    "    description=\"transactions monthly aggregates features\",\n",
    "    event_time=['tran_timestamp'],\n",
    "    online_enabled=True,\n",
    "    stream=True,\n",
    "    statistics_config={\n",
    "        \"enabled\": True, \n",
    "        \"histograms\": True, \n",
    "        \"correlations\": True, \n",
    "        \"exact_uniqueness\": False,\n",
    "    },\n",
    "    expectation_suite=expectation_suite,\n",
    ")   \n",
    "# Insert data into the feature group\n",
    "transactions_fg.insert(in_out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef54d53",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">‚õ≥Ô∏è Party Feature Group</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2685d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create the 'party_labels' feature group\n",
    "party_fg = fs.get_or_create_feature_group(\n",
    "    name = \"party_labels\",\n",
    "    version = 1,\n",
    "    primary_key = [\"id\"],\n",
    "    description = \"party fg with labels\",\n",
    "    event_time = ['tran_timestamp'],        \n",
    "    online_enabled = True,\n",
    "    stream=True,\n",
    "    statistics_config = {\n",
    "        \"enabled\": True, \n",
    "        \"histograms\": True, \n",
    "        \"correlations\": True, \n",
    "        \"exact_uniqueness\": False,\n",
    "    },\n",
    ")\n",
    "# Insert data into the feature group\n",
    "party_fg.insert(party_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68abb141",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">‚õ≥Ô∏è Graph embeddings Feature Group</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad641ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsfs import engine\n",
    "features = engine.get_instance().parse_schema_feature_group(graph_embeddings_df)\n",
    "for f in features:\n",
    "    if f.type == \"array<float>\":\n",
    "        f.online_type = \"VARBINARY(200)\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608667aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create the 'graph_embeddings' feature group\n",
    "graph_embeddings_fg = fs.get_or_create_feature_group(\n",
    "    name=\"graph_embeddings\",\n",
    "    version=1,\n",
    "    primary_key=[\"id\"],\n",
    "    description=\"node embeddings from transactions graph\",\n",
    "    event_time = ['tran_timestamp'],      \n",
    "    online_enabled=True,       \n",
    "    stream=True,\n",
    "    statistics_config={\n",
    "        \"enabled\": False, \n",
    "        \"histograms\": False, \n",
    "        \"correlations\": False, \n",
    "        \"exact_uniqueness\": False,\n",
    "    },\n",
    "    features=features,\n",
    ")\n",
    "# Insert data into the feature group\n",
    "graph_embeddings_fg.insert(graph_embeddings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35b4de9",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\"> üëì Exploration </span>\n",
    "\n",
    "### Feature groups are now accessible and searchable in the UI\n",
    "![fg-overview](images/fg_explore.gif)\n",
    "\n",
    "## üìä Statistics\n",
    "We can explore feature statistics in the feature groups. If statistics was not enabled when feature group was created then this can be done by:\n",
    "\n",
    "```python\n",
    "transactions_fg = fs.get_or_create_feature_group(\n",
    "    name = \"transactions_monthly_fg\", \n",
    "    version = 1)\n",
    "\n",
    "transactions_fg.statistics_config = {\n",
    "    \"enabled\": True,\n",
    "    \"histograms\": True,\n",
    "    \"correlations\": True\n",
    "}\n",
    "\n",
    "transactions_fg.update_statistics_config()\n",
    "transactions_fg.compute_statistics()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d1f19c",
   "metadata": {},
   "source": [
    "![fg-stats](images/freature_group_stats.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0f9e3e",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\"> ‚è≠Ô∏è **Next:** Part 02 </span>\n",
    "    \n",
    "In the next notebook you will create a training dataset, train and deploy a trained model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
