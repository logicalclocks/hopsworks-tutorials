{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b13c37b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import secrets\n",
    "\n",
    "import hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fed7f937",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b609bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['ride_id',\n",
    "        'pickup_datetime',\n",
    "        'pickup_longitude',\n",
    "        'pickup_latitude',\n",
    "        'dropoff_longitude',\n",
    "        'dropoff_latitude',\n",
    "        'passenger_count',\n",
    "        'taxi_id',\n",
    "        'driver_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d176dd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21a9436f5b3804625068ab6b9d0923a8'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secrets.token_hex(nbytes=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "748314e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rides_data(n_records):\n",
    "    res = pd.DataFrame(columns=cols)\n",
    "    \n",
    "    for i in range(1, n_records + 1):\n",
    "        generated_values = list()\n",
    "     \n",
    "        \n",
    "        temp_df = pd.DataFrame.from_dict({\"ride_id\": [secrets.token_hex(nbytes=16)],\n",
    "                                          \"pickup_datetime\": [np.random.randint(1600000000, 1610000000)],\n",
    "                                          \"pickup_longitude\": [round(np.random.uniform(-74.5, -72.8), 5)],\n",
    "                                          \"dropoff_longitude\": [round(np.random.uniform(-74.5, -72.8), 5)],\n",
    "                                          \"pickup_latitude\": [round(np.random.uniform(40.5, 41.8), 5)],\n",
    "                                          \"dropoff_latitude\": [round(np.random.uniform(40.5, 41.8), 5)],\n",
    "                                          \"passenger_count\": [np.random.randint(1, 5)],\n",
    "                                          \"taxi_id\": [np.random.randint(1, 201)],\n",
    "                                          \"driver_id\": [np.random.randint(1, 201)]\n",
    "                                         })\n",
    "        \n",
    "        res = pd.concat([temp_df, res], ignore_index=True)\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb60710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rides = generate_rides_data(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54bed4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns distance in miles\n",
    "def distance(lat1, lon1, lat2, lon2):\n",
    "    p = 0.017453292519943295 # Pi/180\n",
    "    a = 0.5 - np.cos((lat2 - lat1) * p)/2 + np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p)) / 2\n",
    "    return 0.6213712 * 12742 * np.arcsin(np.sqrt(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96f7381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rides[\"distance\"] = distance(df_rides[\"pickup_latitude\"], df_rides[\"pickup_longitude\"],\n",
    "                            df_rides[\"dropoff_latitude\"], df_rides[\"dropoff_longitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e541dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distances to nearby airports\n",
    "jfk = (-73.7781, 40.6413)\n",
    "ewr = (-74.1745, 40.6895)\n",
    "lgr = (-73.8740, 40.7769)\n",
    "\n",
    "df_rides['pickup_distance_to_jfk'] = distance(jfk[1], jfk[0],\n",
    "                                     df_rides['pickup_latitude'], df_rides['pickup_longitude'])\n",
    "df_rides['dropoff_distance_to_jfk'] = distance(jfk[1], jfk[0],\n",
    "                                       df_rides['dropoff_latitude'], df_rides['dropoff_longitude'])\n",
    "df_rides['pickup_distance_to_ewr'] = distance(ewr[1], ewr[0], \n",
    "                                      df_rides['pickup_latitude'], df_rides['pickup_longitude'])\n",
    "df_rides['dropoff_distance_to_ewr'] = distance(ewr[1], ewr[0],\n",
    "                                       df_rides['dropoff_latitude'], df_rides['dropoff_longitude'])\n",
    "df_rides['pickup_distance_to_lgr'] = distance(lgr[1], lgr[0],\n",
    "                                      df_rides['pickup_latitude'], df_rides['pickup_longitude'])\n",
    "df_rides['dropoff_distance_to_lgr'] = distance(lgr[1], lgr[0],\n",
    "                                       df_rides['dropoff_latitude'], df_rides['dropoff_longitude'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "398e8f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rides[\"pickup_datetime\"] = (pd.to_datetime(df_rides[\"pickup_datetime\"],unit='ms'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d284149",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rides['year'] = df_rides.pickup_datetime.apply(lambda t: t.year)\n",
    "df_rides['weekday'] = df_rides.pickup_datetime.apply(lambda t: t.weekday())\n",
    "df_rides['hour'] = df_rides.pickup_datetime.apply(lambda t: t.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f42669ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rides[\"pickup_datetime\"] = df_rides[\"pickup_datetime\"].values.astype(np.int64) // 10 ** 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b075dd19",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ⚖️ Great Expectations </span> \n",
    "\n",
    "Great Expectations’ built-in library includes more than 50 common Expectations, such as:\n",
    "\n",
    "    expect_column_values_to_not_be_null\n",
    "\n",
    "    expect_column_values_to_be_unique\n",
    "\n",
    "    expect_column_median_to_be_between...\n",
    "\n",
    "#### You can find more expectations in the [official docs](https://greatexpectations.io/expectations/)\n",
    "\n",
    "\n",
    "Clean, high quality feature data is of paramount importance to being able to train and serve high quality models. Hopsworks offers integration with [Great Expectations](https://greatexpectations.io/) to enable a smooth data validation workflow.\n",
    "\n",
    "### `More info` - [here](https://docs.hopsworks.ai/3.0/user_guides/fs/feature_group/data_validation/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b36a88bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge\n",
    "\n",
    "# Create (or import an existing) expectation suite using the Great Expectations library.\n",
    "expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"validate_on_insert_suite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d253a0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"meta\": {}, \"kwargs\": {\"column\": \"pickup_latitude\", \"min_value\": 40.5, \"max_value\": 41.8}, \"expectation_type\": \"expect_column_values_to_be_between\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets add an expecation to the 'total_fare' column\n",
    "expectation_suite.add_expectation(\n",
    "    ge.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\": \"pickup_longitude\",\n",
    "            \"min_value\": -74.5, \n",
    "            \"max_value\": -72.8\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# you can add as many expectations (to the different columns in the same time) as you want\n",
    "\n",
    "expectation_suite.add_expectation(\n",
    "    ge.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\": \"pickup_latitude\",\n",
    "            \"min_value\": 40.5,\n",
    "            \"max_value\": 41.8\n",
    "        }\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff8c589d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9295f4d3aa3a440981d0a7b24e0ce3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Profiling Columns:   0%|          | 0/19 [00:00<?, ?it/s, ride_id]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: DataAsset.remove_expectations is deprecated as of v0.12.0 and will be removed in v0.16. Please use ExpectationSuite.remove_expectation instead.\n",
      "DeprecationWarning: DataAsset.remove_expectations is deprecated as of v0.12.0 and will be removed in v0.16. Please use ExpectationSuite.remove_expectation instead.\n",
      "DeprecationWarning: DataAsset.remove_expectations is deprecated as of v0.12.0 and will be removed in v0.16. Please use ExpectationSuite.remove_expectation instead.\n",
      "DeprecationWarning: DataAsset.remove_expectations is deprecated as of v0.12.0 and will be removed in v0.16. Please use ExpectationSuite.remove_expectation instead.\n",
      "DeprecationWarning: DataAsset.remove_expectations is deprecated as of v0.12.0 and will be removed in v0.16. Please use ExpectationSuite.remove_expectation instead.\n",
      "DeprecationWarning: DataAsset.remove_expectations is deprecated as of v0.12.0 and will be removed in v0.16. Please use ExpectationSuite.remove_expectation instead.\n",
      "DeprecationWarning: DataAsset.remove_expectations is deprecated as of v0.12.0 and will be removed in v0.16. Please use ExpectationSuite.remove_expectation instead.\n",
      "DeprecationWarning: DataAsset.remove_expectations is deprecated as of v0.12.0 and will be removed in v0.16. Please use ExpectationSuite.remove_expectation instead.\n",
      "DeprecationWarning: DataAsset.remove_expectations is deprecated as of v0.12.0 and will be removed in v0.16. Please use ExpectationSuite.remove_expectation instead.\n",
      "DeprecationWarning: DataAsset.remove_expectations is deprecated as of v0.12.0 and will be removed in v0.16. Please use ExpectationSuite.remove_expectation instead.\n",
      "DeprecationWarning: DataAsset.remove_expectations is deprecated as of v0.12.0 and will be removed in v0.16. Please use ExpectationSuite.remove_expectation instead.\n",
      "DeprecationWarning: DataAsset.remove_expectations is deprecated as of v0.12.0 and will be removed in v0.16. Please use ExpectationSuite.remove_expectation instead.\n",
      "DeprecationWarning: DataAsset.remove_expectations is deprecated as of v0.12.0 and will be removed in v0.16. Please use ExpectationSuite.remove_expectation instead.\n",
      "DeprecationWarning: DataAsset.remove_expectations is deprecated as of v0.12.0 and will be removed in v0.16. Please use ExpectationSuite.remove_expectation instead.\n",
      "DeprecationWarning: DataAsset.remove_expectations is deprecated as of v0.12.0 and will be removed in v0.16. Please use ExpectationSuite.remove_expectation instead.\n",
      "DeprecationWarning: DataAsset.remove_expectations is deprecated as of v0.12.0 and will be removed in v0.16. Please use ExpectationSuite.remove_expectation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-19 10:23:47,703 INFO: \t118 expectation(s) included in expectation_suite.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: DataAsset.remove_expectations is deprecated as of v0.12.0 and will be removed in v0.16. Please use ExpectationSuite.remove_expectation instead.\n",
      "DeprecationWarning: DataAsset.remove_expectations is deprecated as of v0.12.0 and will be removed in v0.16. Please use ExpectationSuite.remove_expectation instead.\n",
      "DeprecationWarning: DataAsset.remove_expectations is deprecated as of v0.12.0 and will be removed in v0.16. Please use ExpectationSuite.remove_expectation instead.\n"
     ]
    }
   ],
   "source": [
    "# Using Great Expectations Profiler\n",
    "\n",
    "ge_profiler = ge.profile.BasicSuiteBuilderProfiler()\n",
    "expectation_suite_profiler, _ = ge_profiler.profile(ge.from_pandas(df_rides)) # here we pass a DataFrame to validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb4f309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"passenger_count\", \"taxi_id\", \"driver_id\"]:\n",
    "    df_rides[col] = df_rides[col].astype(\"int\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb4c8f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/164/fs/106/fg/619\n",
      "2022-08-19 10:23:50,513 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/164/fs/106/fg/619\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1063f219a30463b861b24467c835af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/100 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching offline feature group backfill job...\n",
      "Backfill Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/164/jobs/named/rides_fg_1_offline_fg_backfill/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x2913ff0d820>,\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.15.18\",\n",
       "     \"expectation_suite_name\": \"validate_on_insert_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_time\": \"2022-08-19T08:23:50.513622+00:00\",\n",
       "       \"run_name\": null\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"410bce62-1f98-11ed-a603-14abc5f42df5\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20220819T082350.513622Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.15.18\"\n",
       "     }\n",
       "   },\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 2,\n",
       "     \"successful_expectations\": 2,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"element_count\": 100,\n",
       "         \"missing_count\": 0,\n",
       "         \"missing_percent\": 0.0,\n",
       "         \"unexpected_count\": 0,\n",
       "         \"unexpected_percent\": 0.0,\n",
       "         \"unexpected_percent_total\": 0.0,\n",
       "         \"unexpected_percent_nonmissing\": 0.0,\n",
       "         \"partial_unexpected_list\": []\n",
       "       },\n",
       "       \"meta\": {},\n",
       "       \"expectation_config\": {\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 237\n",
       "         },\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"pickup_latitude\",\n",
       "           \"min_value\": 40.5,\n",
       "           \"max_value\": 41.8\n",
       "         },\n",
       "         \"expectation_type\": \"expect_column_values_to_be_between\"\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"element_count\": 100,\n",
       "         \"missing_count\": 0,\n",
       "         \"missing_percent\": 0.0,\n",
       "         \"unexpected_count\": 0,\n",
       "         \"unexpected_percent\": 0.0,\n",
       "         \"unexpected_percent_total\": 0.0,\n",
       "         \"unexpected_percent_nonmissing\": 0.0,\n",
       "         \"partial_unexpected_list\": []\n",
       "       },\n",
       "       \"meta\": {},\n",
       "       \"expectation_config\": {\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 238\n",
       "         },\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"pickup_longitude\",\n",
       "           \"min_value\": -74.5,\n",
       "           \"max_value\": -72.8\n",
       "         },\n",
       "         \"expectation_type\": \"expect_column_values_to_be_between\"\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {}\n",
       " })"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rides_fg = fs.get_or_create_feature_group(name=\"rides_fg\",\n",
    "                                          version=1,\n",
    "                                          primary_key=[\"ride_id\"],\n",
    "                                          event_time=[\"pickup_datetime\"],                                   \n",
    "                                          partition_key=[\"month_of_the_ride\"], \n",
    "                                          expectation_suite=expectation_suite,\n",
    "                                          description=\"Rides features\",\n",
    "                                          time_travel_format=\"HUDI\",     \n",
    "                                          online_enabled=True,                                                \n",
    "                                          statistics_config=True)\n",
    "rides_fg.insert(df_rides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ed07f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets save our newly-generated ride_ids to the csv so\n",
    "# we will retrieve them and use in fares_fg in the next notebook\n",
    "df_rides.ride_id.to_csv(\"new_ride_ids.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
