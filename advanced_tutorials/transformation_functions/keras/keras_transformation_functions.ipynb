{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c382383",
   "metadata": {},
   "source": [
    "# <span style=\"color:#ff5f27\"> üë®üèª‚Äçüè´ Keras model and Sklearn Transformation Functions with Hopsworks Model Registry</span>\n",
    "\n",
    "In this tutorial you will learn how to **register Sklearn Transformation Functions and Keras model** in the Hopsworks Model Registry, how to **retrieve** them and then use in **training and inference pipelines**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3994e496",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üóÑÔ∏è Table of Contents</span>\n",
    "- [üìù Imports](#1)\n",
    "- [‚õ≥Ô∏è Feature Pipeline](#t1)\n",
    "    - [üíΩ Loading Data](#2)\n",
    "    - [üîÆ Connecting to Hopsworks Feature Store](#3)\n",
    "    - [ü™Ñ Creating Feature Groups](#4)\n",
    "- [‚õ≥Ô∏è Training Pipeline](#t2)\n",
    "    - [üñç Feature View Creation](#5)\n",
    "    - [üë©üèª‚Äçüî¨ Data Transformation](#6)\n",
    "    - [üëî Sklearn Transformation Functions](#7)\n",
    "    - [üß¨ Modeling](#8)\n",
    "    - [üíæ Saving the Model and Transformation Functions](#9)\n",
    "- [‚õ≥Ô∏è Inference Pipeline](#t3)\n",
    "    - [üìÆ Retrieving the Model and Transformation Functions from Model Registry](#10)\n",
    "    - [üë®üèª‚Äç‚öñÔ∏è Batch Prediction](#11)\n",
    "    - [üë®üèª‚Äç‚öñÔ∏è Real-time Predictions](#12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8743b40",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## <span style='color:#ff5f27'> üìù Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e0c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd               # For data manipulation using DataFrames\n",
    "import numpy as np                # For numerical operations\n",
    "import matplotlib.pyplot as plt   # For data visualization\n",
    "import os                         # For operating system-related tasks\n",
    "import joblib                     # For saving and loading models\n",
    "\n",
    "# Import specific modules from scikit-learn and TensorFlow\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3b6633",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='t1'></a>\n",
    "# <span style=\"color:#ff5f27;\">‚õ≥Ô∏è Feature Pipeline </span>\n",
    "\n",
    "In this section you will load data, create a Hopsworks feature group and insert your dataset into created feature group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626ca429",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## <span style=\"color:#ff5f27;\"> üíΩ Loading Data </span>\n",
    "\n",
    "To begin with, let's load a dataset which contains air quality measurements for different  cities from 2013-01-01 to 2023-04-11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a4b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_original = pd.read_csv(\"https://repo.hops.works/dev/davit/air_quality/backfill_pm2_5_eu.csv\")\n",
    "df_original.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fee3006",
   "metadata": {},
   "source": [
    "Now let's add a target variable to the DataFrame. For simplicity and for demonstration purposes you will randomly assign either a 0 or a 1 to each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7aaf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a binary target column\n",
    "df_original['target'] = np.random.choice([0, 1], size=len(df_original))\n",
    "df_original.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd983ab",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## <span style=\"color:#ff5f27;\"> üîÆ Connecting to Hopsworks Feature Store </span>\n",
    "\n",
    "The next step is to login to the Hopsworks platform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f77b7b",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## <span style=\"color:#ff5f27;\">ü™Ñ Creating Feature Groups</span>\n",
    "\n",
    "Now you need to create a Feature Group and insert your dataset.\n",
    "\n",
    "You will use `.get_or_create_feature_group()` method of the feature store object.\n",
    "\n",
    "You can read about **Feature Groups** [here](https://docs.hopsworks.ai/3.2/concepts/fs/feature_group/fg_overview/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3a1093",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group = fs.get_or_create_feature_group(\n",
    "    name='feature_group_online',\n",
    "    description='Online Feature Group',\n",
    "    version=1,\n",
    "    primary_key=['city_name', 'date'],\n",
    "    online_enabled=True,\n",
    ")    \n",
    "feature_group.insert(df_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656c5800",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='t2'></a>\n",
    "# <span style=\"color:#ff5f27;\">‚õ≥Ô∏è Training Pipeline </span>\n",
    "\n",
    "In the **Training Pipeline** you will create a train-test split, build `to_df` and `transform_data` functions required for data transformation, fit OneHotEncoder and StandardScaler and use them for transforming train and test splits. Then you will build a  Keras Sequential model, fit it and register in the Hopsworks Model Registry together with sklearn transformation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6e3352",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## <span style=\"color:#ff5f27;\"> üñç Feature View Creation</span>\n",
    "\n",
    "In this part you will build a Query object and create a feature view."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a42c6f8",
   "metadata": {},
   "source": [
    "In Hopsworks Feature Store, a Query object allows you to select specific features from a feature group.\n",
    "\n",
    "`feature_group.select_except(['date'])` selects all columns from the feature group except for the 'date' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737998f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Query object\n",
    "query = feature_group.select_except(['date'])\n",
    "query.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09feef51",
   "metadata": {},
   "source": [
    "After creating the Query object, you will create a feature view.\n",
    "\n",
    "A feature view is a logical representation of data which can be used for real-time serving or batch processing. \n",
    "\n",
    "You can read more about **Feature Views** [here](https://docs.hopsworks.ai/3.2/concepts/fs/feature_view/fv_overview/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd09628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name='serving_fv',\n",
    "    version=1,\n",
    "    query=query,\n",
    "    labels=['target'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f554ced8",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è Training Dataset Creation</span>\n",
    "The next step is to create the train-test split of your data.\n",
    "\n",
    "Let's clarify the next parameters of the `.train_test_split()` method:\n",
    "\n",
    "- test_size=0.1: This parameter specifies the size of the test set relative to the entire dataset. In this case, the test set will contain 10% of the data, and the train set will have the remaining 90%.\n",
    "\n",
    "- description='Description of the dataset': A brief description provided for the train-test split dataset, explaining its purpose or any other relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb20081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train-test split dataset\n",
    "X_train, X_test, y_train, y_test = feature_view.train_test_split(\n",
    "    test_size=0.1,\n",
    "    description='Description of the dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a830bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8342245",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2a6bd8",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "## <span style=\"color:#ff5f27;\">üë©üèª‚Äçüî¨ Data Transformation</span>\n",
    "\n",
    "For Data Transformation let's create two functions: `to_df` and `transform_data`.\n",
    "\n",
    "- `to_df` function will transform a feature vector(s) list into a pandas DataFrame.\n",
    "- `transform_data` function will apply transformations to the input data using OneHotEncoder and StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59afede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(feature_vector):\n",
    "    \"\"\"\n",
    "    Convert a feature vector or a list of feature vectors into a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        feature_vector (a list, or list of lists): \n",
    "            A feature vector or a list of feature vectors. A feature vector is \n",
    "            represented as a list containing two elements: the first \n",
    "            element corresponds to the city name (categorical feature), and the \n",
    "            second element corresponds to the PM2.5 value (numerical feature).\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame representing the feature vector(s). \n",
    "        The DataFrame will have two columns: 'city_name' for the city names \n",
    "        and 'pm2_5' for the corresponding PM2.5 values.\n",
    "\n",
    "    Example:\n",
    "        >>> feature_vector = ['New York', 15.3]\n",
    "        >>> to_df(feature_vector)\n",
    "           city_name  pm2_5\n",
    "        0  New York   15.3\n",
    "\n",
    "        >>> multiple_vectors = [['New York', 15.3], ['Los Angeles', 10.7]]\n",
    "        >>> to_df(multiple_vectors)\n",
    "          city_name  pm2_5\n",
    "        0  New York   15.3\n",
    "        1  Los Angeles 10.7\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the input is a list of feature vectors\n",
    "    if isinstance(feature_vector[0], list): \n",
    "        # Separate the city names and PM2.5 values into separate lists\n",
    "        city_names = [vector[0] for vector in feature_vector]\n",
    "        pm2_5_values = [vector[1] for vector in feature_vector]\n",
    "        \n",
    "        # Create a DataFrame with 'city_name' and 'pm2_5' columns from the lists\n",
    "        data = pd.DataFrame(\n",
    "            {\n",
    "                'city_name': city_names,\n",
    "                'pm2_5': pm2_5_values,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Return the DataFrame representing multiple feature vectors\n",
    "        return data\n",
    "\n",
    "    # If only one feature vector is provided, create a DataFrame for it\n",
    "    data = pd.DataFrame(\n",
    "            {\n",
    "                'city_name': [feature_vector[0]],\n",
    "                'pm2_5': [feature_vector[1]],\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    # Return the DataFrame representing a single feature vector\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708a9a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data, one_hot_encoder, standard_scaler):\n",
    "    \"\"\"\n",
    "    Apply transformations to the input data using OneHotEncoder and StandardScaler.\n",
    "\n",
    "    Parameters:\n",
    "        data (pandas.DataFrame):\n",
    "            The input DataFrame containing the columns 'city_name' (categorical feature)\n",
    "            and 'pm2_5' (numerical feature) to be transformed.\n",
    "\n",
    "        one_hot_encoder (sklearn.preprocessing.OneHotEncoder):\n",
    "            The fitted OneHotEncoder object used to encode the 'city_name' column into binary vectors.\n",
    "\n",
    "        standard_scaler (sklearn.preprocessing.StandardScaler):\n",
    "            The fitted StandardScaler object used to standardize the 'pm2_5' column.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame:\n",
    "            A new DataFrame with the 'city_name' column encoded and the 'pm2_5' column\n",
    "            standardized using StandardScaler. The new DataFrame contains all the original\n",
    "            columns except 'city_name', and the encoded 'city_name' columns as binary vectors.\n",
    "    \"\"\"\n",
    "    # Transform the 'city_name' column using OneHotEncoder\n",
    "    city_encoded = one_hot_encoder.transform(data[['city_name']])\n",
    "\n",
    "    # Create a new DataFrame with the encoded values\n",
    "    encoded_df = pd.DataFrame(city_encoded, columns=one_hot_encoder.categories_[0])\n",
    "\n",
    "    # Concatenate the encoded DataFrame with the original DataFrame\n",
    "    data = pd.concat([data.drop('city_name', axis=1), encoded_df], axis=1)\n",
    "    \n",
    "    # Transform the 'pm2_5' column using StandardScaler\n",
    "    data['pm2_5'] = standard_scaler.transform(data[['pm2_5']])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7979c69",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "### <span style=\"color:#ff5f27;\"> üëî Sklearn Transformation Functions</span>\n",
    "\n",
    "The next step is to create instances of OneHotEncoder and StandardScaler transformers and fit them on X_train dataset.\n",
    "\n",
    "- The `OneHotEncoder` is used for converting categorical (discrete) features into a one-hot encoded representation. Categorical features are those that have distinct values and are not numerical in nature. For example, if you have a feature \"Color\" with categories like \"Red,\" \"Blue,\" and \"Green,\" the one-hot encoding will create three binary columns representing each category. If the original data point belonged to the category \"Red,\" then the first column will be 1, and the other two will be 0.\n",
    "\n",
    "- The `StandardScaler` is used for standardizing numerical features by removing the mean and scaling them to unit variance. This process ensures that the features have similar scales, which is particularly important for algorithms that are sensitive to the scale of features, like gradient descent-based methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5fd98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the OneHotEncoder and StandardScaler\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "standard_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175cacd9",
   "metadata": {},
   "source": [
    "Let's fit `one_hot_encoder` on the `city_name` column and `standard_scaler` on the `pm2_5` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a17fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the OneHotEncoder to the 'city_name' column of the training data\n",
    "one_hot_encoder.fit(X_train[['city_name']])\n",
    "\n",
    "# Fit the StandardScaler to the 'pm2_5' column of the training data\n",
    "standard_scaler.fit(X_train[['pm2_5']])\n",
    "\n",
    "# Print a success message after the fitting process is complete\n",
    "print('‚úÖ Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c958cde",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">‚õ≥Ô∏è Train Data Transformation</span>\n",
    "\n",
    "Now let's use `transform_data` function to transform `X_train` and `X_test` using fitted `OneHotEncoder` and `StandardScaler` transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e33a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = transform_data(X_train, one_hot_encoder, standard_scaler)\n",
    "X_train_transformed.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90f90aa",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">‚õ≥Ô∏è Test Data Transformation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16888a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = transform_data(X_test, one_hot_encoder, standard_scaler)\n",
    "X_test_transformed.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09cf48d",
   "metadata": {},
   "source": [
    "<a name='8'></a>\n",
    "## <span style=\"color:#ff5f27;\">üß¨ Modeling</span>\n",
    "In the Modeling part, you will build a Keras Sequential model for binary classification and fit it on the transformed X_train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6534eb57",
   "metadata": {},
   "source": [
    "Let's construct a Keras Sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8c35e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the input layer with appropriate input shape\n",
    "model.add(Dense(units=64, input_dim=X_train_transformed.shape[1], activation='relu'))\n",
    "\n",
    "# Add one or more hidden layers\n",
    "model.add( Dense(units=32, activation='relu'))\n",
    "\n",
    "# Add the sigmoid activation function\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5776dce0",
   "metadata": {},
   "source": [
    "Now you are ready to fit your Keras model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545c00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(\n",
    "    X_train_transformed, \n",
    "    y_train, \n",
    "    epochs=10, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bedc3e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üóÑ Model Registry</span>\n",
    "\n",
    "In Hopsworks, the Model Registry is a crucial component used to manage and version machine learning models. It acts as a centralized repository where trained models can be stored, tracked, and shared among team members.\n",
    "\n",
    "By calling `project.get_model_registry()`, the code retrieves a reference to the Model Registry associated with the current Hopsworks project. This reference allows the user to interact with the Model Registry and perform operations such as registering, versioning, and accessing trained machine learning models.\n",
    "With the Model Registry, data scientists and machine learning engineers can effectively collaborate, track model changes, and easily deploy the best-performing models to production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a73fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbde875",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">‚öôÔ∏è Model Schema</span>\n",
    "\n",
    "The next step is to **define input and output schema** of a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c52621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "input_schema = Schema(X_train_transformed.values)\n",
    "output_schema = Schema(y_train)\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)\n",
    "\n",
    "model_schema.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f6cb84",
   "metadata": {},
   "source": [
    "<a name='9'></a>\n",
    "### <span style=\"color:#ff5f27;\">üíæ Saving the Model and Transformation Functions</span>\n",
    "\n",
    "Now you are ready to register your model and sklearn transformation functions in the Hopsworks Moder Registry.\n",
    "\n",
    "To begin with, let's create the `keras_tf_model` model directory and save the trained model and sklearn transformation functions in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a18cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"keras_tf_model\"\n",
    "\n",
    "if os.path.isdir(model_dir) == False:\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "# Save Transformation Functions\n",
    "joblib.dump(one_hot_encoder, model_dir + '/one_hot_encoder.pkl')\n",
    "joblib.dump(standard_scaler, model_dir + '/standard_scaler.pkl')\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, model_dir + '/keras_classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770e0f9c",
   "metadata": {},
   "source": [
    "To register your model in the Hopsworks model registry you can use `.create_model()` method with the next parameters:\n",
    "\n",
    "- name=\"keras_model\": The name of the model.\n",
    "\n",
    "- metrics={\"Accuracy\": accuracy}: The model's performance metrics are specified as a dictionary, with \"Accuracy\" as the key and the value being the accuracy score computed earlier in the code. This metric represents the accuracy of the model's predictions on the test data.\n",
    "\n",
    "- description=\"Keras model\": A brief description of the model.\n",
    "\n",
    "- input_example=X_train.sample(): An example input from the training data (X_train) is used to demonstrate the expected format of the model's input data. It is randomly sampled from X_train.\n",
    "\n",
    "- model_schema=model_schema: The model schema, which represents the data input and output structure of the model, is specified using the previously defined model_schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7415dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model in the model registry\n",
    "model = mr.tensorflow.create_model(\n",
    "    name=\"keras_model\",\n",
    "    description=\"Keras model\",\n",
    "    input_example=X_train.sample(),\n",
    "    model_schema=model_schema,\n",
    ")\n",
    "\n",
    "model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d27a235",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='t3'></a>\n",
    "# <span style=\"color:#ff5f27;\">‚õ≥Ô∏è Inference Pipeline </span>\n",
    "\n",
    "In the **Inference Pipeline** section, you will retrieve your model from Hopsworks Model Registry and utilize this model to make predictions on both Batch Data and Online Feature Vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4e238f",
   "metadata": {},
   "source": [
    "<a name='10'></a>\n",
    "## <span style=\"color:#ff5f27;\"> üìÆ Retrieving the Model from Model Registry </span>\n",
    "\n",
    "To retrieve a previously registered machine learning model from the Hopsworks Model Registry you need to use the `.get_model()` method with the next parameters:\n",
    "\n",
    "- name=\"keras_model\": The name of the model to be retrieved.\n",
    "\n",
    "- version=1: The version number of the model to be retrieved.\n",
    "\n",
    "Then you will download the model and transformation functions from the Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b287444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve your model from the model registry\n",
    "retrieved_model = mr.get_model(\n",
    "    name=\"keras_model\",\n",
    "    version=1\n",
    ")\n",
    "saved_model_dir = retrieved_model.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9854b853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the Keras model\n",
    "retrieved_keras_model = joblib.load(saved_model_dir + \"/keras_classifier.pkl\")\n",
    "\n",
    "# Retrieve Transformation Functions\n",
    "one_hot_encoder = joblib.load(saved_model_dir + \"/one_hot_encoder.pkl\")\n",
    "standard_scaler = joblib.load(saved_model_dir + \"/standard_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e2e23e",
   "metadata": {},
   "source": [
    "<a name='11'></a>\n",
    "## <span style=\"color:#ff5f27;\"> üë®üèª‚Äç‚öñÔ∏è Batch Prediction </span>\n",
    "\n",
    "Batch prediction is a process in which a trained machine learning model is used to make predictions on a large set of data all at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d701a8",
   "metadata": {},
   "source": [
    "To retrieve batch data from the feature view you need to use `init_batch_scoring` method of the feature view object.\n",
    "\n",
    "`training_dataset_version` parameter specifies the version number of the training dataset that will be used for scoring.\n",
    "\n",
    "Then you can use the `.get_batch_data()` method to retrieve batch data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94123860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise feature view to retrieve batch data\n",
    "feature_view.init_batch_scoring(training_dataset_version=td_version)\n",
    "\n",
    "# Retrieve batch data\n",
    "batch_data = feature_view.get_batch_data()\n",
    "batch_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3f7cbf",
   "metadata": {},
   "source": [
    "The `transform_data` function applies the same transformations to batch_data as were applied to the training data during the preprocessing phase. This ensures that the batch data has the same format and scale as the data used to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410d1d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transformations to the batch data using transform_data function\n",
    "batch_data_transformed = transform_data(batch_data, one_hot_encoder, standard_scaler)\n",
    "batch_data_transformed.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79291d7",
   "metadata": {},
   "source": [
    "Now let's use retrieved model to predict batch data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b96bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict batch data using retrieved model\n",
    "predictions_batch = retrieved_keras_model.predict(batch_data_transformed)\n",
    "predictions_batch[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf4631d",
   "metadata": {},
   "source": [
    "<a name='12'></a>\n",
    "## <span style=\"color:#ff5f27;\"> üë®üèª‚Äç‚öñÔ∏è Real-time Predictions</span>\n",
    "\n",
    "**Real-time Predictions** is a process of using a trained machine learning model to make predictions on feature vector(s) in real-time. \n",
    "\n",
    "To begin with, let's create `to_df` function which will transform a feature vector(s) list into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bfffb8",
   "metadata": {},
   "source": [
    "The next step is to initialize the feature view for serving and then retrieve a feature vector with specified primary keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdb19e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise feature view to retrieve feature vector\n",
    "feature_view.init_serving(1)\n",
    "\n",
    "# Retrieve a feature vector\n",
    "feature_vector = feature_view.get_feature_vector(\n",
    "    entry = {\n",
    "        \"city_name\": 'Amsterdam',\n",
    "        \"date\": '2013-01-01',\n",
    "    }\n",
    ")\n",
    "feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124453e3",
   "metadata": {},
   "source": [
    "Let's apply `to_df` function in order to transform the feature vector into pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f271fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform feature vector to pandas dataframe\n",
    "feature_vector_df = to_df(feature_vector)\n",
    "feature_vector_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a70c997",
   "metadata": {},
   "source": [
    "Transform `feature_vector_df` using `transform_data` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe202dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transformations to the feature vector df using transform_data function\n",
    "feature_vector_transformed = transform_data(feature_vector_df, one_hot_encoder, standard_scaler)\n",
    "feature_vector_transformed.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8be6f56",
   "metadata": {},
   "source": [
    "Now you can use your model to predict the transformed feature vector dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dfdbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict transformed feature vector using retrieved model\n",
    "prediction_feature_vector = retrieved_keras_model.predict(feature_vector_transformed)\n",
    "prediction_feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87707f83",
   "metadata": {},
   "source": [
    "In addition, you can retrieve several feature vectors. Just pass primary keys as a list of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac541e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature vectors from feature store\n",
    "feature_vectors = feature_view.get_feature_vectors(\n",
    "    entry = [\n",
    "        {\"city_name\": 'Amsterdam', \"date\": '2013-01-01'},\n",
    "        {\"city_name\": 'Amsterdam', \"date\": '2014-01-01'},\n",
    "    ]\n",
    ")\n",
    "feature_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bde1c18",
   "metadata": {},
   "source": [
    "Apply `to_df` function in order to transform feature vectors into pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e2f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert feature vectors to pandas dataframe\n",
    "feature_vectors_df = to_df(feature_vectors)\n",
    "feature_vectors_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16794ebc",
   "metadata": {},
   "source": [
    "Transform `feature_vector_dfs` using `transform_data` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transformations to the feature vectors df using transform_data function\n",
    "feature_vectors_transformed = transform_data(feature_vectors_df, one_hot_encoder, standard_scaler)\n",
    "feature_vectors_transformed.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aefe430",
   "metadata": {},
   "source": [
    "Now you can use your model to predict the transformed feature vectors dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee7ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict transformed feature vectors using retrieved model\n",
    "prediction_feature_vectors = retrieved_keras_model.predict(feature_vectors_transformed)\n",
    "prediction_feature_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1149b1",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
