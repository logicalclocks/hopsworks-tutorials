{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c997f05a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"../../../images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 01: Feature Pipeline</span>\n",
    "\n",
    "**Note**: This tutorial does not support Google Colab.\n",
    "\n",
    "This is the first part of the quick start series of tutorials about Hopsworks Feature Store. As part of this first module, you will work with data related to credit card transactions. \n",
    "The objective of this tutorial is to demonstrate how to work with **on-demand transformation function** in the **Hopworks Feature Store** for online data with a goal of training and deploying a model that can predict fraudulent transactions.\n",
    "\n",
    "\n",
    "## üóíÔ∏è This notebook is divided in 3 sections:\n",
    "1. Loading the data and feature engineeing.\n",
    "2. Create on-demand transformation functions.\n",
    "4. Create feature groups with on-demand transformations and upload them to the Feature Store.\n",
    "\n",
    "![tutorial-flow](../../../images/01_featuregroups.png)\n",
    "\n",
    "First of all you will load the data and do some feature engineering on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebdad2e",
   "metadata": {},
   "source": [
    "# <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa7ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U hopsworks --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49806257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from features import transactions_fraud\n",
    "\n",
    "# Mute warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87d8f95",
   "metadata": {},
   "source": [
    "First of all you will load the data and do some feature engineering on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8cd4a4-b552-4cc8-b489-c4c0df165846",
   "metadata": {},
   "source": [
    "# <span style='color:#ff5f27'> üìù Feature Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d04213",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üíΩ Loading the Data </span>\n",
    "\n",
    "The data you will use comes from 2 different CSV files:\n",
    "\n",
    "- `transactions.csv`: events containing information about when a credit card was used, such as a timestamp, location, and the amount spent. A boolean fraud_label variable (True/False) tells us whether a transaction was fraudulent or not.\n",
    "- `profiles.csv`: credit card user information such as birthdate and city of residence.\n",
    "\n",
    "In a production system, these CSV files would originate from separate data sources or tables, and probably separate data pipelines. **These files have a common credit card number column cc_num, which you will use later to join features together from the different datasets.**\n",
    "\n",
    "Now, you can go ahead and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f2b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the profiles data from a CSV file\n",
    "profiles_df = pd.read_csv(\n",
    "    \"https://repo.hops.works/master/hopsworks-tutorials/data/card_fraud_online/profiles.csv\", \n",
    "    parse_dates=[\"birthdate\"],\n",
    ")\n",
    "\n",
    "# Rename columns for clarity\n",
    "profiles_df.columns = [\"name\", \"gender\", \"mail\", \"birthdate\", \"City\", \"Country\", \"cc_num\"]\n",
    "\n",
    "# Display the first three rows of the DataFrame\n",
    "profiles_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713a9568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the transactions data from a CSV file\n",
    "trans_df = pd.read_csv(\n",
    "    \"https://repo.hops.works/master/hopsworks-tutorials/data/card_fraud_online/transactions.csv\", \n",
    "    parse_dates=[\"datetime\"],\n",
    ")\n",
    "\n",
    "# Display the first three rows of the DataFrame\n",
    "trans_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad0edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter transactions DataFrame to include only rows with category \"Cash Withdrawal\"\n",
    "trans_df = trans_df[trans_df.category == \"Cash Withdrawal\"].reset_index(level=0, drop=True)\n",
    "\n",
    "# Fill missing values in the 'country' column with \"US\"\n",
    "trans_df[\"country\"] = trans_df[\"country\"].fillna(\"US\")\n",
    "\n",
    "# Add birthdate to trans_df for \n",
    "trans_df = trans_df.merge(profiles_df, on=\"cc_num\")[['tid', 'datetime', 'cc_num', 'category', 'amount', 'latitude',\n",
    "       'longitude', 'city', 'country', 'fraud_label', 'birthdate']]\n",
    "\n",
    "# Filter profiles DataFrame to include only rows with credit card numbers present in the filtered transactions DataFrame\n",
    "profiles_df = profiles_df[profiles_df.cc_num.isin(trans_df.cc_num.unique())].reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efc0deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the transactions DataFrame by 'datetime' and 'cc_num'\n",
    "trans_df.sort_values([\"datetime\", \"cc_num\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5105a1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b88055",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üõ†Ô∏è Feature Engineering </span>\n",
    "\n",
    "Fraudulent transactions can differ from regular ones in many different ways. Typical red flags would for instance be a large transaction volume/frequency in the span of a few hours. It could also be the case that elderly people in particular are targeted by fraudsters. To facilitate model learning you will create additional features based on these patterns. In particular, you will create two types of features:\n",
    "\n",
    "1. **Features that aggregate data from multiple time steps**. An example of this could be the transaction frequency of a credit card in the span of a few hours, which is computed using a window function.\n",
    "2. **Features that aggregate data from different data sources**. This could for instance be the age of a customer at the time of a transaction, which combines the `birthdate` feature from `profiles.csv` with the `datetime` feature from `transactions.csv`.\n",
    "\n",
    "Let's start with the first category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b27bbd",
   "metadata": {},
   "source": [
    "Now you are ready to start by computing the distance between consecutive transactions, lets call it `loc_delta`.\n",
    "Here you will use the [Haversine distance](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.haversine_distances.html?highlight=haversine#sklearn.metrics.pairwise.haversine_distances) to quantify the distance between two longitude and latitude coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7d5009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the prepare_transactions_fraud function to process the trans_df DataFrame\n",
    "trans_df = transactions_fraud.prepare_transactions_fraud(trans_df)\n",
    "\n",
    "# Display the first three rows of the modified DataFrame\n",
    "trans_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a14693e-10b1-4b1b-b756-b99ed19b093e",
   "metadata": {},
   "source": [
    "Next, we'll move on to the second category of features. Here, you'll calculate the age_at_transaction, which can be considered an on-demand feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38efde18-f5a6-411c-b53e-995fe0cb77b3",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> ‚ö°Ô∏è On-Demand Transformation Functions </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7018552b-1a34-4210-b330-7d29ade0efe0",
   "metadata": {},
   "source": [
    "On-demand features are features that can only be computed at the time of an inference request, based on certain parameters available at that moment. You can learn more in the documentation available [here](https://docs.hopsworks.ai/latest/user_guides/fs/feature_group/on_demand_transformations/).\n",
    "\n",
    "To calculate the feature age_at_transaction, two parameters are needed: the transaction time and the date of birth of the person. The date of birth can be retrieved from an existing feature group, but the transaction time is only known when the inference request is made. As a result, the `age_at_transaction` feature is classified as an on-demand feature.\n",
    "\n",
    "Hopsworks enables the creation of on-demand features through on-demand transformation functions. On-demand transformation functions are created by attaching transformation function to feature groups within Hopsworks.\n",
    "\n",
    "To create a transformation function, you need to use the `@hopsworks.udf` decorator. Let's start by importing the Hopsworks library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8196ffe5-9ecb-4cdf-a7a7-3df8a9f18ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bd28da-fec4-439c-b9a3-4fdbcee30cfa",
   "metadata": {},
   "source": [
    "Now, let's create an transformation function for computing the on-demand feature `age_at_transaction`. The transformation function below creates the on-demand feature `age_at_transaction`. Once the computation is complete, the `birthdate` is dropped to not included in the feature group, since it is already stored in the another feature group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cdc812-08ef-4381-a535-d1baa4f72803",
   "metadata": {},
   "outputs": [],
   "source": [
    "@hopsworks.udf(return_type=float, drop=[\"birthdate\"])\n",
    "def age_at_transaction(datetime, birthdate):\n",
    "    return (datetime - birthdate).dt.days / 365"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad1b947-ffc6-489f-ab06-75bbd5d9deb5",
   "metadata": {},
   "source": [
    "Now, let's test the transformation function we've defined. To do this, you'll first need to establish a connection to Hopsworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2482f143-ecc0-48ef-b6e9-6b881a0a42b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813c6415-a6f0-4e39-9344-7a664814830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_at_transaction.output_column_names = \"age_at_transaction\"\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    'transaction_time': pd.to_datetime(['2022-01-01', '2022-01-15']),\n",
    "    'data_of_birth': pd.to_datetime(['1998-03-21', '2000-01-30'])\n",
    "})\n",
    "\n",
    "age_at_transaction.get_udf()(test_df['transaction_time'], test_df['data_of_birth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e826bb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3ac23b",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ü™Ñ Creating Feature Groups </span>\n",
    "\n",
    "A [feature group](https://docs.hopsworks.ai/3.0/concepts/fs/feature_group/fg_overview/) can be seen as a collection of conceptually related features. In this case, you will create a feature group for the transaction data and a feature group for the windowed aggregations on the transaction data. Both will have `cc_num` as primary key, which will allow you to join them when creating a dataset in the next tutorial.\n",
    "\n",
    "Feature groups can also be used to define a namespace for features. For instance, in a real-life setting you would likely want to experiment with different window lengths. In that case, you can create feature groups with identical schema for each window length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af46c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b742ad",
   "metadata": {},
   "source": [
    "To create a feature group you need to give it a name and specify a primary key. It is also good to provide a description of the contents of the feature group and a version number, if it is not defined it will automatically be incremented to `1`. \n",
    "\n",
    "To add the on-demand feature `age_at_transaction` to a feature group, you must create an on-demand transformation function by attaching the previously defined `age_at_transaction` transformation function to the feature group. The features to be passed to the transformation function can either be explicitly specified as parameters or, if not provided, the function will automatically use features from the feature group that match the names of the function's arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e926dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create the 'transactions_fraud_online_fg' feature group\n",
    "trans_fg = fs.get_or_create_feature_group(\n",
    "    name=\"transactions_fraud_online_fg\",\n",
    "    version=1,\n",
    "    description=\"Transaction data\",\n",
    "    primary_key=['cc_num'],\n",
    "    event_time='datetime',\n",
    "    # Attacthing transformation function `age_at_transaction` to the feature group to create on-demand feature `age_at_transaction`\n",
    "    transformation_functions=[age_at_transaction],\n",
    "    online_enabled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16ae49d",
   "metadata": {},
   "source": [
    "Here you have also set `online_enabled=True`, which enables low latency access to the data. A full list of arguments can be found in the [documentation](https://docs.hopsworks.ai/feature-store-api/latest/generated/api/feature_store_api/#create_feature_group).\n",
    "\n",
    "At this point, you have only specified some metadata for the feature group. It does not store any data or even have a schema defined for the data. To make the feature group persistent you need to populate it with its associated data using the `insert` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d1428-fd2d-4333-9ba6-ea6b395f2f55",
   "metadata": {},
   "source": [
    "When inserting data into a feature group with an on-demand transformation function, you have to include all the features required for the transformation in the DataFrame being inserted. \n",
    "\n",
    "Hopsworks computes all on-demand features using the transformation function when data is inserted into the feature group, allowing for backfilling of on-demand features. This backfilling process reduces the computational effort required for creating training data, as these transformations do not need to be applied repeatedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a366430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into feature group\n",
    "trans_fg.insert(trans_df)\n",
    "print('‚úÖ Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7de1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update feature descriptions\n",
    "feature_descriptions = [\n",
    "    {\"name\": \"tid\", \"description\": \"Transaction id\"},\n",
    "    {\"name\": \"datetime\", \"description\": \"Transaction time\"},\n",
    "    {\"name\": \"cc_num\", \"description\": \"Number of the credit card performing the transaction\"},\n",
    "    {\"name\": \"amount\", \"description\": \"Dollar amount of the transaction\"},\n",
    "    {\"name\": \"country\", \"description\": \"Country in which the transaction was made\"},\n",
    "    {\"name\": \"fraud_label\", \"description\": \"Whether the transaction was fraudulent or not\"},\n",
    "    {\"name\": \"loc_delta_t_minus_1\", \"description\": \"Location of previous transaction\"},\n",
    "    {\"name\": \"time_delta_t_minus_1\", \"description\": \"Time of previous transaction\"},\n",
    "    {\"name\": \"age_at_transaction\", \"description\": \"Age of user at the time the transaction has been performed\"},\n",
    "]\n",
    "\n",
    "for desc in feature_descriptions: \n",
    "    trans_fg.update_feature_description(desc[\"name\"], desc[\"description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18025f56-0ef8-4b2f-adf9-2e47b68e6efb",
   "metadata": {},
   "source": [
    "You can now check the UI to see that the on-demand feature `age_at_transaction` is also present in the feature group along with other feature. On-demand features in the feature group can also be used as normal feature while creating feature view for model training and inference. You will see this in the following notebook.\n",
    "\n",
    "![tutorial-flow](images/on_demand_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbe721c",
   "metadata": {},
   "source": [
    "You can move on and do the same thing for the profile and label feature groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8027f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create the 'profile_fraud_online_fg' feature group\n",
    "profile_fg = fs.get_or_create_feature_group(\n",
    "    name=\"profile_fraud_online_fg\",\n",
    "    version=1,\n",
    "    description=\"Credit card holder demographic data\",\n",
    "    primary_key=['cc_num'],\n",
    "    online_enabled=True,\n",
    ")\n",
    "# Insert data into feature group\n",
    "profile_fg.insert(profiles_df)\n",
    "print('‚úÖ Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef348581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update feature descriptions\n",
    "feature_descriptions = [\n",
    "    {\"name\": \"cc_num\", \"description\": \"Number of the credit card performing the transaction\"},\n",
    "    {\"name\": \"gender\", \"description\": \"Gender of the credit card holder\"},\n",
    "]\n",
    "\n",
    "for desc in feature_descriptions: \n",
    "    profile_fg.update_feature_description(desc[\"name\"], desc[\"description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65cde95",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 02 Training Pipeline </span>\n",
    "\n",
    "In the following notebook you will use our feature groups to create a dataset you can train a model on."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1ddeae6eefc765c17da80d38ea59b893ab18c0c0904077a035ef84cfe367f83"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
