{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23feb96b",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"../images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 01: Feature Pipeline</span>\n",
    "\n",
    "**Note**: This tutorial does not support Google Colab.\n",
    "\n",
    "This is the first part of the quick start series of tutorials about Hopsworks Feature Store. As part of this first module, you will work with data related to credit card transactions. \n",
    "The objective of this tutorial is to demonstrate how to work with the **Hopworks Feature Store**  for batch data with a goal of training and saving a model that can predict fraudulent transactions. Then try it on retrieved from Feature Store batch data.\n",
    "\n",
    "\n",
    "## üóíÔ∏è This notebook is divided in 3 sections:\n",
    "1. Loading the data and feature engineeing,\n",
    "2. Connect to the Hopsworks Feature Store,\n",
    "3. Create feature groups and upload them to the Feature Store.\n",
    "\n",
    "![tutorial-flow](../images/01_featuregroups.png)\n",
    "\n",
    "First of all you will load the data and do some feature engineering on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b9be52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Downloading modules...\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "‚úÖ Done!"
     ]
    }
   ],
   "source": [
    "# Hosted notebook environments may not have the local features package\n",
    "import os\n",
    "from IPython import get_ipython\n",
    "\n",
    "\n",
    "def need_download_modules():\n",
    "    if 'google.colab' in str(get_ipython()):\n",
    "        return True\n",
    "    if 'HOPSWORKS_PROJECT_ID' in os.environ:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "if need_download_modules():\n",
    "    print(\"‚öôÔ∏è Downloading modules...\")\n",
    "    os.system('mkdir -p synthetic_data')\n",
    "    os.system('cd synthetic_data && wget https://raw.githubusercontent.com/manu-sj/hopsworks-tutorials/FSTORE-1107/advanced_tutorials/pyspark_streaming/synthetic_data/synthetic_data.py')\n",
    "    os.system('cd synthetic_data && wget https://raw.githubusercontent.com/manu-sj/hopsworks-tutorials/FSTORE-1107/advanced_tutorials/pyspark_streaming/synthetic_data/create_transaction_stream.py')\n",
    "    os.system('cd synthetic_data && wget https://raw.githubusercontent.com/manu-sj/hopsworks-tutorials/FSTORE-1107/advanced_tutorials/pyspark_streaming/synthetic_data/init_kafka.py')\n",
    "    os.system('cd synthetic_data && wget https://raw.githubusercontent.com/manu-sj/hopsworks-tutorials/FSTORE-1107/advanced_tutorials/pyspark_streaming/synthetic_data/__init__.py')\n",
    "    print('‚úÖ Done!')\n",
    "else:\n",
    "    print(\"Local environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1b2a31",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "709b0826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th></tr><tr><td>11</td><td>application_1709431794369_0071</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"/hopsworks-api/yarnui/https://ip-172-16-4-190.us-east-2.compute.internal:8089/proxy/application_1709431794369_0071/\">Link</a></td><td><a target=\"_blank\" href=\"/hopsworks-api/yarnui/https://ip-172-16-4-221.us-east-2.compute.internal:8044/node/containerlogs/container_e01_1709431794369_0071_01_000001/my_pyspark__manujose\">Link</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import (\n",
    "    from_json,\n",
    "    window,\n",
    "    avg,\n",
    "    count,\n",
    "    stddev,\n",
    "    explode,\n",
    "    date_format,\n",
    "    col,\n",
    "    mean,\n",
    "    pandas_udf,\n",
    "    PandasUDFType)\n",
    "\n",
    "from pyspark.sql.types import (\n",
    "    LongType,\n",
    "    DoubleType,\n",
    "    StringType,\n",
    "    TimestampType,\n",
    "    StructType,\n",
    "    StructField,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa510030",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üì° Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a6f8e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://staging.cloud.hopsworks.ai/p/124\n",
      "Connected. Call `.close()` to terminate connection gracefully."
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "from hsfs.core.storage_connector_api import StorageConnectorApi\n",
    "\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()\n",
    "sc_api = StorageConnectorApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50cbe0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_api = StorageConnectorApi()\n",
    "kafka_connector = sc_api.get_kafka_connector(feature_store_id=fs.id, external=False)\n",
    "kafka_config = kafka_connector.spark_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bf280a",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üóÇ Reading from Kakfa Stream </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c337242",
   "metadata": {},
   "outputs": [],
   "source": [
    "KAFKA_TOPIC_NAME = \"transactions_topic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9bc53b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from the source\n",
    "df_read = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .options(**kafka_config) \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .option(\"maxOffsetsPerTrigger\", 100) \\\n",
    "    .option(\"subscribe\", KAFKA_TOPIC_NAME) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed65282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_schema = StructType([StructField(\"tid\", StringType(), True),\n",
    "                           StructField(\"datetime\", TimestampType(), True),\n",
    "                           StructField(\"cc_num\", LongType(), True),\n",
    "                           StructField(\"category\", StringType(), True),\n",
    "                           StructField(\"amount\", DoubleType(), True),\n",
    "                           StructField(\"latitude\", DoubleType(), True),\n",
    "                           StructField(\"longitude\", DoubleType(), True),\n",
    "                           StructField(\"city\", StringType(), True),\n",
    "                           StructField(\"country\", StringType(), True),\n",
    "                           StructField(\"fraud_label\", StringType(), True),\n",
    "                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1827d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deserialize data from and create streaming query\n",
    "transaction_streaming_df = df_read.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "    .select(from_json(\"value\", parse_schema).alias(\"value\")) \\\n",
    "    .select(\"value.tid\",\n",
    "            \"value.datetime\",\n",
    "            \"value.cc_num\",\n",
    "            \"value.category\",\n",
    "            \"value.amount\",\n",
    "            \"value.latitude\",\n",
    "            \"value.longitude\",\n",
    "            \"value.city\",\n",
    "            \"value.country\",\n",
    "            \"value.fraud_label\") \\\n",
    "    .selectExpr(\"CAST(tid as string)\",\n",
    "                \"CAST(datetime as timestamp)\",\n",
    "                \"CAST(cc_num as long)\",\n",
    "                \"CAST(category as string)\",\n",
    "                \"CAST(amount as double)\",\n",
    "                \"CAST(latitude as double)\",\n",
    "                \"CAST(longitude as double)\",\n",
    "                \"CAST(city as string)\",\n",
    "                \"CAST(country as string)\",\n",
    "                \"CAST(fraud_label as string)\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83f2598",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üõ†Ô∏è Feature Engineering </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177a1de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read profile data to cogroup with streaming dataframe\n",
    "profile_fg = fs.get_or_create_feature_group(\n",
    "    name=\"profile\",\n",
    "    version=1)\n",
    "\n",
    "profile_df = profile_fg.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d821a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_transaction_df = transaction_streaming_df \\\n",
    "    .selectExpr(\"tid\",\n",
    "                \"datetime\",\n",
    "                \"cc_num\",\n",
    "                \"category\",\n",
    "                \"CAST(amount as double)\",\n",
    "                \"radians(latitude) as latitude\",\n",
    "                \"radians(longitude) as longitude\",\n",
    "                \"city\",\n",
    "                \"country\") \\\n",
    "    .withWatermark(\"datetime\", \"24 hours\") \\\n",
    "    .groupBy(window(\"datetime\", \"168 hours\")) \\\n",
    "    .applyInPandas(transactions.loc_delta_t_minus_1, schema=schema1) \\\n",
    "    .withWatermark(\"datetime\", \"24 hours\") \\\n",
    "    .groupBy(window(\"datetime\", \"168 hours\")) \\\n",
    "    .applyInPandas(transactions.time_delta_t_minus_1, schema=schema2) \\\n",
    "    .withColumn(\"month\", udf(col(\"datetime\"))) \\\n",
    "    .withWatermark(\"datetime\", \"24 hours\") \\\n",
    "    .groupBy(window(\"datetime\", \"168 hours\")) \\\n",
    "    .cogroup(profile_df.groupby(\"cc_provider\")) \\\n",
    "    .applyInPandas(transactions.card_owner_age, schema=schema3) \\\n",
    "    .withWatermark(\"datetime\", \"24 hours\") \\\n",
    "    .groupBy(window(\"datetime\", \"168 hours\")) \\\n",
    "    .cogroup(profile_df.groupby(\"cc_provider\")) \\\n",
    "    .applyInPandas(transactions.expiry_days, schema=schema4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc2d81a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_fg = fs.get_or_create_feature_group(\n",
    "    name=\"transactions\",\n",
    "    version=1,\n",
    "    description=\"Transaction data\",\n",
    "    primary_key=['cc_num'],\n",
    "    #partition_key=['month'],\n",
    "    stream=True,\n",
    "    online_enabled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7905c4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://staging.cloud.hopsworks.ai/p/124/fs/72/fg/154"
     ]
    }
   ],
   "source": [
    "q = trans_fg.insert_stream(transaction_streaming_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f0202d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6b0d90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: transactions_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://staging.cloud.hopsworks.ai/p/124/jobs/named/transactions_1_offline_fg_materialization/executions"
     ]
    }
   ],
   "source": [
    "trans_fg.materialization_job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8216031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
