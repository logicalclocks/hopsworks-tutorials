{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbca0c8a",
   "metadata": {},
   "source": [
    "![hopsworks_logo](../images/hopsworks_logo.png)\n",
    "\n",
    "# Part 01: Load, Engineer & Connect\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/logicalclocks/hopsworks-tutorials/blob/master/fraud_online/1_feature_groups.ipynb)\n",
    "\n",
    "This is the first part of the quick start series of tutorials about Hopsworks Feature Store. As part of this first module, we will work with data related to credit card transactions. \n",
    "The objective of this tutorial is to demonstrate how to work with the **Hopworks Feature Store**  for batch data with a goal of training and deploying a model that can predict fraudulent transactions.\n",
    "\n",
    "## üóíÔ∏è This notebook is divided in 3 sections:\n",
    "1. Loading the data and feature engineeing,\n",
    "2. Connect to the Hopsworks feature store,\n",
    "3. Create feature groups and upload them to the feature store.\n",
    "\n",
    "![tutorial-flow](../images/01_featuregroups.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844826d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U hopsworks --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b37bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24739fb4",
   "metadata": {},
   "source": [
    "### First of all we will load the data and do some feature engineering on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9683141",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üíΩ Loading the Data </span>\n",
    "\n",
    "The data we will use comes from 2 different CSV files:\n",
    "\n",
    "- `transactions.csv`: events containing information about when a credit card was used, such as a timestamp, location, and the amount spent. A boolean fraud_label variable (True/False) tells us whether a transaction was fraudulent or not.\n",
    "- `profiles.csv`: credit card user information such as birthdate and city of residence.\n",
    "\n",
    "In a production system, these CSV files would originate from separate data sources or tables, and probably separate data pipelines. **These files have a common credit card number column cc_num, which you will use later to join features together from the different datasets.**\n",
    "\n",
    "Now, you can go ahead and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0c21d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_df = pd.read_csv(\"https://repo.hops.works/master/hopsworks-tutorials/data/card_fraud_online/profiles.csv\", parse_dates=[\"birthdate\"])\n",
    "profiles_df.columns = [\"name\", \"gender\", \"mail\", \"birthdate\", \"City\", \"Country\", \"cc_num\"]\n",
    "profiles_df = profiles_df[[\"cc_num\", \"gender\"]]\n",
    "profiles_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c43c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df = pd.read_csv(\"https://repo.hops.works/master/hopsworks-tutorials/data/card_fraud_online/transactions.csv\", parse_dates=[\"datetime\"])\n",
    "trans_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7601bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df = trans_df[trans_df.category == \"Cash Withdrawal\"].reset_index(level=0, drop=True)\n",
    "trans_df[\"country\"] = trans_df[\"country\"].fillna(\"US\")\n",
    "profiles_df = profiles_df[profiles_df.cc_num.isin(trans_df.cc_num.unique())].reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a590082",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c82a98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a308a5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df.sort_values([\"datetime\",\"cc_num\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b951bec",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üõ†Ô∏è Feature Engineering </span>\n",
    "\n",
    "Fraudulent transactions can differ from regular ones in many different ways. Typical red flags would for instance be a large transaction volume/frequency in the span of a few hours. It could also be the case that elderly people in particular are targeted by fraudsters. To facilitate model learning we will create additional features based on these patterns. In particular, we will create two types of features:\n",
    "1. **Features that aggregate data from different data sources**. This could for instance be the age of a customer at the time of a transaction, which combines the `birthdate` feature from `profiles.csv` with the `datetime` feature from `transactions.csv`.\n",
    "2. **Features that aggregate data from multiple time steps**. An example of this could be the transaction frequency of a credit card in the span of a few hours, which is computed using a window function.\n",
    "\n",
    "Let's start with the first category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9a4481",
   "metadata": {},
   "source": [
    "Now you are ready to start by computing the distance between consecutive transactions, which we will call `loc_delta`.\n",
    "Here we use the [Haversine distance](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.haversine_distances.html?highlight=haversine#sklearn.metrics.pairwise.haversine_distances) to quantify the distance between two longitude and latitude coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1af707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians\n",
    "\n",
    "# Feature engineering.\n",
    "trans_df.sort_values(\"datetime\", inplace=True)\n",
    "trans_df[[\"longitude\", \"latitude\"]] = trans_df[[\"longitude\", \"latitude\"]].applymap(radians)\n",
    "\n",
    "def haversine(long, lat, shift):\n",
    "    \"\"\"Compute Haversine distance between each consecutive coordinate in (long, lat).\"\"\"\n",
    "\n",
    "    long_shifted = long.shift(shift)\n",
    "    lat_shifted = lat.shift(shift)\n",
    "    long_diff = long_shifted - long\n",
    "    lat_diff = lat_shifted - lat\n",
    "\n",
    "    a = np.sin(lat_diff/2.0)**2\n",
    "    b = np.cos(lat) * np.cos(lat_shifted) * np.sin(long_diff/2.0)**2\n",
    "    c = 2*np.arcsin(np.sqrt(a + b))\n",
    "\n",
    "    return c\n",
    "\n",
    "def time_delta(datetime_value, shift):\n",
    "    \"\"\"Compute time difference between each consecutive transaction.\"\"\"\n",
    "\n",
    "    time_shifted = datetime_value.shift(shift)\n",
    "    return time_shifted\n",
    "\n",
    "trans_df[\"loc_delta_t_plus_1\"] = trans_df.groupby(\"cc_num\")\\\n",
    "    .apply(lambda x : haversine(x[\"longitude\"], x[\"latitude\"], 1))\\\n",
    "    .reset_index(level=0, drop=True)\\\n",
    "    .fillna(0)\n",
    "\n",
    "trans_df[\"loc_delta_t_minus_1\"] = trans_df.groupby(\"cc_num\")\\\n",
    "    .apply(lambda x : haversine(x[\"longitude\"], x[\"latitude\"], -1))\\\n",
    "    .reset_index(level=0, drop=True)\\\n",
    "    .fillna(0)\n",
    "\n",
    "trans_df[\"time_delta_t_plus_1\"] = trans_df.groupby(\"cc_num\")\\\n",
    "    .apply(lambda x : time_delta(x[\"datetime\"], 1 ))\\\n",
    "    .reset_index(level=0, drop=True)\n",
    "\n",
    "trans_df[\"time_delta_t_minus_1\"] = trans_df.groupby(\"cc_num\")\\\n",
    "    .apply(lambda x : time_delta(x[\"datetime\"],  -1))\\\n",
    "    .reset_index(level=0, drop=True)\n",
    "\n",
    "trans_df[\"time_delta_t_plus_1\"] = (trans_df.datetime - trans_df.time_delta_t_plus_1 )/ np.timedelta64(1, 'D')\n",
    "trans_df[\"time_delta_t_minus_1\"] = (trans_df.time_delta_t_minus_1 - trans_df.datetime )/ np.timedelta64(1, 'D')\n",
    "trans_df[\"time_delta_t_plus_1\"] = trans_df.time_delta_t_plus_1.fillna(0)\n",
    "trans_df[\"time_delta_t_minus_1\"] = trans_df.time_delta_t_minus_1.fillna(0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b8f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df = trans_df[[\"tid\",\"datetime\",\"cc_num\",\"category\",\"amount\",\"city\",\"country\",\"fraud_label\",\"loc_delta_t_plus_1\", \"loc_delta_t_minus_1\", \"time_delta_t_plus_1\", \"time_delta_t_minus_1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98abc75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trans_df.datetime = trans_df.datetime.values.astype(np.int64) // 10 ** 6\n",
    "trans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3e5d79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trans_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30302881",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ae18e5",
   "metadata": {},
   "source": [
    "> **‚úÇÔ∏è Let's reduce size of `trans_df` for better perfomance. Also let's split our `trans_df` into 3 parts - the first one will be used in creating the Feature Group and the rest will be inserted in the existing Feature Group later in this tutorial.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01baf969",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df1 = trans_df.iloc[:5000]\n",
    "\n",
    "trans_df2 = trans_df.iloc[5000:7500]\n",
    "\n",
    "trans_df3 = trans_df.iloc[7500:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76167a6d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c700660a",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ü™Ñ Creating Feature Groups </span>\n",
    "\n",
    "A [feature group](https://docs.hopsworks.ai/feature-store-api/latest/generated/feature_group/) can be seen as a collection of conceptually related features. In our case, we will create a feature group for the transaction data and a feature group for the windowed aggregations on the transaction data. Both will have `tid` as primary key, which will allow us to join them when creating a dataset in the next tutorial.\n",
    "\n",
    "Feature groups can also be used to define a namespace for features. For instance, in a real-life setting we would likely want to experiment with different window lengths. In that case, we can create feature groups with identical schema for each window length. \n",
    "\n",
    "Before you can create a feature group you need to connect to our feature store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c0217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beaf1c1",
   "metadata": {},
   "source": [
    "To create a feature group we need to give it a name and specify a primary key. It is also good to provide a description of the contents of the feature group and a version number, if it is not defined it will automatically be incremented to `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896416fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_fg = fs.get_or_create_feature_group(\n",
    "    name=\"trans_fraud_online_fg\",\n",
    "    version=1,\n",
    "    description=\"Transaction data\",\n",
    "    primary_key=['cc_num'],\n",
    "    event_time=['datetime'],\n",
    "    online_enabled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dda50f",
   "metadata": {},
   "source": [
    "Here you have also set `online_enabled=True`, which enables low latency access to the data. A full list of arguments can be found in the [documentation](https://docs.hopsworks.ai/feature-store-api/latest/generated/api/feature_store_api/#create_feature_group).\n",
    "\n",
    "At this point, you have only specified some metadata for the feature group. It does not store any data or even have a schema defined for the data. To make the feature group persistent you need to populate it with its associated data using the `insert` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba48a6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trans_fg.insert(trans_df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2ce9cb",
   "metadata": {},
   "source": [
    "#### Click on the hyperlink printed in the cell output above to inspect your feature group in the UI.\n",
    "\n",
    "#### Or use the Feature Store UI\n",
    "\n",
    "![fg_open_from_jupyter.gif](../images/fg_open_from_jupyter.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0465a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_descriptions = [\n",
    "    {\"name\": \"tid\", \"description\": \"Transaction id\"},\n",
    "    {\"name\": \"datetime\", \"description\": \"Transaction time\"},\n",
    "    {\"name\": \"cc_num\", \"description\": \"Number of the credit card performing the transaction\"},\n",
    "    {\"name\": \"category\", \"description\": \"Expense category\"},\n",
    "    {\"name\": \"amount\", \"description\": \"Dollar amount of the transaction\"},\n",
    "    {\"name\": \"city\", \"description\": \"City in which the transaction was made\"},\n",
    "    {\"name\": \"country\", \"description\": \"Country in which the transaction was made\"},\n",
    "    {\"name\": \"fraud_label\", \"description\": \"Whether the transaction was fraudulent or not\"},\n",
    "    {\"name\": \"loc_delta_t_plus_1\", \"description\": \"Location of consecutive transaction\"},\n",
    "    {\"name\": \"loc_delta_t_minus_1\", \"description\": \"Location of previous transaction\"},\n",
    "    {\"name\": \"time_delta_t_plus_1\", \"description\": \"Time of consecutive transaction\"},\n",
    "    {\"name\": \"time_delta_t_minus_1\", \"description\": \"Time of previous transaction\"},    \n",
    "]\n",
    "\n",
    "for desc in feature_descriptions: \n",
    "    trans_fg.update_feature_description(desc[\"name\"], desc[\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d47a92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profile_fg = fs.get_or_create_feature_group(\n",
    "    name=\"profile_fraud_online_fg\",\n",
    "    version=1,\n",
    "    description=\"Credit card holder demographic data\",\n",
    "    primary_key=['cc_num'],\n",
    "    online_enabled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb93518",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_fg.insert(profiles_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd7fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_descriptions = [\n",
    "    {\"name\": \"cc_num\", \"description\": \"Number of the credit card performing the transaction\"},\n",
    "    {\"name\": \"gender\", \"description\": \"Gender of the credit card holder\"},\n",
    "]\n",
    "\n",
    "for desc in feature_descriptions: \n",
    "    profile_fg.update_feature_description(desc[\"name\"], desc[\"description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af0c854",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513bc729",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üëì Exploration</span>\n",
    "In the Hopsworks feature store, the metadata allows for multiple levels of explorations and review. Here we will show a few of those capacities. \n",
    "\n",
    "### <span style=\"color:#ff5f27;\"> üîé Search</span>\n",
    "Using the search function in the ui, you can query any aspect of the feature groups, feature_view and training data that was previously created.\n",
    "\n",
    "### <span style=\"color:#ff5f27;\">üìä Statistics</span>\n",
    "You can also enable statistics in the feature groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c64c36a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trans_fg = fs.get_feature_group(\"trans_fraud_online_fg\", version = 1)\n",
    "trans_fg.statistics_config = {\n",
    "    \"enabled\": True,\n",
    "    \"histograms\": True,\n",
    "    \"correlations\": True\n",
    "}\n",
    "\n",
    "trans_fg.update_statistics_config()\n",
    "trans_fg.compute_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293a8969",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ce590a",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚öñÔ∏è Great Expectations </span> \n",
    "\n",
    "Clean, high quality feature data is of paramount importance to being able to train and serve high quality models. Hopsworks offers integration with [Great Expectations](https://greatexpectations.io/) to enable a smooth data validation workflow.\n",
    "\n",
    "### `More info` - [here](https://docs.hopsworks.ai/3.0/user_guides/fs/feature_group/data_validation/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984c1598",
   "metadata": {},
   "source": [
    "> You can attach at most **one expectation suite** to a Feature Group. It can be done **on creation** or at a **later point in time**. Data validation is an **optional step** and is not required to write to a Feature Group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f928225",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd705cb",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üñ• `UI` approach </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a21ed",
   "metadata": {},
   "source": [
    "1. Click on the Feature Group section in the navigation menu.\n",
    "2. Click on New Feature Group if you want to create a brand new Feature Group. If you already created your Feature Group you can use the search bar to find and open it. Select `edit` at the top right corner of page.\n",
    "3. Scroll down to the `Expectation Suite` section. By clicking on `Add another expectation` one can choose an expectation type from a dropdown menu.  All default kwargs associated to the selected expectation type are populated as a json below the dropdown menu. **Edit the json and click the tick button to save the change locally**.\n",
    "\n",
    "![fg_edit_expectations.gif](../images/fg_edit_expectations.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e478490b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d708b49",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚úîÔ∏è‚úîÔ∏è‚úñÔ∏è Now lets create an Expectation </span> \n",
    "![expectation.png](../images/expectation.png)\n",
    "\n",
    "### So here we basically want values in `amount` column to be >10 and <10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61b39f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we can see, there are some values that are less than 10 and greater than 10000 in this batch of data.\n",
    "trans_df2.amount.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d962ee3",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üîÑ Validate your data </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5870e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets test our expectation\n",
    "trans_fg.insert(trans_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dee1b34",
   "metadata": {},
   "source": [
    "Even in the output of cell above we can see that there is an `exception` during Data validation.\n",
    "\n",
    "To see more details, please go to your Feature Group in the UI and scroll a little bit down to the corresponding section.\n",
    "\n",
    "![expectation_res.png](../images/expectation_res.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece5a118",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cbc6a2",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚å®Ô∏è `Code` approach </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f411ad",
   "metadata": {},
   "source": [
    "### The same results we can achive without UI. Here is code example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563683c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U great_expectations --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7865e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge\n",
    "\n",
    "# Create (or import an existing) expectation suite using the Great Expectations library.\n",
    "expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"validate_on_insert_suite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8452a132",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee266b03",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚úîÔ∏è‚úîÔ∏è‚úñÔ∏è Now lets create an Expectation </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e075f6",
   "metadata": {},
   "source": [
    "### ‚öñÔ∏è Great Expectations‚Äô built-in library includes more than 50 common Expectations, such as:\n",
    "\n",
    "    expect_column_values_to_not_be_null\n",
    "\n",
    "    expect_column_values_to_be_unique\n",
    "\n",
    "    expect_column_median_to_be_between...\n",
    "\n",
    "#### You can find more in the [official docs](https://legacy.docs.greatexpectations.io/en/latest/reference/glossary_of_expectations.html#expectation-glossary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d1872b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# lets add an expecation to the 'amount' column\n",
    "expectation_suite.add_expectation(\n",
    "    ge.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_columns_values_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\": \"amount\", # here we define column to which we apply an expectation\n",
    "            \"min_value\": 10,\n",
    "            \"max_value\": 100\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# you can add as many expectations (to different columns in the same time) as you want\n",
    "expectation_suite.add_expectation(\n",
    "    ge.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_minimum_value_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\": \"amount\", # here we define column to which we apply an expectation\n",
    "            \"min_value\": 0,\n",
    "            \"max_value\": 1\n",
    "        }\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfee38e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029a6ca3",
   "metadata": {},
   "source": [
    "> You can provide 'expectation_suite' **as an argument while creating a new Feature Group**. And then **insert new data** like usual, validation will run automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f539a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature = fs.get_or_create_feature_group(\n",
    "    name=\"test_fg\",\n",
    "    version=1,\n",
    "    description=\"Test data\",\n",
    "    primary_key=['index']\n",
    "    online_enabled=True,\n",
    "    # Uncomment below to attach a GE suite when creating this Feature Group\n",
    "    # expectation_suite=expectation_suite\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9879225",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7ddfb0",
   "metadata": {},
   "source": [
    "### üìÑ Here we will save an Expectation Suite to the existing Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f8492a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using Great Expectations Profiler\n",
    "\n",
    "ge_profiler = ge.profile.BasicSuiteBuilderProfiler()\n",
    "expectation_suite_profiler, _ = ge_profiler.profile(ge.from_pandas(trans_df3)) # here we pass a DataFrame to validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded485c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we retrieve our 'trans_fraud_online_fg' Feature Group from the Feature Store\n",
    "trans_fg = fs.get_or_create_feature_group(\n",
    "    name=\"trans_fraud_online_fg\",\n",
    "    version=1,\n",
    "    description=\"Transaction data\",\n",
    "    primary_key=['cc_num'],\n",
    "    event_time=['datetime'],\n",
    "    online_enabled=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96462ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets attach an expectation suite to your Feature Group.\n",
    "# It enables persistence of the expectation suite to the Hopsworks backend.\n",
    "trans_fg.save_expectation_suite(expectation_suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a14a2f",
   "metadata": {},
   "source": [
    "Here they are\n",
    "\n",
    "![expectation_using_code.png](../images/expectation_using_code.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0350bdd4",
   "metadata": {},
   "source": [
    "> **‚ùóÔ∏è Note that the expectation suite object is modified in place to populate it with necessary information to further upload validation reports. This suite can easily be retrieved during a different session or deleted whenever you are working with this Feature Group by calling:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4bd4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_expectation_suite = trans_fg.get_expectation_suite()\n",
    "ge_expectation_suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdea2c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or delete with\n",
    "# trans_fg.drop_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1847e4ca",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üîÑ Validate your data </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a21a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As validation objects returned by Hopsworks are native Great Expectation objects, \n",
    "# you can run validation using the usual Great Expectations syntax:\n",
    "ge_df = ge.from_pandas(trans_df3, expectation_suite=trans_fg.get_expectation_suite())\n",
    "ge_report = ge_df.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dd3840",
   "metadata": {},
   "source": [
    "> **‚ùóÔ∏è Note that you should always use an expectation suite that has been saved to Hopsworks if you intend to upload the associated validation report. You can use a convenience wrapper method provided by Hopsworks to validate using the attached suite:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310c2957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will run the validation using the expectation suite attached to this Feature Group\n",
    "# and raise an exception if no attached suite is found.\n",
    "ge_report = trans_fg.validate(trans_df3)\n",
    "\n",
    "# set the save_report parameter to False to skip uploading the report to Hopsworks\n",
    "# ge_report = fg.validate(df, save_report=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb92e71c",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚¨ÜÔ∏è Save Validation Reports </span> \n",
    "\n",
    "When running validation using `Great Expectations`, a **validation report** is generated containing all validation results for the different expectations. Each result provides information about whether the provided DataFrame conforms to the corresponding expectation. These reports can be stored in Hopsworks to save a validation history for the data written to a particular Feature Group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b92c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_fg.save_validation_report(ge_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e0bf9e",
   "metadata": {},
   "source": [
    "A summary of these reports is available via an API call or in the Hopsworks UI enabling easy monitoring.\n",
    "\n",
    "![expectation_res_using_code.png](../images/expectation_res_using_code.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d728f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For in-depth analysis, it is possible to download the complete report from the UI.\n",
    "\n",
    "# convenience method for rapid development\n",
    "ge_latest_report = trans_fg.get_latest_validation_report()\n",
    "# fetching the latest summary prints a link to the UI \n",
    "# where you can download full report if summary is insufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a17948",
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_latest_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdda361",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 02 </span>\n",
    "\n",
    "In the following notebook you will use our feature groups to create a dataset you can train a model on."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1ddeae6eefc765c17da80d38ea59b893ab18c0c0904077a035ef84cfe367f83"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
