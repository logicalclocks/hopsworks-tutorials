{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0279e128",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üìù Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8efd4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import getpass\n",
    "import json\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d389343",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">‚öôÔ∏è Settings </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270b84fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or getpass.getpass('üîë Enter your OpenAI API key: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58f52ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16fbf15",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üîÆ Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8916cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f2bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the 'documents' feature view\n",
    "feature_view = fs.get_feature_view(\n",
    "    name='documents',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60460ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize batch scoring for feature view\n",
    "feature_view.init_batch_scoring()\n",
    "\n",
    "# Get batch data from the feature view\n",
    "data = feature_view.get_batch_data()\n",
    "\n",
    "# Filter data to include only rows where the 'text' column length is greater than 2500\n",
    "data_filtered = data[data.text.str.len() > 2500]\n",
    "\n",
    "# Display the filtered data\n",
    "data_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d2fcb2",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">ü™Ñ Dataset Generation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d80597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(context):\n",
    "\n",
    "    instruction = \"\"\"\n",
    "    The given text is the result of the text extraction from the PDF files. \n",
    "    Generate 3 meaningful questions on the text and the respective answers.\n",
    "    Reply strictly in the JSON format:\n",
    "    {\n",
    "      \"questions\": [\"question1\", \"question2\", \"question3\"],\n",
    "      \"answers\": [\"answer1\", \"answer2\", \"answer3\"]\n",
    "    }\n",
    "\n",
    "    Ensure that the lists of questions and answers are complete and properly formatted. \n",
    "    DO NOT include any additional information or characters outside the specified JSON format. \n",
    "    The response must consist only of the requested JSON structure. \n",
    "    If the generated content does not meet the specified format, please make the necessary adjustments to ensure compliance.\"\"\"\n",
    "\n",
    "    prompt = f\"\\nContext: {context}\\nQuestion: {instruction}\"\n",
    "\n",
    "    # Create a chatbot\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        # Pre-define conversation messages for the possible roles \n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    )\n",
    "    response = json_repair.loads(completion.choices[0].message.content)\n",
    "    \n",
    "    response['context'] = context\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3642f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate question-answer pairs\n",
    "generated_questions = [\n",
    "    generate_questions(text)\n",
    "    for text \n",
    "    in tqdm(data_filtered['text'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f1cc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the generated_questions\n",
    "df = pd.DataFrame(generated_questions)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f906442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the DataFrame to expand lists in specified columns ('questions' and 'answers')\n",
    "df_expanded = df.explode(['questions', 'answers']).reset_index(drop=True)\n",
    "\n",
    "# Reset the index to create a new default integer index\n",
    "df_expanded.reset_index(inplace=True)\n",
    "\n",
    "# Rename the 'index' column to 'record_id' for clarity\n",
    "df_expanded.rename(columns={'index': 'record_id'}, inplace=True)\n",
    "\n",
    "# Display the expanded DataFrame\n",
    "df_expanded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe81b9f",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ü™Ñ CQA Feature Group Creation </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a84b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create the 'cqa_fg' feature group\n",
    "cqa_fg = fs.get_or_create_feature_group(\n",
    "    name=\"cqa_fg\",\n",
    "    version=1,\n",
    "    description='Context-Question-Response Data',\n",
    "    primary_key=['record_id'],\n",
    ")\n",
    "\n",
    "cqa_fg.insert(df_expanded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed251e4",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ü™Ñ CQA Feature View Creation </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7146f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create the 'cqa' feature view\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"cqa\",\n",
    "    version=1,\n",
    "    query=cqa_fg.select([\"context\", \"questions\", \"responses\"]),\n",
    "    description='Context-Question-Response pairs for model fine-tuning',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f6f11a",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
