{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07578271",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\">**Hopsworks Feature Store** </span> <span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 03: Training Data & Feature views</span>\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/logicalclocks/hopsworks-tutorials/blob/master/advanced_tutorials/electricity/3_feature_views_and_training_dataset.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into 3 main sections:\n",
    "1. **Feature selection**,\n",
    "2. **Feature transformations**,\n",
    "3. **Training datasets creation**\n",
    "\n",
    "![02_training-dataset](../../images/02_training-dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf4a7fa",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üì° Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d28042",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U hopsworks --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6fe84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0c75e0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9c31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_prices_fg = fs.get_or_create_feature_group(\n",
    "    name = 'electricity_prices',\n",
    "    version = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55091de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorological_measurements_fg = fs.get_or_create_feature_group(\n",
    "    name = 'meteorological_measurements',\n",
    "    version = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed73cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "swedish_holidays_fg = fs.get_or_create_feature_group(\n",
    "    name = 'swedish_holidays',\n",
    "    version = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c3e5f6",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üñç Feature View Creation and Retrieving </span>\n",
    "\n",
    "Let's start by selecting all the features you want to include for model training/inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e991e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for training data.\n",
    "fg_query = electricity_prices_fg.select_all()\\\n",
    "                        .join(\n",
    "                            meteorological_measurements_fg.select_except([\"timestamp\"])\n",
    "                        )\\\n",
    "                        .join(\n",
    "                            swedish_holidays_fg.select_all()\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb8c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this if you would like to view query results\n",
    "fg_query.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5869c48",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> ü§ñ Transformation Functions</span>\n",
    "\n",
    "Hopsworks Feature Store provides functionality to attach transformation functions to feature views and comes with built-in transformation functions such as `min_max_scaler`, `standard_scaler`, `robust_scaler` and `label_encoder`.\n",
    "\n",
    "You will preprocess our data using *min-max scaling* on numerical features and *label encoding* on categorical features. To do this you simply define a mapping between our features and transformation functions. This ensures that transformation functions such as *min-max scaling* are fitted only on the training data (and not the validation/test data), which ensures that there is no data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6198f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_areas = [\"se1\", \"se2\", \"se3\", \"se4\"]\n",
    "\n",
    "#Map features to transformations.\n",
    "mapping_transformers = {}\n",
    "for area in price_areas:\n",
    "    mapping_transformers[f\"price_{area}\"] = fs.get_transformation_function(name=\"min_max_scaler\")\n",
    "    mapping_transformers[f\"mean_temp_per_day_{area}\"] = fs.get_transformation_function(name=\"min_max_scaler\")\n",
    "    mapping_transformers[f\"mean_wind_speed_{area}\"] = fs.get_transformation_function(name=\"min_max_scaler\")\n",
    "    mapping_transformers[f\"precipitaton_amount_{area}\"] = fs.get_transformation_function(name=\"min_max_scaler\")\n",
    "    mapping_transformers[f\"total_sunshine_time_{area}\"] = fs.get_transformation_function(name=\"min_max_scaler\")\n",
    "    mapping_transformers[f\"mean_cloud_perc_{area}\"] = fs.get_transformation_function(name=\"min_max_scaler\")    \n",
    "    mapping_transformers[f\"precipitaton_type_{area}\"] = fs.get_transformation_function(name='label_encoder')\n",
    "\n",
    "mapping_transformers[\"type_of_day\"] = label_encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda7d172",
   "metadata": {},
   "source": [
    "`Feature Views` stands between **Feature Groups** and **Training Dataset**. –°ombining **Feature Groups** we can create **Feature Views** which store a metadata of our data. Having **Feature Views** we can create **Training Dataset**.\n",
    "\n",
    "The Feature Views allows schema in form of a query with filters, define a model target feature/label and additional transformation functions.\n",
    "\n",
    "In order to create Feature View we can use `FeatureStore.create_feature_view()` method.\n",
    "\n",
    "We can specify next parameters:\n",
    "\n",
    "- `name` - name of a feature group.\n",
    "\n",
    "- `version` - version of a feature group.\n",
    "\n",
    "- `labels`- our target variable.\n",
    "\n",
    "- `transformation_functions` - functions to transform our features.\n",
    "\n",
    "- `query` - query object with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd75ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.create_feature_view(\n",
    "    name='electricity_feature_view',\n",
    "    version=1,\n",
    "    transformation_functions=mapping_transformers,\n",
    "    query=fg_query\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59705f29",
   "metadata": {},
   "source": [
    "For now `Feature View` is saved in Hopsworks and we can retrieve it using `FeatureStore.get_feature_view()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1b2a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.get_feature_view(\n",
    "    name = 'electricity_feature_view',\n",
    "    version = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dc6f5d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è Training Dataset Creation</span>\n",
    "\n",
    "In Hopsworks training data is a query where the projection (set of features) is determined by the parent FeatureView with an optional snapshot on disk of the data returned by the query.\n",
    "\n",
    "**Training Dataset  may contain splits such as:** \n",
    "* Training set - the subset of training data used to train a model.\n",
    "* Validation set - the subset of training data used to evaluate hparams when training a model\n",
    "* Test set - the holdout subset of training data used to evaluate a mode\n",
    "\n",
    "To create training dataset we use `FeatureView.create_training_data()` method.\n",
    "\n",
    "Here are some importand things:\n",
    "\n",
    "- It will inherit the name of FeatureView.\n",
    "\n",
    "- The feature store currently supports the following data formats for\n",
    "training datasets: **tfrecord, csv, tsv, parquet, avro, orc**.\n",
    "\n",
    "- We can choose necessary format using **data_format** parameter.\n",
    "\n",
    "- **start_time** and **end_time** in order to filter dataset in specific time range.\n",
    "\n",
    "- We can create **train, test** splits using `create_train_test_split()`. \n",
    "\n",
    "- We can create **train,validation, test** splits using `create_train_validation_test_splits()` methods.\n",
    "\n",
    "- The only thing is that we should specify desired ratio of splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9d987a",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> ‚õ≥Ô∏è Dataset with train, test and validation splits</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa89bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training datasets based event time filter\n",
    "td_jan2021_feb2022_version, td_job = feature_view.create_training_data(\n",
    "        start_time=\"20210101\",\n",
    "        end_time=\"20220228\",    \n",
    "        description='Electricity price prediction training dataset jan2021/feb2022',\n",
    "        data_format=\"csv\",\n",
    "        coalesce=True,\n",
    "        write_options={'wait_for_job': False},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72fc15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training datasets based event time filter\n",
    "td_spring2022, td_job = feature_view.create_training_data(\n",
    "    start_time=\"20220301\",\n",
    "    end_time=\"20220531\",    \n",
    "    description='Electricity price prediction training dataset March/May 2022',\n",
    "    data_format=\"csv\",\n",
    "    coalesce=True,\n",
    "    write_options={'wait_for_job': False},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd376a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training datasets based event time filter\n",
    "td_summer2022, td_job = feature_view.create_training_data(\n",
    "    start_time=\"20220601\",\n",
    "    end_time=\"20220909\",    \n",
    "    description='Electricity price prediction training dataset June/August 2022',\n",
    "    data_format=\"csv\",\n",
    "    coalesce=True,\n",
    "    write_options={'wait_for_job': True},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248aeb38",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b95674",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 04 </span>\n",
    "\n",
    "In the next notebook you will train a model on the Training dataset, that was created in this notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
