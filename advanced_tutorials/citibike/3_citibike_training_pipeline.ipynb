{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b75d88",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\">**Hopsworks Feature Store** </span> <span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 03: Training Pipeline</span>\n",
    "\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into 3 main sections:\n",
    "1. Feature Selection.\n",
    "2. Feature preprocessing.\n",
    "3. Training datasets creation.\n",
    "4. Loading the training data.\n",
    "5. Train the model.\n",
    "6. Register model to Hopsworks model registry.\n",
    "\n",
    "![02_training-dataset](../../images/02_training-dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be42c18",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8527eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329c3705",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5327ca0a",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üì° Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134eefda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6870ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Feature Groups\n",
    "citibike_usage_fg = fs.get_or_create_feature_group(\n",
    "    name=\"citibike_usage\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "us_holidays_fg = fs.get_or_create_feature_group(\n",
    "    name=\"us_holidays\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "meteorological_measurements_fg = fs.get_or_create_feature_group(\n",
    "    name=\"meteorological_measurements\",\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c983ba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937eea82",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üñç Feature View Creation and Retrieving </span>\n",
    "\n",
    "Let's start by selecting all the features you want to include for model training/inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492fe596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for training data\n",
    "selected_features = meteorological_measurements_fg.select_except([\"timestamp\"])\\\n",
    "                          .join(\n",
    "                                us_holidays_fg.select_except([\"timestamp\"]),\n",
    "                                on=\"date\", join_type=\"left\"\n",
    "                          )\\\n",
    "                          .join(\n",
    "                              citibike_usage_fg.select_except([\"timestamp\"]),\n",
    "                              on=\"date\", join_type=\"left\"\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b293bc00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uncomment this if you would like to view your selected features\n",
    "# selected_features.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad20ee3",
   "metadata": {},
   "source": [
    "`Feature Views` stands between **Feature Groups** and **Training Dataset**. –°ombining **Feature Groups** we can create **Feature Views** which store a metadata of our data. Having **Feature Views** we can create **Training Dataset**.\n",
    "\n",
    "The Feature Views allows schema in form of a query with filters, define a model target feature/label and additional transformation functions.\n",
    "\n",
    "In order to create Feature View we can use `FeatureStore.get_or_create_feature_view()` method.\n",
    "\n",
    "We can specify next parameters:\n",
    "\n",
    "- `name` - name of a feature group.\n",
    "\n",
    "- `version` - version of a feature group.\n",
    "\n",
    "- `labels`- our target variable.\n",
    "\n",
    "- `transformation_functions` - functions to transform our features.\n",
    "\n",
    "- `query` - query object with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cd5362",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name='citibike_fv',\n",
    "    query=selected_features,\n",
    "    labels=[\"users_count\"],\n",
    "    version=1,   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2664d7d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è Training Dataset Creation</span>\n",
    "\n",
    "In Hopsworks training data is a query where the projection (set of features) is determined by the parent FeatureView with an optional snapshot on disk of the data returned by the query.\n",
    "\n",
    "**Training Dataset  may contain splits such as:** \n",
    "* Training set - the subset of training data used to train a model.\n",
    "* Validation set - the subset of training data used to evaluate hparams when training a model\n",
    "* Test set - the holdout subset of training data used to evaluate a mode\n",
    "\n",
    "To create training dataset you will use the `FeatureView.train_test_split()` method.\n",
    "\n",
    "Here are some importand things:\n",
    "\n",
    "- It will inherit the name of FeatureView.\n",
    "\n",
    "- The feature store currently supports the following data formats for\n",
    "training datasets: **tfrecord, csv, tsv, parquet, avro, orc**.\n",
    "\n",
    "- You can choose necessary format using **data_format** parameter.\n",
    "\n",
    "- **start_time** and **end_time** in order to filter dataset in specific time range.\n",
    "\n",
    "- You can create **train, test** splits using `train_test_split()`. \n",
    "\n",
    "- You can create **train,validation, test** splits using `train_validation_test_splits()` methods.\n",
    "\n",
    "- The only thing is that we should specify desired ratio of splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf7cd6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = feature_view.train_test_split(\n",
    "    train_start=\"2023-01-01\",\n",
    "    train_end=\"2023-05-01\",\n",
    "    test_start=\"2023-05-02\",\n",
    "    test_end=\"2023-05-31\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9970969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the multi-level index for the training set using 'date' and 'station_id' columns\n",
    "X_train = X_train.set_index([\"date\", \"station_id\"])\n",
    "\n",
    "# Set the multi-level index for the test set using 'date' and 'station_id' columns\n",
    "X_test = X_test.set_index([\"date\", \"station_id\"])\n",
    "\n",
    "# Convert the specified columns in the training set to float type\n",
    "X_train.iloc[:, 1:-1] = X_train.iloc[:, 1:-1].astype(float)\n",
    "\n",
    "# Convert the specified columns in the test set to float type\n",
    "X_test.iloc[:, 1:-1] = X_test.iloc[:, 1:-1].astype(float)\n",
    "\n",
    "print(f'‚õ≥Ô∏è X_train shape: {X_train.shape}')\n",
    "print(f'‚õ≥Ô∏è y_train shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec1b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in the training set\n",
    "X_train.dropna(inplace=True)\n",
    "\n",
    "# Drop rows with missing values in the test set\n",
    "X_test.dropna(inplace=True)\n",
    "\n",
    "# Drop rows with missing values in the training labels\n",
    "y_train.dropna(inplace=True)\n",
    "\n",
    "# Drop rows with missing values in the test labels\n",
    "y_test.dropna(inplace=True)\n",
    "\n",
    "# Display the first three rows of the training set\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8f9077",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\">üß¨ Modeling</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd16a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an XGBoost Regressor\n",
    "regressor = xgb.XGBRegressor()\n",
    "\n",
    "# Fit the model using the training set\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692cf009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the trained XGBoost model\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculate and print the R2 score for the XGBoost model\n",
    "r2_xgb = r2_score(y_pred, y_test.values)\n",
    "print(\"üéØ R2 score for XGBoost model:\", r2_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55a7910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with true and predicted values\n",
    "df_ = pd.DataFrame({\n",
    "    \"y_true\": np.hstack(y_test.values),\n",
    "    \"y_pred\": y_pred,\n",
    "})\n",
    "\n",
    "# Create a residual plot using Seaborn\n",
    "residplot = sns.residplot(data=df_, x=\"y_true\", y=\"y_pred\", color='#613F75')\n",
    "\n",
    "# Set plot titles and labels\n",
    "plt.title('Model Residuals')\n",
    "plt.xlabel('Observation #')\n",
    "plt.ylabel('Error')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52f9ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the figure from the residual plot\n",
    "fig = residplot.get_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a55b93",
   "metadata": {},
   "source": [
    "---\n",
    "### <span style=\"color:#ff5f27;\">‚öôÔ∏è Model Schema</span>\n",
    "\n",
    "The model needs to be set up with a [Model Schema](https://docs.hopsworks.ai/3.0/user_guides/mlops/registry/model_schema/), which describes the inputs and outputs for a model.\n",
    "\n",
    "A Model Schema can be automatically generated from training examples, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d29272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "# Create input and output schemas using the provided training data\n",
    "input_schema = Schema(X_train)\n",
    "output_schema = Schema(y_train)\n",
    "\n",
    "# Create a model schema with the input and output schemas\n",
    "model_schema = ModelSchema(\n",
    "    input_schema=input_schema, \n",
    "    output_schema=output_schema,\n",
    ")\n",
    "\n",
    "# Convert the model schema to a dictionary\n",
    "model_schema.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66fcfcb",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>üóÑ Model Registry</span>\n",
    "\n",
    "One of the features in Hopsworks is the model registry. This is where you can store different versions of models and compare their performance. Models from the registry can then be served as API endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0838eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for the model if it does not exist\n",
    "model_dir = \"citibike_xgb_model\"\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "# Save the XGBoost regressor model as json file to the specified directory\n",
    "regressor.save_model(model_dir + \"/model.json\")\n",
    "\n",
    "# Save the residual plot figure as an image in the model directory\n",
    "fig.savefig(model_dir + \"/residplot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebbb812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model registry for the project\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# Create a Python model in the model registry\n",
    "citibike_model = mr.python.create_model(\n",
    "    name=\"citibike_xgb_model\", \n",
    "    metrics={\"r2_score\": r2_xgb},\n",
    "    model_schema=model_schema,\n",
    "    input_example=X_train.sample(), \n",
    "    description=\"Citibike users per station Predictor\",\n",
    ")\n",
    "\n",
    "# Save the model directory to the model registry\n",
    "citibike_model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a7b133",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 04: Batch Inference </span>\n",
    "\n",
    "In the next notebook you will use your registered model to predict batch data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
