{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üë®üèª‚Äçüè´ Create Deployment </span>\n",
    "\n",
    "In this notebook, we'll create a deployment for our recommendation system.\n",
    "\n",
    "**NOTE Currently the transformer scripts are not implemented.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üìù Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üîÆ Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to Hopsworks Model Registry\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "dataset_api = project.get_dataset_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#ff5f27\">üöÄ Ranking Model Deployment </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll deploy our ranking model. Since it is a CatBoost model we need to implement a `Predict` class that tells Hopsworks how to load the model and how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_model = mr.get_best_model(\"ranking_model\", \"fscore\", \"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ranking_transformer.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import hopsworks\n",
    "from opensearchpy import OpenSearch\n",
    "\n",
    "import logging\n",
    "\n",
    "\n",
    "class Transformer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # connect to Hopsworks\n",
    "        project = hopsworks.connection().get_project()\n",
    "        \n",
    "        # get feature views\n",
    "        self.fs = project.get_feature_store()\n",
    "        self.articles_fv = self.fs.get_feature_view(\"articles\", 1)\n",
    "        self.articles_features = [feat.name for feat in self.articles_fv.schema]\n",
    "        self.customer_fv = self.fs.get_feature_view(\"customers\", 1)\n",
    "\n",
    "        # create opensearch client\n",
    "        opensearch_api = project.get_opensearch_api()\n",
    "        self.os_client = OpenSearch(**opensearch_api.get_default_py_config())\n",
    "        self.candidate_index = opensearch_api.get_project_index(\"candidate_index\")\n",
    "\n",
    "        # get ranking model feature names\n",
    "        mr = project.get_model_registry()\n",
    "        model = mr.get_model(\"ranking_model\", 1)\n",
    "        input_schema = model.model_schema[\"input_schema\"][\"columnar_schema\"]\n",
    "        \n",
    "        self.ranking_model_feature_names = [feat[\"name\"] for feat in input_schema]\n",
    "            \n",
    "    def preprocess(self, inputs):\n",
    "        inputs = inputs[\"instances\"][0]\n",
    "        customer_id = inputs[\"customer_id\"]\n",
    "        \n",
    "        # search for candidates\n",
    "        hits = self.search_candidates(inputs[\"query_emb\"], k=100)\n",
    "        \n",
    "        # get already bought items\n",
    "        already_bought_items_ids = self.fs.sql(\n",
    "            f\"SELECT article_id from transactions_1 WHERE customer_id = '{customer_id}'\"\n",
    "        ).values.reshape(-1).tolist()\n",
    "        \n",
    "        # build dataframes\n",
    "        item_id_list = []\n",
    "        item_emb_list = []\n",
    "        exclude_set = set(already_bought_items_ids)\n",
    "        for el in hits:\n",
    "            item_id = str(el[\"_id\"])\n",
    "            if item_id in exclude_set:\n",
    "                continue\n",
    "            item_emb = el[\"_source\"][\"my_vector1\"]\n",
    "            item_id_list.append(item_id)\n",
    "            item_emb_list.append(item_emb)\n",
    "        item_id_df = pd.DataFrame({\"article_id\" : item_id_list})\n",
    "        #item_emb_df = pd.DataFrame(item_emb_list).add_prefix(\"item_emb_\")\n",
    "        \n",
    "        # get articles feature vectors\n",
    "        articles_data = []\n",
    "        for article_id in item_id_list:\n",
    "            try:\n",
    "                article_features = self.articles_fv.get_feature_vector({\"article_id\" : article_id})\n",
    "                articles_data.append(article_features)\n",
    "            except:\n",
    "                logging.info(\"-- not found:\" + str(article_id))\n",
    "                pass # article might have been removed from catalogue\n",
    "            \n",
    "        articles_df = pd.DataFrame(data=articles_data, columns=self.articles_features)\n",
    "        \n",
    "        # join candidates with item features\n",
    "        ranking_model_inputs = item_id_df.merge(articles_df, on=\"article_id\", how=\"inner\")\n",
    "        \n",
    "        # add customer features\n",
    "        customer_features = self.customer_fv.get_feature_vector({\"customer_id\": customer_id}, return_type=\"pandas\")\n",
    "        ranking_model_inputs[\"age\"] = customer_features.age.values[0]   \n",
    "        ranking_model_inputs[\"month_sin\"] = inputs[\"month_sin\"]\n",
    "        ranking_model_inputs[\"month_cos\"] = inputs[\"month_cos\"]\n",
    "        ranking_model_inputs = ranking_model_inputs[self.ranking_model_feature_names]\n",
    "                \n",
    "        return { \"inputs\" : [{\"ranking_features\": ranking_model_inputs.values.tolist(), \"article_ids\": item_id_list} ]}\n",
    "\n",
    "    def postprocess(self, outputs):\n",
    "        preds = outputs[\"predictions\"]\n",
    "        ranking = list(zip(preds[\"scores\"], preds[\"article_ids\"])) # merge lists\n",
    "        ranking.sort(reverse=True) # sort by score (descending)\n",
    "        return { \"ranking\": ranking }\n",
    "    \n",
    "    def search_candidates(self, query_emb, k=100):\n",
    "        k = 100\n",
    "        query = {\n",
    "          \"size\": k,\n",
    "          \"query\": {\n",
    "            \"knn\": {\n",
    "              \"my_vector1\": {\n",
    "                \"vector\": query_emb,\n",
    "                \"k\": k\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "        return self.os_client.search(body = query, index = self.candidate_index)[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy transformer file into Hopsworks File System\n",
    "uploaded_file_path = dataset_api.upload(\"ranking_transformer.py\", \"Resources\", overwrite=True)\n",
    "transformer_script_path = os.path.join(\"/Projects\", project.name, uploaded_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ranking_predictor.py\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "\n",
    "class Predict(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = joblib.load(os.environ[\"ARTIFACT_FILES_PATH\"] + \"/ranking_model.pkl\")\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        features = inputs[0].pop(\"ranking_features\")\n",
    "        article_ids = inputs[0].pop(\"article_ids\")\n",
    "        \n",
    "        logging.info(\"predict -> \" + str(features))\n",
    "\n",
    "        scores = self.model.predict_proba(features).tolist()\n",
    "        scores = np.asarray(scores)[:,1].tolist() # get scores of positive class\n",
    "\n",
    "        return { \"scores\": scores, \"article_ids\": article_ids }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload predictor file to Hopsworks\n",
    "uploaded_file_path = dataset_api.upload(\"ranking_predictor.py\", \"Resources\", overwrite=True)\n",
    "predictor_script_path = os.path.join(\"/Projects\", project.name, uploaded_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that in place, we can finally deploy our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.transformer import Transformer\n",
    "\n",
    "ranking_deployment_name = \"rankingdeployment\"\n",
    "\n",
    "# define transformer\n",
    "ranking_transformer=Transformer(\n",
    "    script_file=transformer_script_path, \n",
    "    resources={\"num_instances\": 1},\n",
    ")\n",
    "\n",
    "# deploy ranking model\n",
    "ranking_deployment = ranking_model.deploy(\n",
    "    name=ranking_deployment_name,\n",
    "    description=\"Deployment that search for item candidates and scores them based on customer metadata\",\n",
    "    script_file=predictor_script_path,\n",
    "    resources={\"num_instances\": 1},\n",
    "    transformer=ranking_transformer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_deployment.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #in case of failure\n",
    "# ranking_deployment.get_logs(component=\"predictor\", tail=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test ranking deployment\n",
    "test_ranking_input = {\"instances\": [{\"customer_id\": \"641e6f3ef3a2d537140aaa0a06055ae328a0dddf2c2c0dd6e60eb0563c7cbba0\",\n",
    "    \"month_sin\": 1.2246467991473532e-16,\n",
    "    \"query_emb\": [0.214135289,\n",
    "     0.571055949,\n",
    "     0.330709577,\n",
    "     -0.225899458,\n",
    "     -0.308674961,\n",
    "     -0.0115124583,\n",
    "     0.0730511621,\n",
    "     -0.495835781,\n",
    "     0.625569344,\n",
    "     -0.0438038409,\n",
    "     0.263472944,\n",
    "     -0.58485353,\n",
    "     -0.307070434,\n",
    "     0.0414443575,\n",
    "     -0.321789205,\n",
    "     0.966559],\n",
    "    \"month_cos\": -1.0}]}\n",
    "\n",
    " # test ranking\n",
    "ranking_deployment.predict(test_ranking_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #in case of failure\n",
    "# ranking_deployment.get_logs(component=\"transformer\",tail=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#ff5f27\">üöÄ Query Model Deployment </span>\n",
    "\n",
    "We start by deploying our query model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_model = mr.get_model(\n",
    "    name=\"query_model\",\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile querymodel_transformer.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import hopsworks\n",
    "\n",
    "import logging\n",
    "\n",
    "\n",
    "class Transformer(object):\n",
    "    \n",
    "    def __init__(self):            \n",
    "        # connect to Hopsworks\n",
    "        project = hopsworks.connection().get_project()\n",
    "    \n",
    "        # get feature views and transformation functions\n",
    "        fs = project.get_feature_store()\n",
    "        self.customer_fv = fs.get_feature_view(\"customers\", 1)\n",
    "        \n",
    "        # get ranking deployment metadata object\n",
    "        ms = project.get_model_serving()\n",
    "        self.ranking_server = ms.get_deployment(\"rankingdeployment\")\n",
    "\n",
    "        # TODO (Davit): make this as on-demand feature calculation\n",
    "        self.c = 2 * np.pi / 12\n",
    "        \n",
    "        \n",
    "    def preprocess(self, inputs):\n",
    "        inputs = inputs[\"instances\"] if \"instances\" in inputs else inputs\n",
    "        customer_id = inputs[\"customer_id\"]\n",
    "        transaction_date = inputs[\"transaction_date\"]\n",
    "        \n",
    "        # extract month\n",
    "        month_of_purchase = datetime.fromisoformat(inputs.pop(\"transaction_date\"))\n",
    "        \n",
    "        # get customer features\n",
    "        #customer_features = self.customer_fv.get_feature_vector(inputs, return_type=\"pandas\")\n",
    "        customer_features = self.customer_fv.get_feature_vector({\"customer_id\": customer_id}, return_type=\"pandas\")\n",
    "        \n",
    "        # enrich inputs\n",
    "        inputs[\"age\"] = customer_features.age.values[0]   \n",
    "        \n",
    "        # TODO (Davit): make this as on-demand feature calculation\n",
    "        month_of_purchase = datetime.strptime(transaction_date, \"%Y-%m-%dT%H:%M:%S.%f\").month\n",
    "        inputs[\"month_sin\"] = float(np.sin(month_of_purchase * self.c)) \n",
    "        inputs[\"month_cos\"] = float(np.cos(month_of_purchase * self.c))\n",
    "                \n",
    "        return {\"instances\" : [inputs]}\n",
    "    \n",
    "    def postprocess(self, outputs):\n",
    "        # get ordered ranking predictions        \n",
    "        return {\"predictions\": self.ranking_server.predict({ \"instances\": outputs[\"predictions\"]})}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy transformer file into Hopsworks File System\n",
    "uploaded_file_path = dataset_api.upload(\"querymodel_transformer.py\", \"Models\", overwrite=True)\n",
    "transformer_script_path = os.path.join(\"/Projects\", project.name, uploaded_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.transformer import Transformer\n",
    "\n",
    "query_model_deployment_name = \"querydeployment\"\n",
    "\n",
    "# define transformer\n",
    "query_model_transformer=Transformer(\n",
    "    script_file=transformer_script_path, \n",
    "    resources={\"num_instances\": 1},\n",
    ")\n",
    "\n",
    "# deploy query model\n",
    "query_model_deployment = query_model.deploy(\n",
    "    name=query_model_deployment_name,\n",
    "    description=\"Deployment that generates query embeddings from customer and item features using the query model\",\n",
    "    resources={\"num_instances\": 1},\n",
    "    transformer=query_model_transformer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have registered our deployment. To start it up we need to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_model_deployment.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #in case of failure\n",
    "# query_model_deployment.get_logs(component=\"transformer\", tail=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the deployment by making a prediction on the input example we registered together with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"instances\": {\"customer_id\": \"641e6f3ef3a2d537140aaa0a06055ae328a0dddf2c2c0dd6e60eb0563c7cbba0\", \"transaction_date\": \"2022-11-15T12:16:25.330916\"}}\n",
    "# # data = {\"customer_id\": \"641e6f3ef3a2d537140aaa0a06055ae328a0dddf2c2c0dd6e60eb0563c7cbba0\", \"date_of_purchase\": \"2022-11-15T12:16:25.330916\"}\n",
    "\n",
    "query_model_deployment.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #in case of failure\n",
    "# query_model_deployment.get_logs(component=\"transformer\",tail=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's stop the deployment when we're not using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranking_deployment.stop()\n",
    "# query_model_deployment.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
