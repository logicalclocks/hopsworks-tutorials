{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"../images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 02: Training Data & Feature views</span>\n",
    "\n",
    "<span style=\"font-width:bold; font-size: 1.4rem;\">This is the second part of the quick start series of tutorials about Hopsworks Feature Store. This notebook explains how to read from a feature group and create training dataset within the feature store</span>\n",
    "\n",
    "## **üóíÔ∏è In this notebook we will see how to create a training dataset from the feature groups:** \n",
    "1. **Select the features** we want to train our model on,\n",
    "2. **How the features should be preprocessed,**\n",
    "3. **Create a dataset** for training fraud detection model.\n",
    "\n",
    "![tutorial-flow](../images/02_training-dataset.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üî™ Feature Selection </span>\n",
    "\n",
    "We start by selecting all the features we want to include for model training/inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature groups.\n",
    "trans_fg = fs.get_feature_group('transactions_fraud_online_fg', version=1)\n",
    "profile_online_fg = fs.get_feature_group('profile_fraud_online_fg', version=1)\n",
    "\n",
    "# Select features for training data.\n",
    "ds_query = trans_fg.select([\"fraud_label\", \"loc_delta_t_plus_1\", \"loc_delta_t_minus_1\",\"time_delta_t_plus_1\", \n",
    "                                                       \"time_delta_t_minus_1\", \"country\"]).\\\n",
    "                                      join(profile_online_fg.select_all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this if you would like to view query results\n",
    "#ds_query.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that you computed the features in `transactions_fg`. If you had created multiple feature groups with identical schema for different window lengths, and wanted to include them in the join you would need to include a prefix argument in the join to avoid feature name clash. See the [documentation](https://docs.hopsworks.ai/feature-store-api/latest/generated/api/query_api/#join) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§ñ Transformation Functions </span>\n",
    "\n",
    "We will preprocess our data using *min-max scaling* on numerical features and *label encoding* on categorical features. To do this we simply define a mapping between our features and transformation functions. This ensures that transformation functions such as *min-max scaling* are fitted only on the training data (and not the validation/test data), which ensures that there is no data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the transformation functions.\n",
    "min_max_scaler = fs.get_transformation_function(name=\"min_max_scaler\")\n",
    "label_encoder = fs.get_transformation_function(name=\"label_encoder\")\n",
    "\n",
    "# Map features to transformation functions.\n",
    "transformation_functions = {\n",
    "    \"loc_delta_t_plus_1\": min_max_scaler, \n",
    "    \"loc_delta_t_minus_1\": min_max_scaler, \n",
    "    \"time_delta_t_plus_1\": min_max_scaler, \n",
    "    \"time_delta_t_minus_1\": min_max_scaler,\n",
    "    \"country\": label_encoder,\n",
    "    \"gender\": label_encoder,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚öôÔ∏è Feature View Creation </span>\n",
    "\n",
    "The Feature Views allows schema in form of a query with filters, define a model target feature/label and additional transformation functions.\n",
    "In order to create a Feature View we may use `fs.create_feature_view()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/164/fs/106/fv/transactions_fraud_online_fv/version/1\n"
     ]
    }
   ],
   "source": [
    "feature_view = fs.create_feature_view(\n",
    "    name='transactions_fraud_online_fv',\n",
    "    query=ds_query,\n",
    "    labels=[\"fraud_label\"],\n",
    "    transformation_functions=transformation_functions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view and explore data in the feature view we can retrieve batch data using `get_batch_data()` method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è Training Dataset Creation</span>\n",
    "\n",
    "In Hopsworks training data is a query where the projection (set of features) is determined by the parent FeatureView with an optional snapshot on disk of the data returned by the query.\n",
    "\n",
    "**Training Dataset  may contain splits such as:** \n",
    "* Training set - the subset of training data used to train a model.\n",
    "* Validation set - the subset of training data used to evaluate hparams when training a model\n",
    "* Test set - the holdout subset of training data used to evaluate a mode\n",
    "\n",
    "Training dataset is created using `fs.create_training_dataset()` method.\n",
    "\n",
    "**From feature view APIs we can also create training datasts based on even time filters specifing `start_time` and `end_time`** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "date_format = \"%Y-%m-%d %H:%M:%S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/164/jobs/named/transactions_fraud_online_fv_1_1_create_fv_td_13072022210439/executions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `1`.\n"
     ]
    }
   ],
   "source": [
    "# Create training datasets based event time filter\n",
    "start_time = int(float(datetime.strptime(\"2022-01-01 00:00:01\", date_format).timestamp()) * 1000)\n",
    "end_time = int(float(datetime.strptime(\"2022-02-28 23:59:59\", date_format).timestamp()) * 1000)\n",
    "\n",
    "td_jan_feb_version, td_job = feature_view.create_training_data(\n",
    "        start_time = start_time,\n",
    "        end_time = end_time,    \n",
    "        description = 'transactions fraud online training dataset jan/feb',\n",
    "        data_format = \"csv\",\n",
    "        coalesce = True,\n",
    "        write_options = {'wait_for_job': True},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/164/jobs/named/transactions_fraud_online_fv_1_2_create_fv_td_13072022210558/executions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `2`.\n"
     ]
    }
   ],
   "source": [
    "start_time = int(float(datetime.strptime(\"2022-03-01 00:00:01\", date_format).timestamp()) * 1000)\n",
    "end_time = int(float(datetime.strptime(\"2022-03-31 23:59:59\", date_format).timestamp()) * 1000)\n",
    "\n",
    "td_mar_version, td_job = feature_view.create_training_data(\n",
    "        start_time = start_time,\n",
    "        end_time = end_time,\n",
    "        description = 'transactions fraud online training dataset mar',\n",
    "        data_format = \"csv\",\n",
    "        coalesce = True,\n",
    "        write_options = {'wait_for_job': True},\n",
    " )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ü™ù Training Dataset retreival </span>\n",
    "\n",
    "To retrieve training data from storage (already materialised) or from feature groups direcly we can use `get_training_dataset_splits` or `get_training_dataset` methods. If version is not provided or provided version has not already existed, it creates a new version of training data according to given arguments and returns a dataframe. If version is provided and has already existed, it reads training data from storage or feature groups and returns a dataframe. If split is provided, it reads the specific split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_jan_feb_x, train_jan_feb_y = feature_view.get_training_data(td_jan_feb_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mar_x, test_mar_y = feature_view.get_training_data(td_mar_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_delta_t_plus_1</th>\n",
       "      <th>loc_delta_t_minus_1</th>\n",
       "      <th>time_delta_t_plus_1</th>\n",
       "      <th>time_delta_t_minus_1</th>\n",
       "      <th>country</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.151085</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>0.011207</td>\n",
       "      <td>0.063218</td>\n",
       "      <td>0</td>\n",
       "      <td>4706176324350385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.016407</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>0.011939</td>\n",
       "      <td>0</td>\n",
       "      <td>4534470426799971</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018589</td>\n",
       "      <td>0.015141</td>\n",
       "      <td>0.058219</td>\n",
       "      <td>0.009030</td>\n",
       "      <td>0</td>\n",
       "      <td>4171230858092016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.064589</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.031869</td>\n",
       "      <td>0.068929</td>\n",
       "      <td>0</td>\n",
       "      <td>4835698922091297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.077770</td>\n",
       "      <td>0.040956</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>0</td>\n",
       "      <td>4429984350982682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272127</th>\n",
       "      <td>0.060584</td>\n",
       "      <td>0.092025</td>\n",
       "      <td>0.028107</td>\n",
       "      <td>0.021518</td>\n",
       "      <td>0</td>\n",
       "      <td>4923148453269709</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272128</th>\n",
       "      <td>0.096405</td>\n",
       "      <td>0.215912</td>\n",
       "      <td>0.018944</td>\n",
       "      <td>0.005257</td>\n",
       "      <td>0</td>\n",
       "      <td>4817626088411704</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272129</th>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.152283</td>\n",
       "      <td>0.004433</td>\n",
       "      <td>0.040071</td>\n",
       "      <td>0</td>\n",
       "      <td>4204637067642319</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272130</th>\n",
       "      <td>0.176244</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.028628</td>\n",
       "      <td>0.004802</td>\n",
       "      <td>0</td>\n",
       "      <td>4561295401840672</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272131</th>\n",
       "      <td>0.172232</td>\n",
       "      <td>0.062279</td>\n",
       "      <td>0.142015</td>\n",
       "      <td>0.079412</td>\n",
       "      <td>0</td>\n",
       "      <td>4302167010994550</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272132 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loc_delta_t_plus_1  loc_delta_t_minus_1  time_delta_t_plus_1  \\\n",
       "0                 0.151085             0.015748             0.011207   \n",
       "1                 0.002381             0.016407             0.002695   \n",
       "2                 0.018589             0.015141             0.058219   \n",
       "3                 0.064589             0.041533             0.031869   \n",
       "4                 0.077770             0.040956             0.002015   \n",
       "...                    ...                  ...                  ...   \n",
       "272127            0.060584             0.092025             0.028107   \n",
       "272128            0.096405             0.215912             0.018944   \n",
       "272129            0.001671             0.152283             0.004433   \n",
       "272130            0.176244             0.000200             0.028628   \n",
       "272131            0.172232             0.062279             0.142015   \n",
       "\n",
       "        time_delta_t_minus_1  country            cc_num  gender  \n",
       "0                   0.063218        0  4706176324350385       0  \n",
       "1                   0.011939        0  4534470426799971       1  \n",
       "2                   0.009030        0  4171230858092016       1  \n",
       "3                   0.068929        0  4835698922091297       1  \n",
       "4                   0.003456        0  4429984350982682       0  \n",
       "...                      ...      ...               ...     ...  \n",
       "272127              0.021518        0  4923148453269709       1  \n",
       "272128              0.005257        0  4817626088411704       0  \n",
       "272129              0.040071        0  4204637067642319       0  \n",
       "272130              0.004802        0  4561295401840672       1  \n",
       "272131              0.079412        0  4302167010994550       0  \n",
       "\n",
       "[272132 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_jan_feb_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_delta_t_plus_1</th>\n",
       "      <th>loc_delta_t_minus_1</th>\n",
       "      <th>time_delta_t_plus_1</th>\n",
       "      <th>time_delta_t_minus_1</th>\n",
       "      <th>country</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014424</td>\n",
       "      <td>0.065056</td>\n",
       "      <td>0.020885</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0</td>\n",
       "      <td>4661166931354394</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.170561</td>\n",
       "      <td>0.037195</td>\n",
       "      <td>0.036021</td>\n",
       "      <td>0.052136</td>\n",
       "      <td>0</td>\n",
       "      <td>4884743781376544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015706</td>\n",
       "      <td>0.066272</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.097817</td>\n",
       "      <td>0</td>\n",
       "      <td>4467360740682089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.141861</td>\n",
       "      <td>0.086142</td>\n",
       "      <td>0.061637</td>\n",
       "      <td>0.019772</td>\n",
       "      <td>0</td>\n",
       "      <td>4989125842799621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.080644</td>\n",
       "      <td>0.125840</td>\n",
       "      <td>0.042164</td>\n",
       "      <td>0.033426</td>\n",
       "      <td>0</td>\n",
       "      <td>4803107556056624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85023</th>\n",
       "      <td>0.157155</td>\n",
       "      <td>0.213473</td>\n",
       "      <td>0.099437</td>\n",
       "      <td>0.146200</td>\n",
       "      <td>0</td>\n",
       "      <td>4505415537884993</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85024</th>\n",
       "      <td>0.194970</td>\n",
       "      <td>0.081032</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>0.128793</td>\n",
       "      <td>0</td>\n",
       "      <td>4763158569828903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85025</th>\n",
       "      <td>0.083641</td>\n",
       "      <td>0.058278</td>\n",
       "      <td>0.089191</td>\n",
       "      <td>0.043657</td>\n",
       "      <td>0</td>\n",
       "      <td>4117492142704098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85026</th>\n",
       "      <td>0.129000</td>\n",
       "      <td>0.191834</td>\n",
       "      <td>0.061103</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0</td>\n",
       "      <td>4537099914694993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85027</th>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.066696</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.096349</td>\n",
       "      <td>0</td>\n",
       "      <td>4782192361332696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85028 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loc_delta_t_plus_1  loc_delta_t_minus_1  time_delta_t_plus_1  \\\n",
       "0                0.014424             0.065056             0.020885   \n",
       "1                0.170561             0.037195             0.036021   \n",
       "2                0.015706             0.066272             0.002872   \n",
       "3                0.141861             0.086142             0.061637   \n",
       "4                0.080644             0.125840             0.042164   \n",
       "...                   ...                  ...                  ...   \n",
       "85023            0.157155             0.213473             0.099437   \n",
       "85024            0.194970             0.081032             0.004169   \n",
       "85025            0.083641             0.058278             0.089191   \n",
       "85026            0.129000             0.191834             0.061103   \n",
       "85027            0.002320             0.066696             0.001425   \n",
       "\n",
       "       time_delta_t_minus_1  country            cc_num  gender  \n",
       "0                  0.005784        0  4661166931354394       0  \n",
       "1                  0.052136        0  4884743781376544       1  \n",
       "2                  0.097817        0  4467360740682089       1  \n",
       "3                  0.019772        0  4989125842799621       1  \n",
       "4                  0.033426        0  4803107556056624       0  \n",
       "...                     ...      ...               ...     ...  \n",
       "85023              0.146200        0  4505415537884993       0  \n",
       "85024              0.128793        0  4763158569828903       0  \n",
       "85025              0.043657        0  4117492142704098       0  \n",
       "85026              0.005357        0  4537099914694993       1  \n",
       "85027              0.096349        0  4782192361332696       1  \n",
       "\n",
       "[85028 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mar_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature view and training dataset are now visible in the UI\n",
    "\n",
    "![fg-overview](../images/fv_overview.gif)\n",
    "\n",
    "### ‚õìÔ∏è <b> Lineage </b> \n",
    "In all the feature groups and feature view you can look at the relation between each abstractions; what feature group created which training dataset and that is used in which model.\n",
    "This allows for a clear undestanding of the pipeline in relation to each element. \n",
    "\n",
    "![provenance](../images/provenance.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 03 </span>\n",
    "\n",
    "In the following notebook, you will train a model on the dataset you created in this notebook."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
