{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2kLrOh-bpGy"
   },
   "source": [
    "# Iris Flower Classification with Scikit-Learn and Hopsworks\n",
    "\n",
    "In this notebook we will, \n",
    "\n",
    "1. Load the Iris Flower dataset into Pandas from a CSV file\n",
    "2. Save the features to a feature group\n",
    "3. Create a feature view from the feature group\n",
    "4. Read the train/test features and labels using the feature view\n",
    "5. Train a KNN Model using SkLearn\n",
    "6. Save the trained model to Hopsworks\n",
    "7. Launch a serving instance to serve the trained model (KServe)\n",
    "8. Send a prediction request to the served model\n",
    "9. Start a Gradio UI to interactively make predictions using the input features for the Iris Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vVDAHU_bpG4"
   },
   "outputs": [],
   "source": [
    "!pip install -U hopsworks --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETSvpjlsbpG7"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRtpj-psbpG8"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import hopsworks\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BoEJURubpG8"
   },
   "source": [
    "### Not app.hopsworks.ai ?\n",
    "\n",
    "If you are running your own Hopsworks cluster (not app.hopsworks.ai):\n",
    "\n",
    " * uncomment the cell below\n",
    " * fill in details for your cluster\n",
    " * run the cel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMpETqYKbpG9"
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#key=\"\"\n",
    "#with open(\"api-key.txt\", \"r\") as f:\n",
    "#    key = f.read().rstrip()\n",
    "#os.environ['HOPSWORKS_PROJECT']=\"dowlingj\"\n",
    "#os.environ['HOPSWORKS_HOST']=\"35.187.178.84\"\n",
    "#os.environ['HOPSWORKS_API_KEY']=key    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWWFuDXsbpG-"
   },
   "source": [
    "### Connect to your Hopsworks cluster\n",
    "\n",
    "If you only set the HOPSWORKS_API_KEY, it will assume you are connecting to app.hopsworks.ai.\n",
    "Set HOPSWORKS_HOST and HOPSWORKS_PROJECT environment variables to connect to a different Hopsworks cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V0yX2d03bpG_"
   },
   "outputs": [],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()\n",
    "mr = project.get_model_registry()\n",
    "ms = project.get_model_serving()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVCqQYDhbpG_"
   },
   "source": [
    "## Prepare Training Dataset\n",
    "\n",
    "### Load Iris Dataset (csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRmFM7vcbpHA"
   },
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv(\"https://repo.hops.works/master/hopsworks-tutorials/data/iris.csv\")\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JR8HeEs6bpHB"
   },
   "outputs": [],
   "source": [
    "iris_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2H3XTfhMbpHB"
   },
   "source": [
    "### Save Features to the Feature Store\n",
    "\n",
    "We can save two feature groups (hive tables), one called `iris_features` that contains the iris features and the corresponding numeric label, and another feature group called `iris_labels_lookup` for converting the numeric iris label back to categorical.\n",
    "\n",
    "**Note**: To be able to run the feature store code, you first have to enable the Feature Store Service in your project. To do this, go to the \"Settings\" tab in your project, select the feature store service and click \"Save\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4By1zTHIbpHC"
   },
   "outputs": [],
   "source": [
    "iris_fg = fs.create_feature_group(name=\"iris\",\n",
    "                                  version=1,\n",
    "                                  primary_key=[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"],\n",
    "                                  description=\"Iris flower dataset\"\n",
    "                                 )\n",
    "iris_fg.insert(iris_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Feature View to Read with\n",
    "\n",
    "Feature views are used to read features for training and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tO8iIb5bpHC"
   },
   "outputs": [],
   "source": [
    "query = iris_fg.select_all()\n",
    "feature_view = fs.create_feature_view(name=\"iris\",\n",
    "                                      version=1,\n",
    "                                      description=\"Read from Iris flower dataset\",\n",
    "                                      labels=[\"variety\"],\n",
    "                                      query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rU008V0_bpHD"
   },
   "outputs": [],
   "source": [
    "feature_view = fs.get_feature_view(name=\"iris\", version=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training data\n",
    "\n",
    "Return training data as Pandas DataFrames, split into train/test sets\n",
    "\n",
    "* X_train is the train features\n",
    "* Y_train is the train labels\n",
    "* X_test is the test features\n",
    "* Y_test is the test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kyXCHVdbpHD"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = feature_view.train_test_split(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model\n",
    "Train a KNN (k-nearest neighbors) model with Scikit-learn. Use a label encoder to map the categorical labels to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJb2bj-_bpHD"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train_encoded=le.fit_transform(y_train['variety'])\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=4)\n",
    "model.fit(X_train, y_train_encoded) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalute model performance\n",
    "\n",
    "Compute the MSE of the model against the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8EC4_SvbpHE"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test_encoded, y_pred)\n",
    "\n",
    "metrics = {\n",
    "    \"rmse\" : rmse\n",
    "}\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Model for the Model Registry\n",
    "\n",
    "Save the following pickled objects as .pkl files locally to a directory that will be uploaded later to the model registry:\n",
    "\n",
    " * the model object, **model** saved as knn_iris_model.pkl\n",
    " * the label encoder object, **le** saved as knn_iris_encoder.pkl, so that we can reconstruct categorical names \n",
    "    from the encoded predictions (numbers) \n",
    "    \n",
    "The model input schema is the same set of features as in the *x_train* DataFrame.\n",
    "\n",
    "The model output schema is the same label as in the *y_train* DataFrame.\n",
    "\n",
    "Finally, lazily create the model that will be register, including all files (artifacts) in the directory (containing the pickled label encoder object and the pickled model object), the model's input/output schema, and a sample input row (**input_example**). The model registry is the **mr** object, and for our Scikit-Learn model, we create a model of type Python with **mr.python.create_model()**. For TensorFlow, there is *mr.tensorflow.create_model()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ulH3bX02bpHE"
   },
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "import os\n",
    "\n",
    "model_dir=\"iris_model\"\n",
    "if os.path.isdir(model_dir) == False:\n",
    "    os.mkdir(model_dir)\n",
    "# Put the pickled model and the predictor script in the 'iris_model' directory\n",
    "# Then save the whole 'iris_model' directory to the model registry\n",
    "pickle='knn_iris_model.pkl'\n",
    "le_pickle='knn_iris_encoder.pkl'\n",
    "\n",
    "joblib.dump(model, model_dir + \"/\" + pickle)\n",
    "joblib.dump(le, model_dir + \"/\" + le_pickle)\n",
    "\n",
    "\n",
    "input_example = X_train.sample()\n",
    "input_schema = Schema(X_train)\n",
    "output_schema = Schema(y_train)\n",
    "model_schema = ModelSchema(input_schema, output_schema)\n",
    "\n",
    "iris_model = mr.python.create_model(\n",
    "    version=1,\n",
    "    name=\"iris_model\", \n",
    "    metrics=metrics,\n",
    "    model_schema=model_schema,\n",
    "    input_example=input_example, \n",
    "    description=\"Iris Flower Predictor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictor script for Python models\n",
    "\n",
    "Scikit-learn models are deployed as Python models, in which case you need to provide a **Predict** class that implements the **predict** method. The **predict()** method invokes the model on the inputs and returns the prediction as a list.\n",
    "\n",
    "The **init()** method is run when the predictor is loaded into memory, loading the model from the local directory it is materialized to, *ARTIFACT_FILES_PATH*.\n",
    "\n",
    "The directive \"%%writefile\" writes out the cell before to the given Python file. We will use the **iris_predictor.py** file to create a deployment for our Scikit-Learn K-NN model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1k14k_uqbpHF"
   },
   "outputs": [],
   "source": [
    "%%writefile iris_model/iris_predictor.py\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "class Predict(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # NOTE: env var ARTIFACT_FILES_PATH has the local path to the model artifact files        \n",
    "        self.model = joblib.load(os.environ[\"ARTIFACT_FILES_PATH\"] + \"/knn_iris_model.pkl\")\n",
    "\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\" Serves a prediction request from a trained model\"\"\"\n",
    "        return self.model.predict(inputs).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the model with the Model Registry\n",
    "\n",
    "Register the model and its artifacts in the 'iris_model' directory to the model registry, including the model, label encoder object, and the predictor script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rPUCGnFzbpHG"
   },
   "outputs": [],
   "source": [
    "iris_model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model deployment\n",
    "\n",
    "Provide the predictor script because it is a Python model (Scikit-Learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zEEHKFzdbpHG"
   },
   "outputs": [],
   "source": [
    "predictor_script_path = iris_model.version_path + \"/iris_predictor.py\"\n",
    "irisclassifier = iris_model.deploy(name = \"irisdeployed\",\n",
    "                                   script_file=predictor_script_path,  \n",
    "                                   model_server=\"PYTHON\", \n",
    "                                   serving_tool=\"KSERVE\")\n",
    "irisclassifier.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the model running\n",
    "\n",
    "Check the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7h4qsnUlbpHG"
   },
   "outputs": [],
   "source": [
    "irisclassifier.start()\n",
    "irisclassifier.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0iRFs0FbpHH"
   },
   "source": [
    "### Send Prediction Requests to the Deployed Model\n",
    "\n",
    "For making inference requests you can use the utility method `.predict()` from the deployment object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ICAE38pzbpHH"
   },
   "outputs": [],
   "source": [
    "input_list = list(iris_model.input_example)\n",
    "\n",
    "data = {\"instances\" : [input_list]}\n",
    "res = irisclassifier.predict(data)\n",
    "print(input_list)\n",
    "print(le.inverse_transform([res[\"predictions\"][0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSFCgRWcbpHH"
   },
   "source": [
    "## Try out your Model Interactively with a Gradio UI\n",
    "\n",
    "We will build a user interface with Gradio to allow you to enter the 4 feature values (sepal length/width and petal length/width), producing a prediction of the type of iris flower.\n",
    "\n",
    "First, we have to install the gradio library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdMNftbQbpHI"
   },
   "outputs": [],
   "source": [
    "!pip install gradio --quiet\n",
    "!pip install typing-extensions==4.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "madD7SErbpHI"
   },
   "source": [
    "### Check in the Hopsworks UI that your model deployment is running \n",
    "\n",
    "If your model is already deployed, you can get a reference to it.\n",
    "\n",
    "Your iris model deployment needs to be running for the Gradio UI to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "idqSR8FobpHI"
   },
   "outputs": [],
   "source": [
    "irisclassifier = ms.get_deployment(\"irisdeployed\")\n",
    "irisclassifier.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download your model artifacts from the Model Registry\n",
    "\n",
    "You  need to download the label_encoder from the model registry to transform predictions to the labels. This could alternatively be done in a transformer script in KServe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JeXUFurEom49"
   },
   "outputs": [],
   "source": [
    "iris_model = mr.get_model(\"iris_model\", version=1)\n",
    "model_dir = iris_model.download()\n",
    "\n",
    "le = joblib.load(model_dir + \"/knn_iris_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Gradio\n",
    "\n",
    "Start the Gradio UI. Users enter the 4 feature values and a prediction is returned. We use the label encoder object to transform the number returned to the categorical value (stringified name of the Iris Flower)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h3DyKEOLbpHI"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def iris(sl, sw, pl, pw):\n",
    "    list_inputs = []\n",
    "    list_inputs.append(sl)\n",
    "    list_inputs.append(sw)\n",
    "    list_inputs.append(pl)\n",
    "    list_inputs.append(pw)\n",
    "    data = {\n",
    "        \"instances\": [list_inputs]\n",
    "    }\n",
    "    res = irisclassifier.predict(data)\n",
    "    # Convert the numerical representation of the label back to it's original iris flower name.\n",
    "    return le.inverse_transform([res[\"predictions\"][0]])[0]\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=iris,\n",
    "    title=\"Iris Flower Predictive Analytics\",\n",
    "    description=\"Experiment with sepal/petal lengths/widths to predict which flower it is.\",\n",
    "    allow_flagging=\"never\",\n",
    "    inputs=[\n",
    "        gr.inputs.Number(default=1.0, label=\"sepal length (cm)\"),\n",
    "        gr.inputs.Number(default=1.0, label=\"sepal width (cm)\"),\n",
    "        gr.inputs.Number(default=1.0, label=\"petal length (cm)\"),\n",
    "        gr.inputs.Number(default=1.0, label=\"petal width (cm)\"),\n",
    "        ],\n",
    "    outputs=\"text\")\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6trMW766bpHJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "August 2022 iris_sklearn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
