{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üë®üèª‚Äçüè´ Create Ranking Dataset </span>\n",
    "\n",
    "In this notebook, we'll create a dataset for our ranking model. Since our dataset only consists of positive user-item interactions (transactions) we need to do negative sampling. (Otherwise our model might just recommend all items to all users.)\n",
    "\n",
    "This notebook can be run to generate both training and validation data. Please run the the notebook once, change `USE_TRAIN` below to False, and run the notebook again if you want to generate both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üîÆ Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üìù Requirements </span>\n",
    "\n",
    "Install libraries:\n",
    "\n",
    "* **tensorflow** (version 2.11) [already installed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">ü™ù Retrieve Feature View and Training Dataset</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.get_feature_view(\n",
    "    name=\"retrieval\", \n",
    "    version=1,\n",
    ")\n",
    "\n",
    "train_df, val_df, test_df, y_train, y_val, y_test = feature_view.get_train_validation_test_split(\n",
    "    training_dataset_version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df[\"article_id\"] = train_df[\"article_id\"].astype(str) # to be deleted\n",
    "val_df[\"article_id\"] = val_df[\"article_id\"].astype(str)\n",
    "test_df[\"article_id\"] = test_df[\"article_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <span style=\"color:darkred\">NOTE: </span>&emsp;Repeat all cells below with both USE_TRAIN = True and USE_TRAIN = false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_TRAIN = False\n",
    "\n",
    "split, df = (\"train\", train_df) if USE_TRAIN else (\"validation\", val_df)\n",
    "df['article_id'] = df['article_id'].astype(str)\n",
    "\n",
    "ds_name = f\"ranking_{split}.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the true positive pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_features = [\"customer_id\", \"age\", \"month_sin\", \"month_cos\"]\n",
    "\n",
    "positive_pairs = df[query_features + [\"article_id\"]].copy()\n",
    "positive_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neg = len(positive_pairs)*10\n",
    "\n",
    "negative_pairs = positive_pairs[query_features]\\\n",
    "    .sample(n_neg, replace=True, random_state=1)\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "negative_pairs[\"article_id\"] = positive_pairs[\"article_id\"]\\\n",
    "    .sample(n_neg, replace=True, random_state=2).to_numpy()\n",
    "\n",
    "negative_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels.\n",
    "positive_pairs[\"label\"] = 1\n",
    "negative_pairs[\"label\"] = 0\n",
    "\n",
    "# Concatenate.\n",
    "ranking_df = pd.concat([positive_pairs, negative_pairs], ignore_index=True)\n",
    "ranking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with item features.\n",
    "articles_fg = fs.get_feature_group(\"articles\")\n",
    "item_df = articles_fg.read()\n",
    "item_df.drop_duplicates(subset=\"article_id\", inplace=True)\n",
    "ranking_df = ranking_df.merge(item_df, on=\"article_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the query and candidate embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several \"duplicated\" categorical features in the dataset. For instance, `index_code` and `index_name` encodes the same feature, but in different formats (int, string). Therefore we have to deduplicate these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_feat(s):\n",
    "    return s.endswith(\"_id\") or s.endswith(\"_no\") or s.endswith(\"_code\")\n",
    "\n",
    "features_to_exclude = [col for col in ranking_df.columns if exclude_feat(col)]\n",
    "features_to_exclude.append(\"prod_name\")\n",
    "\n",
    "ranking_df.drop(features_to_exclude, axis=\"columns\", inplace=True)\n",
    "ranking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df.to_csv(ds_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_api = project.get_dataset_api()\n",
    "uploaded_file_path = dataset_api.upload(ds_name, \"Resources\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27\">‚è©Ô∏è Next Steps </span>\n",
    "\n",
    "In the next notebook, we'll train a ranking model on the dataset we created in this notebook."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
