{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eb83ff8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"../../images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 03: Training Pipeline</span>\n",
    "\n",
    "<span style=\"font-width:bold; font-size: 1.4rem;\">This notebook explains how to read from a feature group and create training dataset within the feature store</span>\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into the following sections:\n",
    "\n",
    "1. Fetch Feature Groups\n",
    "2. Define Transformation functions\n",
    "4. Create Feature Views\n",
    "5. Create Training Dataset with training, validation and test splits\n",
    "\n",
    "![part2](../../images/02_training-dataset.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b5f602-a575-49a8-bce9-a997cca936e0",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f2ac81-423a-4380-8fd6-b70aa55eb864",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b3bcd1",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üì° Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ad779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735a083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name='air_quality',\n",
    "    version=1,\n",
    ")\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be427dca",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> üñç Feature View Creation and Retrieving </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3192d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for training data.\n",
    "selected_features = air_quality_fg.select_all().join(\n",
    "    weather_fg.select_except(['unix_time']), \n",
    "    on=['city_name', 'date'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b8ba7b-b0ab-4ea5-b050-f8e1faf43c27",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment this if you would like to view your selected features\n",
    "# selected_features.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83a1681",
   "metadata": {},
   "source": [
    "`Feature Views` stands between **Feature Groups** and **Training Dataset**. –°ombining **Feature Groups** we can create **Feature Views** which store a metadata of our data. Having **Feature Views** we can create **Training Dataset**.\n",
    "\n",
    "The Feature Views allows schema in form of a query with filters, define a model target feature/label and additional transformation functions.\n",
    "\n",
    "In order to create Feature View we can use `FeatureStore.create_feature_view()` method.\n",
    "\n",
    "You can specify next parameters:\n",
    "\n",
    "- `name` - name of a feature group.\n",
    "\n",
    "- `version` - version of a feature group.\n",
    "\n",
    "- `labels`- our target variable.\n",
    "\n",
    "- `transformation_functions` - functions to transform our features.\n",
    "\n",
    "- `query` - query object with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403df0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create the 'air_quality_fv' feature view\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name='air_quality_fv',\n",
    "    version=1,\n",
    "    query=selected_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c723c54",
   "metadata": {},
   "source": [
    "For now `Feature View` is saved in Hopsworks and you can retrieve it using `FeatureStore.get_feature_view()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1187a2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è Training Dataset Creation</span>\n",
    "\n",
    "In Hopsworks training data is a query where the projection (set of features) is determined by the parent FeatureView with an optional snapshot on disk of the data returned by the query.\n",
    "\n",
    "**Training Dataset  may contain splits such as:** \n",
    "* Training set - the subset of training data used to train a model.\n",
    "* Validation set - the subset of training data used to evaluate hparams when training a model\n",
    "* Test set - the holdout subset of training data used to evaluate a mode\n",
    "\n",
    "To create training dataset you use the `FeatureView.training_data()` method.\n",
    "\n",
    "Here are some importand things:\n",
    "\n",
    "- It will inherit the name of FeatureView.\n",
    "\n",
    "- The feature store currently supports the following data formats for\n",
    "training datasets: **tfrecord, csv, tsv, parquet, avro, orc**.\n",
    "\n",
    "- You can choose necessary format using **data_format** parameter.\n",
    "\n",
    "- **start_time** and **end_time** in order to filter dataset in specific time range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5bcf22-6ff1-4995-a8c3-11a1dab396a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = feature_view.training_data(\n",
    "    description = 'Air Quality dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c995b340-5ba6-4116-b8b6-86ca34f0a0ab",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95783124-8303-47c5-bd15-2804efa15611",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üß¨ Modeling</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b937dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fitting the encoder to the data in the 'city_name' column\n",
    "label_encoder.fit(X[['city_name']])\n",
    "\n",
    "# Transforming the 'city_name' column data using the fitted encoder\n",
    "encoded = label_encoder.transform(X[['city_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cdb6bb-6c9c-44b7-9171-1b420bae9181",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the output of the label encoding to a dense array and concatenate with the original data\n",
    "X = pd.concat([X, pd.DataFrame(encoded)], axis=1)\n",
    "\n",
    "# Drop columns 'date', 'city_name', 'unix_time' from the DataFrame 'X'\n",
    "X = X.drop(columns=['date', 'city_name', 'unix_time'])\n",
    "\n",
    "# Rename the newly added column with label-encoded city names to 'city_name_encoded'\n",
    "X = X.rename(columns={0: \"city_name_encoded\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df41c7d-00bd-4203-90a1-8cc298508d68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extracting the target variable 'pm2_5' from the DataFrame 'X' and assigning it to the variable 'y'\n",
    "y = X.pop('pm2_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0299506-195f-4ebc-b43e-347fe59db31c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets using the train_test_split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd4e24e-7f02-4944-a309-6475b65e7846",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> ‚öñÔ∏è Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5be9f8-0f88-4a7e-8fc1-65ec8b02920d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Storing the current time as the start time of the cell execution\n",
    "start_of_cell = time.time()\n",
    "\n",
    "# Creating an instance of the XGBoost Regressor\n",
    "xgb_regressor = XGBRegressor()\n",
    "\n",
    "# Fitting the XGBoost Regressor to the training data\n",
    "xgb_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting target values on the test set\n",
    "y_pred = xgb_regressor.predict(X_test)\n",
    "\n",
    "# Calculating Mean Squared Error (MSE) using sklearn\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "# Calculating Root Mean Squared Error (RMSE) using sklearn\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "# Calculating R squared using sklearn\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R squared:\", r2)\n",
    "\n",
    "# Storing the current time as the end time of the cell execution\n",
    "end_of_cell = time.time()\n",
    "\n",
    "# Printing information about the execution, including the time taken\n",
    "print(f\"Took {round(end_of_cell - start_of_cell, 2)} sec.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac31f9fb-7904-416a-9938-e85320340412",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a DataFrame 'df_' to store true and predicted values for evaluation\n",
    "df_ = pd.DataFrame({\n",
    "    \"y_true\": y_test,\n",
    "    \"y_pred\": y_pred,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc8448-2150-4cfd-803d-afbd4845b59e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a residual plot using Seaborn\n",
    "residplot = sns.residplot(data=df_, x=\"y_true\", y=\"y_pred\", color='orange')\n",
    "\n",
    "# Adding title, xlabel, and ylabel to the residual plot\n",
    "plt.title('Model Residuals')\n",
    "plt.xlabel('Observation #')\n",
    "plt.ylabel('Error')\n",
    "\n",
    "# Displaying the residual plot\n",
    "plt.show()\n",
    "\n",
    "# Getting the figure from the residual plot and displaying it separately\n",
    "fig = residplot.get_figure()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae4e226-7a93-4e4d-8131-c1de62a7b6f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting feature importances using the plot_importance function from XGBoost\n",
    "# 'xgb_regressor' is the trained XGBoost Regressor\n",
    "# Setting 'max_num_features' to 25 to display the top 25 most important features\n",
    "plot_importance(xgb_regressor, max_num_features=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcea831-6c21-4396-a0ce-0631d21d1875",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c066fe79-315e-4b85-b2ab-32d503679dc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style='color:#ff5f27'>üóÑ Model Registry</span>\n",
    "\n",
    "One of the features in Hopsworks is the model registry. This is where you can store different versions of models and compare their performance. Models from the registry can then be served as API endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a787ec40-6bd7-4950-aa5d-bf004e1e5ade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the model registry\n",
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d240dc7-8a02-47b2-9667-7483508b2d24",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">‚öôÔ∏è Model Schema</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c658df3-56a4-450b-90ee-127d0afe5b74",
   "metadata": {},
   "source": [
    "The model needs to be set up with a [Model Schema](https://docs.hopsworks.ai/machine-learning-api/latest/generated/model_schema/), which describes the inputs and outputs for a model.\n",
    "\n",
    "A Model Schema can be automatically generated from training examples, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3f3751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "# Creating input and output schemas using the 'Schema' class for features (X) and target variable (y)\n",
    "input_schema = Schema(X)\n",
    "output_schema = Schema(y)\n",
    "\n",
    "# Creating a model schema using 'ModelSchema' with the input and output schemas\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)\n",
    "\n",
    "# Converting the model schema to a dictionary representation\n",
    "schema_dict = model_schema.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2777f5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a directory for the model artifacts if it doesn't exist\n",
    "model_dir = \"air_quality_model\"\n",
    "if os.path.isdir(model_dir) == False:\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "# Saving the label encoder and XGBoost regressor as joblib files in the model directory\n",
    "joblib.dump(label_encoder, model_dir + '/label_encoder.pkl')\n",
    "joblib.dump(xgb_regressor, model_dir + '/xgboost_regressor.pkl')\n",
    "\n",
    "# Saving the residual plot figure as an image in the model directory\n",
    "fig.savefig(model_dir + \"/residplot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f6811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Python model in the model registry named 'air_quality_xgboost_model'\n",
    "aq_model = mr.python.create_model(\n",
    "    name=\"air_quality_xgboost_model\", \n",
    "    metrics={\n",
    "        \"RMSE\": rmse,\n",
    "        \"MSE\": mse,\n",
    "        \"R squared\": r2,\n",
    "    },\n",
    "    model_schema=model_schema,\n",
    "    input_example=X_test.sample().values, \n",
    "    description=\"Air Quality (PM2.5) predictor\",\n",
    ")\n",
    "\n",
    "# Saving the model artifacts to the 'air_quality_model' directory in the model registry\n",
    "aq_model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6544a7",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 04: Batch Inference</span>\n",
    "\n",
    "In the following notebook you will use your model for Batch Inference.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "63265f9757e7c73c149a91832e3b2b12ced37a5390b9151ad08a04f276cd5846"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
