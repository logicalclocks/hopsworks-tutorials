{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fadaf397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th></tr><tr><td>2</td><td>application_1680613147107_0013</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"/hopsworks-api/yarnui/https://ip-172-31-29-232.eu-north-1.compute.internal:8089/proxy/application_1680613147107_0013/\">Link</a></td><td><a target=\"_blank\" href=\"/hopsworks-api/yarnui/https://ip-172-31-24-24.eu-north-1.compute.internal:8044/node/containerlogs/container_e01_1680613147107_0013_01_000001/hackathon__davit000\">Link</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pyspark.sql.types import StructField, StructType, StringType, DoubleType, TimestampType, LongType, IntegerType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e15b76",
   "metadata": {},
   "source": [
    "# Create empty feature groups \n",
    "In this demo example we are expecting to recieve data from Kafka topic, read using spark streaming, do streamig aggregations and ingest aggregated data to feature groups. Thus we will create empy feature groups where we will ingest streaming data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cbceaf",
   "metadata": {},
   "source": [
    "### Define schema for the feature group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129816f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_ride_schema = StructType([StructField('ride_id', StringType(), True),\n",
    "                               StructField('ride_status', StringType(), True),\n",
    "                               StructField('point_idx', IntegerType(), True),\n",
    "                               StructField('longitude', DoubleType(), True),\n",
    "                               StructField('latitude', DoubleType(), True),\n",
    "                               StructField('meter_reading', DoubleType(), True),\n",
    "                               StructField('meter_increment', DoubleType(), True),\n",
    "                               StructField('passenger_count', IntegerType(), True)\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9e246c",
   "metadata": {},
   "source": [
    "### Create empty spark dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83d126ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_taxi_ride_df = sqlContext.createDataFrame(sc.emptyRDD(), taxi_ride_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016a35d6",
   "metadata": {},
   "source": [
    "### Establish a connection with your Hopsworks feature store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a4da6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully."
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "connection = hsfs.connection()\n",
    "# get a reference to the feature store, you can access also shared feature stores by providing the feature store name\n",
    "fs = connection.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac85edb",
   "metadata": {},
   "source": [
    "### Create feature group metadata object and save empty spark dataframe to materialise them in hopsworks feature store.\n",
    "\n",
    "Now We will create each feature group and enable online feature store. Since we are plannig to use these feature groups durring online model serving primary key(s) are required to retrieve feature vector from online feature store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fb0ab99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://023f3040-d2e6-11ed-9e7a-35fcede20462.cloud.hopsworks.ai/p/120/fs/68/fg/18\n",
      "(None, None)"
     ]
    }
   ],
   "source": [
    "taxi_ride_fg = fs.create_feature_group(\"taxi_ride\", \n",
    "                                        version = 1,\n",
    "                                        statistics_config=False, \n",
    "                                        primary_key=[\"ride_id\"],\n",
    "                                        online_enabled=True,\n",
    "                                        stream=True)\n",
    "\n",
    "taxi_ride_fg.save(empty_taxi_ride_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45305b20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}