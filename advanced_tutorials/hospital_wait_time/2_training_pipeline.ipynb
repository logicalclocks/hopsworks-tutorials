{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6699fe1",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üìù Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39a3d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from prophet import Prophet\n",
    "from prophet.serialize import model_to_json\n",
    "\n",
    "# Mute warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f80e358",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üì° Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88a3faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65e85bf",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üî™ Feature Selection </span>\n",
    "\n",
    "You will start by selecting all the features you want to include for model training/inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ec70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the 'patient_info' feature group\n",
    "patient_info_fg = fs.get_feature_group(\n",
    "    name=\"patient_info\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "# Retrieve the 'medical_info' feature group\n",
    "medical_info_fg = fs.get_feature_group(\n",
    "    name=\"medical_info\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "# Retrieve the 'transplant_compatibility' feature group\n",
    "transplant_compatibility_fg = fs.get_feature_group(\n",
    "    name=\"transplant_compatibility\",\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ba77ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for training data.\n",
    "selected_features = patient_info_fg.select_all([\"id\", \"date\"])\\\n",
    "    .join(medical_info_fg.select_except([\"id\", \"date\"]))\\\n",
    "    .join(transplant_compatibility_fg.select_except([\"id\", \"date\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495cbb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this if you would like to view your selected features\n",
    "selected_features.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5902c9e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚öôÔ∏è Transformation Functions </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4ae19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[f.name for f in fs.get_transformation_functions()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c32555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = fs.get_transformation_function(name=\"label_encoder\")\n",
    "\n",
    "standard_scaler = fs.get_transformation_function(name=\"standard_scaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4580c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_category = ['gender', 'age_cat', 'blood_gp', 'underlying_disease', 'gestation', 'prior_transplant', 'if_transplanted']\n",
    "\n",
    "transformation_functions_category = {\n",
    "    feature_name: label_encoder\n",
    "    for feature_name\n",
    "    in features_category\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5eb3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_numerical = [\n",
    "    'age_at_list_registration', 'dialysis_duration', 'number_prior_transplant', 'cpra', 'hla_a1', 'hla_a2', 'hla_b1', 'hla_b2', 'hla_dr1', 'hla_dr2',\n",
    "]\n",
    "\n",
    "transformation_functions_numerical = {\n",
    "    feature_name: standard_scaler\n",
    "    for feature_name\n",
    "    in features_numerical\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7e76ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join transformation_functions_category and transformation_functions_numerical dictionaries into one\n",
    "transformation_functions = transformation_functions_category | transformation_functions_numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91636dc3",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚öôÔ∏è Feature View Creation </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576617c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create the 'medical_features' feature view\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name='medical_features',\n",
    "    version=1,\n",
    "    query=selected_features,\n",
    "    labels=[\"duration\"],\n",
    "    transformation_functions=transformation_functions,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb3b8e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è Training Dataset Creation</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7851e335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split date with percentage \n",
    "df = patient_info_fg.read()\n",
    "\n",
    "def split_dfs(df): \n",
    "    df = df.sort_values(by='date') \n",
    "    trainvals = df[:int(len(df)*0.8)] \n",
    "    testvals = df[int(len(df)*0.8):] \n",
    "    return {\n",
    "        'train_start': min(trainvals.date).date(), \n",
    "        'train_end': max(trainvals.date).date(), \n",
    "        'test_start': min(testvals.date).date(), \n",
    "        'test_end': max(testvals.date).date(),\n",
    "    }\n",
    "\n",
    "split_dict = split_dfs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a8f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f4373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = feature_view.train_test_split(\n",
    "    train_start=split_dict['train_start'],\n",
    "    train_end=split_dict['train_end'],\n",
    "    test_start=split_dict['test_start'],\n",
    "    test_end=split_dict['test_end'],    \n",
    "    event_time=True,\n",
    ")\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2facefa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d510db36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the X_train DataFrame based on the \"datetime\" column in ascending order\n",
    "X_train = X_train.sort_values(\"date\")\n",
    "# Reindex the y_train Series to match the order of rows in the sorted X_train DataFrame\n",
    "y_train = y_train.reindex(X_train.index)\n",
    "\n",
    "# Sort the X_test DataFrame based on the \"datetime\" column in ascending order\n",
    "X_test = X_test.sort_values(\"date\")\n",
    "# Reindex the y_test Series to match the order of rows in the sorted X_test DataFrame\n",
    "y_test = y_test.reindex(X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e10eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['y'] = y_train\n",
    "X_train['ds'] = X_train.date\n",
    "X_train['ds'] = pd.to_datetime(X_train.ds)\n",
    "X_train['ds'] = X_train.ds.map(lambda x: x.replace(tzinfo=None))\n",
    "X_train.drop(columns=[\"date\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbb7b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['ds'] = X_test.date\n",
    "X_test['ds'] = pd.to_datetime(X_test.ds)\n",
    "X_test['ds'] = X_test.ds.map(lambda x: x.replace(tzinfo=None))\n",
    "X_test.drop(columns=[\"date\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3847431e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üß¨ Modeling</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d639b394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Prophet model with the appropriate seasonalities\n",
    "model = Prophet(\n",
    "    daily_seasonality=False,\n",
    "    weekly_seasonality=True,\n",
    "    yearly_seasonality=True,\n",
    ")\n",
    "\n",
    "# Add monthly seasonality with a period of 30.5 days (average length of a month)\n",
    "model.add_seasonality(\n",
    "    name='monthly', \n",
    "    period=30.5, \n",
    "    fourier_order=5,\n",
    "    mode='additive',\n",
    ")\n",
    "\n",
    "# Add the additional regressors\n",
    "additional_regressors = [\n",
    "    'age_at_list_registration','cpra', 'hla_a1', 'hla_a2', 'hla_b1', 'hla_b2', 'hla_dr1', 'hla_dr2',\n",
    "]\n",
    "\n",
    "for regressor in additional_regressors:\n",
    "    model.add_regressor(regressor)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce527621",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = model.predict(X_test)\n",
    "\n",
    "# Summarize the forecast\n",
    "print(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head())\n",
    "\n",
    "# Plot the forecast\n",
    "fig = model.plot(forecast)\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4217c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8701339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MAE between expected and predicted values for december\n",
    "y_pred = forecast['yhat']\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('MAE: %.3f' % mae)\n",
    "# plot expected vs actual\n",
    "\n",
    "metrics = {\n",
    "    \"mae\": round(mae,2)\n",
    "}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6cfd10",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">‚öôÔ∏è Model Schema</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf4bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "# Define the input schema using the values of X_test\n",
    "input_schema = Schema(X_test.values)\n",
    "\n",
    "# Define the output schema using y_train\n",
    "output_schema = Schema(y_train)\n",
    "\n",
    "# Create a ModelSchema object specifying the input and output schemas\n",
    "model_schema = ModelSchema(\n",
    "    input_schema=input_schema, \n",
    "    output_schema=output_schema,\n",
    ")\n",
    "\n",
    "# Convert the model schema to a dictionary for further inspection or serialization\n",
    "model_schema.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a92ddd",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üìù Register model</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbc8bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory where the model will be saved\n",
    "model_dir = \"forecast_model\"\n",
    "\n",
    "# Check if the directory exists, and create it if it doesn't\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "# Save the trained model using joblib\n",
    "with open(model_dir + '/serialized_model.json', 'w') as fout:\n",
    "    fout.write(model_to_json(model))  # Save model\n",
    "    \n",
    "# Save the confusion matrix plot as an image file in the 'iris_model' directory\n",
    "fig.savefig(model_dir + \"/forecast.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707022f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model registry\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# Create a new model in the model registry\n",
    "forecast_model = mr.python.create_model(\n",
    "    name=\"waiting_time_forecast_model\",   # Name for the model\n",
    "    metrics=metrics,                      # Metrics used for evaluation\n",
    "    model_schema=model_schema,            # Schema defining the model's input and output\n",
    "    input_example=X_test.sample(),        # Example input data for reference\n",
    "    description=\"Waiting time for a deceased donor kidney transplant forecasting model\",  # Description of the model\n",
    ")\n",
    "\n",
    "# Save the model to the specified directory\n",
    "forecast_model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db0bf98",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
