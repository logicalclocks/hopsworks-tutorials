{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"../images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 02: Training Pipeline</span>\n",
    "\n",
    "\n",
    "<span style=\"font-width:bold; font-size: 1.4rem;\">This notebook explains how to read from a feature group, create training dataset within the feature store, train a model and save it to model registry.</span>\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into the following sections:\n",
    "\n",
    "1. Fetch Feature Groups.\n",
    "2. Define Transformation functions.\n",
    "3. Create Feature Views.\n",
    "4. Create Training Dataset with training, validation and test splits.\n",
    "5. Train the model.\n",
    "6. Register model in Hopsworks Model Registry.\n",
    "7. Create the Deployment.\n",
    "\n",
    "![part2](../images/02_training-dataset.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U xgboost --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Mute warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üì° Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-21 13:50:30,270 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://hopsworks.ai.local/p/120\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üî™ Feature Selection </span>\n",
    "\n",
    "You will start by selecting all the features you want to include for model training/inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-21 13:50:30,997 INFO: Using ['tid', 'amount', 'country', 'fraud_label', 'loc_delta_t_plus_1', 'loc_delta_t_minus_1', 'time_delta_t_minus_1'] from feature group `transactions_fraud_online_fg` as features for the query. To include primary key and event time use `select_all`.\n",
      "2025-11-21 13:50:30,997 INFO: Using ['gender'] from feature group `profile_fraud_online_fg` as features for the query. To include primary key and event time use `select_all`.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve feature groups.\n",
    "trans_fg = fs.get_feature_group(\n",
    "    name='transactions_fraud_online_fg', \n",
    "    version=1,\n",
    ")\n",
    "profile_online_fg = fs.get_feature_group(\n",
    "    name='profile_fraud_online_fg', \n",
    "    version=1,\n",
    ")\n",
    "\n",
    "# Select features for training dataset\n",
    "selected_features = trans_fg.select_features().join(profile_online_fg.select_features())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this if you would like to view your selected features\n",
    "# selected_features.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that you computed the features in `transactions_fraud_online_fg`. If you had created multiple feature groups with identical schema for different window lengths, and wanted to include them in the join you would need to include a prefix argument in the join to avoid feature name clash. See the [documentation](https://docs.hopsworks.ai/feature-store-api/latest/generated/api/query_api/#join) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> ü§ñ Transformation Functions </span>\n",
    "\n",
    "\n",
    "You will preprocess our data using *min-max scaling* on numerical features and *label encoding* on categorical features. To do this you simply define a mapping between our features and transformation functions. This ensures that transformation functions such as *min-max scaling* are fitted only on the training data (and not the validation/test data), which ensures that there is no data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import transformation functions from Hopsworks.\n",
    "from hopsworks.hsfs.builtin_transformations import label_encoder\n",
    "\n",
    "# Map features to transformation functions.\n",
    "transformation_functions = [\n",
    "    label_encoder(\"country\"),\n",
    "    label_encoder(\"gender\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚öôÔ∏è Feature View Creation </span>\n",
    "\n",
    "The Feature Views allows schema in form of a query with filters, define a model target feature/label and additional transformation functions.\n",
    "In order to create or get a Feature View you may use `fs.get_or_create_feature_view()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view created successfully, explore it at \n",
      "https://hopsworks.ai.local/p/120/fs/68/fv/transactions_fraud_online_fv/version/1\n"
     ]
    }
   ],
   "source": [
    "# Get or create the 'transactions_fraud_online_fv' feature view\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name='transactions_fraud_online_fv',\n",
    "    version=1,\n",
    "    query=selected_features,\n",
    "    labels=[\"fraud_label\"],\n",
    "    transformation_functions=transformation_functions,\n",
    "    inference_helper_columns=[\"tid\"],\n",
    "    logging_enabled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è Training Dataset </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.85s) \n",
      "2025-11-21 13:50:42,896 INFO: Profiling dataframe in Python Engine\n",
      "2025-11-21 13:50:44,491 INFO: Profiling dataframe in Python Engine\n",
      "2025-11-21 13:50:44,537 INFO: Profiling dataframe in Python Engine\n",
      "2025-11-21 13:50:44,852 WARNING: VersionWarning: Incremented version to `1`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training/Test splits, datasets creation. Using timerange arguments.\n",
    "train_start = \"2022/01/01\"\n",
    "train_end = \"2022/03/10\"\n",
    "test_start = \"2022/03/10\"\n",
    "test_end = \"2022/03/31\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = feature_view.train_test_split(\n",
    "    train_start=train_start,\n",
    "    train_end=train_end,\n",
    "    test_start=test_start,\n",
    "    test_end=test_end,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>loc_delta_t_plus_1</th>\n",
       "      <th>loc_delta_t_minus_1</th>\n",
       "      <th>time_delta_t_minus_1</th>\n",
       "      <th>label_encoder_country_</th>\n",
       "      <th>label_encoder_gender_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>510.90</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.89</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.28</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.244046</td>\n",
       "      <td>3.231134</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.56</td>\n",
       "      <td>0.244046</td>\n",
       "      <td>0.087633</td>\n",
       "      <td>0.553877</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>752.57</td>\n",
       "      <td>0.087633</td>\n",
       "      <td>2.417108</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365107</th>\n",
       "      <td>1.78</td>\n",
       "      <td>0.177518</td>\n",
       "      <td>0.177387</td>\n",
       "      <td>0.380405</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365108</th>\n",
       "      <td>25.77</td>\n",
       "      <td>0.177387</td>\n",
       "      <td>0.221254</td>\n",
       "      <td>0.234132</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365109</th>\n",
       "      <td>91.63</td>\n",
       "      <td>0.221254</td>\n",
       "      <td>0.273620</td>\n",
       "      <td>0.182662</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365110</th>\n",
       "      <td>1.87</td>\n",
       "      <td>0.273620</td>\n",
       "      <td>0.195295</td>\n",
       "      <td>0.208206</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365111</th>\n",
       "      <td>738.82</td>\n",
       "      <td>0.195295</td>\n",
       "      <td>0.313242</td>\n",
       "      <td>0.023032</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316206 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        amount  loc_delta_t_plus_1  loc_delta_t_minus_1  time_delta_t_minus_1  \\\n",
       "0       510.90            0.000000             0.000112              0.958333   \n",
       "1        21.89            0.000112             0.000127              0.958333   \n",
       "2        11.28            0.000127             0.244046              3.231134   \n",
       "3        27.56            0.244046             0.087633              0.553877   \n",
       "4       752.57            0.087633             2.417108              0.166667   \n",
       "...        ...                 ...                  ...                   ...   \n",
       "365107    1.78            0.177518             0.177387              0.380405   \n",
       "365108   25.77            0.177387             0.221254              0.234132   \n",
       "365109   91.63            0.221254             0.273620              0.182662   \n",
       "365110    1.87            0.273620             0.195295              0.208206   \n",
       "365111  738.82            0.195295             0.313242              0.023032   \n",
       "\n",
       "        label_encoder_country_  label_encoder_gender_  \n",
       "0                          111                      1  \n",
       "1                          111                      1  \n",
       "2                          111                      1  \n",
       "3                          111                      1  \n",
       "4                          111                      1  \n",
       "...                        ...                    ...  \n",
       "365107                     111                      1  \n",
       "365108                     111                      1  \n",
       "365109                     111                      1  \n",
       "365110                     111                      1  \n",
       "365111                     111                      1  \n",
       "\n",
       "[316206 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature view and training dataset are now visible in the UI\n",
    "\n",
    "![fg-overview](../../../images/fv_overview.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fraud_label\n",
       "0              0.996458\n",
       "1              0.003542\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the normalized value counts of the training labels (y_train)\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the distribution is extremely skewed, which is natural considering that fraudulent transactions make up a tiny part of all transactions. Thus you should somehow address the class imbalance. There are many approaches for this, such as weighting the loss function, over- or undersampling, creating synthetic data, or modifying the decision threshold. In this example, you will use the simplest method which is to just supply a class weight parameter to our learning algorithm. The class weight will affect how much importance is attached to each class, which in our case means that higher importance will be placed on positive (fraudulent) samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üß¨ Modeling</span>\n",
    "\n",
    "Next you will train a model. Here, you set larger class weight for the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an XGBoost classifier\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "# Train the classifier using the training features (X_train) and labels (y_train)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the training set\n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "# Predict the test set\n",
    "y_pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1_score': 1.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute f1 score\n",
    "metrics = {\n",
    "    \"f1_score\": f1_score(y_test, y_pred_test, average='macro')\n",
    "}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40229     0]\n",
      " [    0     0]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix for the test set predictions\n",
    "results = confusion_matrix(\n",
    "    y_test, \n",
    "    y_pred_test, \n",
    "    labels=[False, True],\n",
    ")\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üìù Register model</span>\n",
    "\n",
    "One of the features in Hopsworks is the model registry. This is where we can store different versions of models and compare their performance. Models from the registry can then be served as API endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model directory\n",
    "model_dir = \"fraud_online_model\"\n",
    "images_dir = os.path.join(model_dir, \"images\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(images_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fraud_online_model/xgboost_fraud_online_model.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained XGBoost model\n",
    "joblib.dump(model, os.path.join(model_dir, \"xgboost_fraud_online_model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the confusion matrix results\n",
    "df_cm = pd.DataFrame(\n",
    "    results, \n",
    "    ['True Normal', 'True Fraud'],\n",
    "    ['Pred Normal', 'Pred Fraud']\n",
    ")\n",
    "\n",
    "# Create and save the confusion matrix heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = sns.heatmap(\n",
    "    df_cm, \n",
    "    annot=True,\n",
    "    fmt='d',                 # Use integer format for numbers\n",
    "    cmap='RdPu',             # Use a color palette that works well for binary classification\n",
    "    annot_kws={'size': 12},  # Increase annotation text size\n",
    "    cbar=True                # Include color bar\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Confusion Matrix for Fraud Detection')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "# Adjust layout and save\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(images_dir, \"confusion_matrix.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a8caa3494c4a8abd1579a2dbbbef32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://hopsworks.ai.local/p/120/models/xgboost_fraud_online_model/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'xgboost_fraud_online_model', version: 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the model registry\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# Create a Python model in the model registry\n",
    "fraud_model = mr.python.create_model(\n",
    "    name=\"xgboost_fraud_online_model\", \n",
    "    description=\"Fraud Online Predictor\", # Add a description for the model\n",
    "    metrics=metrics,                      # Specify the metrics used to evaluate the model\n",
    "    input_example=[4467360740682089],     # Example input for testing deployments\n",
    "    feature_view=feature_view,            # Add a feature view to the model\n",
    ")\n",
    "\n",
    "# Save the model to the specified model directory\n",
    "fraud_model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <a class=\"anchor\" id=\"1.5_bullet\" style=\"color:#ff5f27\"> üöÄ Model Deployment</a>\n",
    "\n",
    "\n",
    "### About Model Serving\n",
    "Models can be served via KFServing or \"default\" serving, which means a Docker container exposing a Flask server. For KFServing models, or models written in Tensorflow, you do not need to write a prediction file (see the section below). However, for sklearn models using default serving, you do need to proceed to write a prediction file.\n",
    "\n",
    "In order to use KFServing, you must have Kubernetes installed and enabled on your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">üìé Predictor script for Python models</span>\n",
    "\n",
    "\n",
    "Scikit-learn and XGBoost models are deployed as Python models, in which case you need to provide a **Predict** class that implements the **predict** method. The **predict()** method invokes the model on the inputs and returns the prediction as a list.\n",
    "\n",
    "The **init()** method is run when the predictor is loaded into memory, loading the model from the local directory it is materialized to, *ARTIFACT_FILES_PATH*.\n",
    "\n",
    "The directive \"%%writefile\" writes out the cell before to the given Python file. We will use the **predict_example.py** file to create a deployment for our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting predict_example.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predict_example.py\n",
    "import os\n",
    "import numpy as np\n",
    "import hopsworks\n",
    "import joblib\n",
    "\n",
    "\n",
    "class Predict(object):\n",
    "\n",
    "    def __init__(self, async_logger, model):\n",
    "        \"\"\" Initializes the serving state, reads a trained model\"\"\"        \n",
    "        # Get feature store handle\n",
    "        project = hopsworks.login()\n",
    "        self.mr = project.get_model_registry()\n",
    "\n",
    "        # Retrieve the feature view from the model\n",
    "        retrieved_model = self.mr.get_model(\n",
    "            name=\"xgboost_fraud_online_model\",\n",
    "            version=1,\n",
    "        )\n",
    "        self.feature_view = retrieved_model.get_feature_view()\n",
    "        \n",
    "        # Initialize serving and async feature logging\n",
    "        self.feature_view.init_serving(feature_logger=async_logger)\n",
    "\n",
    "        # Load the trained model\n",
    "        self.hopsworks_model = model\n",
    "\n",
    "        self.model = joblib.load(os.environ[\"MODEL_FILES_PATH\"] + \"/xgboost_fraud_online_model.pkl\")\n",
    "\n",
    "        print(\"Initialization Complete\")\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\" Serves a prediction request usign a trained model\"\"\"\n",
    "        feature_vector = self.feature_view.get_feature_vector({\"cc_num\": inputs[0][0]}, logging_data=True)   \n",
    "        prediction = self.model.predict(np.asarray(feature_vector).reshape(1, -1)).tolist() # Numpy Arrays are not JSON serializable\n",
    "        self.feature_view.log(feature_vector,\n",
    "            predictions=prediction,\n",
    "            model=self.hopsworks_model)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wonder why we use the path Models/fraud_tutorial_model/1/model.pkl, it is useful to know that the Data Sets tab in the Hopsworks UI lets you browse among the different files in the project. Registered models will be found underneath the Models directory. Since you saved you model with the name fraud_tutorial_model, that's the directory you should look in. 1 is just the version of the model you want to deploy.\n",
    "\n",
    "This script needs to be put into a known location in the Hopsworks file system. Let's call the file predict_example.py and put it in the Models directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70572426f1c430da8ed15e6bc89e9e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /hopsfs/Jupyter/hopsworks-tutorials/real-time-ai-systems/fraud_online/predict_example.py: 0.000%|   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the dataset API for the current project\n",
    "dataset_api = project.get_dataset_api()\n",
    "\n",
    "# Specify the local file path of the Python script to be uploaded\n",
    "local_script_path = \"predict_example.py\"\n",
    "\n",
    "# Upload the Python script to the \"Models\", and overwrite if it already exists\n",
    "uploaded_file_path = dataset_api.upload(local_script_path, \"Models\", overwrite=True)\n",
    "\n",
    "# Create the full path to the uploaded script for future reference\n",
    "predictor_script_path = os.path.join(\"/Projects\", project.name, uploaded_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the deployment\n",
    "Here, you fetch the model you want from the model registry and define a configuration for the deployment. For the configuration, you need to specify the serving type (default or KFserving)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment created, explore it at https://hopsworks.ai.local/p/120/deployments/18\n",
      "Before making predictions, start the deployment by using `.start()`\n"
     ]
    }
   ],
   "source": [
    "# Deploy the fraud model\n",
    "deployment = fraud_model.deploy(\n",
    "    name=\"fraudonlinemodeldeployment\",  # Specify a name for the deployment\n",
    "    script_file=predictor_script_path,  # Provide the path to the Python script for prediction\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment: fraudonlinemodeldeployment\n",
      "{\n",
      "    \"api_protocol\": \"REST\",\n",
      "    \"batching_configuration\": {\n",
      "        \"batching_enabled\": false\n",
      "    },\n",
      "    \"config_file\": null,\n",
      "    \"created\": \"2025-11-21T13:51:07.000Z\",\n",
      "    \"creator\": \"Admin Admin\",\n",
      "    \"description\": null,\n",
      "    \"id\": 18,\n",
      "    \"inference_logging\": \"NONE\",\n",
      "    \"model_framework\": \"PYTHON\",\n",
      "    \"model_name\": \"xgboost_fraud_online_model\",\n",
      "    \"model_path\": \"/Projects/happening_example/Models/xgboost_fraud_online_model\",\n",
      "    \"model_server\": \"PYTHON\",\n",
      "    \"model_version\": 1,\n",
      "    \"name\": \"fraudonlinemodeldeployment\",\n",
      "    \"predictor\": \"predict_example.py\",\n",
      "    \"predictor_resources\": {\n",
      "        \"limits\": {\n",
      "            \"cores\": 2,\n",
      "            \"gpus\": 0,\n",
      "            \"memory\": 1024\n",
      "        },\n",
      "        \"requests\": {\n",
      "            \"cores\": 0.2,\n",
      "            \"gpus\": 0,\n",
      "            \"memory\": 32\n",
      "        }\n",
      "    },\n",
      "    \"project_namespace\": \"happening-example\",\n",
      "    \"requested_instances\": 1,\n",
      "    \"serving_tool\": \"KSERVE\",\n",
      "    \"version\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print the name of the deployment\n",
    "print(\"Deployment: \" + deployment.name)\n",
    "\n",
    "# Display information about the deployment\n",
    "deployment.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The deployment has now been registered. However, to start it you need to run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6527830278c4ee697935ab66e29000f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start making predictions by using `.predict()`\n"
     ]
    }
   ],
   "source": [
    "# Start the deployment and wait for it to be in a running state for up to 300 seconds\n",
    "deployment.start(await_running=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"available_instances\": 1,\n",
      "    \"condition\": {\n",
      "        \"reason\": \"Deployment is ready\",\n",
      "        \"status\": true,\n",
      "        \"type\": \"READY\"\n",
      "    },\n",
      "    \"deployed\": \"2025-11-21T13:51:08.000Z\",\n",
      "    \"hopsworks_inference_path\": \"/project/120/inference/serving/fraudonlinemodeldeployment\",\n",
      "    \"model_server_inference_path\": \"/v1/models/fraudonlinemodeldeployment\",\n",
      "    \"revision\": \"21592840\",\n",
      "    \"status\": \"Running\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Get the current state of the deployment\n",
    "deployment.get_state().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explore all the logs and filters in the Kibana logs at https://hopsworks.ai.local/p/120/deployments/18\n",
      "\n",
      "DeployableComponentLogs(instance_name: 'fraudonlinemodeldeployment-predictor-00001-deployment-894885zkh', date: datetime.datetime(2025, 11, 21, 13, 51, 43, 486760)) \n",
      "WARNING:py.warnings:DeprecationWarning: websockets.server.WebSocketServerProtocol is deprecated\n",
      "\n",
      "2025-11-21 13:51:30.691 uvicorn.error INFO:     Started server process [8]\n",
      "2025-11-21 13:51:30.691 uvicorn.error INFO:     Waiting for application startup.\n",
      "2025-11-21 13:51:30.694 8 kserve INFO [server.py:start():68] Starting gRPC server on [::]:8081\n",
      "2025-11-21 13:51:30.694 uvicorn.error INFO:     Application startup complete.\n",
      "2025-11-21 13:51:30.694 uvicorn.error INFO:     Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)\n",
      "2025-11-21 13:51:38.509 uvicorn.access INFO:     127.0.0.1:53888 8 - \"GET /metrics HTTP/1.1\" 200 OK\n",
      "2025-11-21 13:51:38.509 kserve.trace kserve.io.kserve.protocol.rest.server.metrics_handler: 0.0014011859893798828 ['http_status:200', 'http_method:GET', 'time:wall']\n",
      "2025-11-21 13:51:38.509 kserve.trace kserve.io.kserve.protocol.rest.server.metrics_handler: 0.001366999999999674 ['http_status:200', 'http_method:GET', 'time:cpu']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To troubleshoot you can use `get_logs()` method\n",
    "deployment.get_logs(component='predictor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Deployment\n",
    "To stop the deployment you simply run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the deployment and wait for it to be in a stopped state for up to 180 seconds\n",
    "deployment.stop(await_stopped=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 03: Inference Pipeline</span>\n",
    "\n",
    "In the following notebook you will use your model for Serving Vector Inference.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
