{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b54564ad",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"../../images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 03: Training Dataset and Modeling</span>\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/logicalclocks/hopsworks-tutorials/blob/master/advanced_tutorials/air_quality/3_training_dataset_and_modeling.ipynb)\n",
    "\n",
    "<span style=\"font-width:bold; font-size: 1.4rem;\">This notebook explains how to read from a feature group, create a feature view and training dataset within the feature store, train a model and register it in model registry.</span>\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into the following sections:\n",
    "\n",
    "1. Fetch Feature Groups.\n",
    "2. Define Transformation functions.\n",
    "3. Create Feature Views.\n",
    "4. Create Training Dataset with training, validation and test splits.\n",
    "5. Loading the training data.\n",
    "6. Train the model.\n",
    "7. Register model in Hopsworks model registry.\n",
    "\n",
    "![part2](../../images/02_training-dataset.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba14b392",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af93b242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cf167f",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üì° Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc38890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d9f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_fg = fs.get_or_create_feature_group(\n",
    "    name = 'air_quality_fg',\n",
    "    version = 1\n",
    ")\n",
    "\n",
    "weather_fg = fs.get_or_create_feature_group(\n",
    "    name = 'weather_fg',\n",
    "    version = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b17b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = air_quality_fg.select_all().join(weather_fg.select_all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f25bf0d",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> üñç Feature View Creation and Retrieving </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36131fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = air_quality_fg.select_all().join(weather_fg.select_all())\n",
    "\n",
    "query_5_records = query.show(5)\n",
    "col_names = query_5_records.columns\n",
    "\n",
    "query_5_records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149d7282",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">üßëüèª‚Äçüî¨ Transformation functions</span>\n",
    "\n",
    "Hopsworks Feature Store provides functionality to attach transformation functions to training datasets.\n",
    "\n",
    "Hopsworks Feature Store also comes with built-in transformation functions such as `min_max_scaler`, `standard_scaler`, `robust_scaler` and `label_encoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66bb623",
   "metadata": {},
   "outputs": [],
   "source": [
    "[t_func.name for t_func in fs.get_transformation_functions()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dba0c6",
   "metadata": {},
   "source": [
    "You can retrieve transformation function you need.\n",
    "\n",
    "To attach transformation function to training dataset provide transformation functions as dict, where key is feature name and value is online transformation function name.\n",
    "\n",
    "Also training dataset must be created from the Query object. Once attached transformation function will be applied on whenever save, insert and get_serving_vector methods are called on training dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89002ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_cols = ['city','conditions']\n",
    "\n",
    "le = fs.get_transformation_function(name='label_encoder') \n",
    "\n",
    "transformation_functions = {\n",
    "    col: le\n",
    "    for col \n",
    "    in category_cols\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530439a4",
   "metadata": {},
   "source": [
    "`Feature Views` stands between **Feature Groups** and **Training Dataset**. –°ombining **Feature Groups** we can create **Feature Views** which store a metadata of our data. Having **Feature Views** we can create **Training Dataset**.\n",
    "\n",
    "The Feature Views allows schema in form of a query with filters, define a model target feature/label and additional transformation functions.\n",
    "\n",
    "In order to create Feature View we can use `FeatureStore.get_or_create_feature_view()` method.\n",
    "\n",
    "You can specify next parameters:\n",
    "\n",
    "- `name` - name of a feature group.\n",
    "\n",
    "- `version` - version of a feature group.\n",
    "\n",
    "- `labels`- our target variable.\n",
    "\n",
    "- `transformation_functions` - functions to transform our features.\n",
    "\n",
    "- `query` - query object with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8810e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.get_or_create_feature_view(name=\"air_quality_fv\",\n",
    "                                             version=1,\n",
    "                                             transformation_functions=transformation_functions,\n",
    "                                             query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8103228",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è Training Dataset Creation</span>\n",
    "\n",
    "In Hopsworks training data is a query where the projection (set of features) is determined by the parent FeatureView with an optional snapshot on disk of the data returned by the query.\n",
    "\n",
    "**Training Dataset  may contain splits such as:** \n",
    "* Training set - the subset of training data used to train a model.\n",
    "* Validation set - the subset of training data used to evaluate hparams when training a model\n",
    "* Test set - the holdout subset of training data used to evaluate a mode\n",
    "\n",
    "To create training dataset we use `FeatureView.create_training_data()` method.\n",
    "\n",
    "Here are some importand things:\n",
    "\n",
    "- It will inherit the name of FeatureView.\n",
    "\n",
    "- The feature store currently supports the following data formats for\n",
    "training datasets: **tfrecord, csv, tsv, parquet, avro, orc**.\n",
    "\n",
    "- We can choose necessary format using **data_format** parameter.\n",
    "\n",
    "- **start_time** and **end_time** in order to filter dataset in specific time range.\n",
    "\n",
    "- We can create **train, test** splits using `create_train_test_split()`. \n",
    "\n",
    "- We can create **train,validation, test** splits using `create_train_validation_test_splits()` methods.\n",
    "\n",
    "- The only thing is that we should specify desired ratio of splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9736185a-cb29-44b1-9bac-d8b28fa062d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_version, td_job = feature_view.create_training_data(\n",
    "    description='Ait Quality Project dataset',\n",
    "    data_format='csv',\n",
    "    write_options={'wait_for_job': True},\n",
    "    coalesce=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dddfe5",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\">ü™ù Training Dataset Retrieval</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06836b5-21c6-4161-89f5-9fbeae91d58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = feature_view.get_training_data(\n",
    "    training_dataset_version=td_version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3651f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acddd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0148abf",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\">üß¨ Modeling</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bafd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_line = int(X.shape[0] * 0.75)\n",
    "\n",
    "X_train = X.iloc[:split_line]\n",
    "X_test = X.iloc[split_line:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4518b240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.sort_values(by=[\"date\", 'city'], ascending=[False, True]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a805a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13c7591",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.groupby('city')['aqi'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ed009c-568b-4dc7-88fb-2fd77d51f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.sort_values(by=[\"date\", 'city'], ascending=[False, True]).reset_index(drop=True)\n",
    "X_train[\"aqi_next_day\"] = X_train.groupby('city')['aqi'].shift(1)\n",
    "\n",
    "X_test = X_test.sort_values(by=[\"date\", 'city'], ascending=[False, True]).reset_index(drop=True)\n",
    "X_test[\"aqi_next_day\"] = X_test.groupby('city')['aqi'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda60d53-a3fa-434f-9377-bc2e98be26f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=[\"date\"]).fillna(0)\n",
    "y_train = X_train.pop(\"aqi_next_day\")\n",
    "\n",
    "X_test = X_test.drop(columns=[\"date\"]).fillna(0)\n",
    "y_test = X_test.pop(\"aqi_next_day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3eb53d-4c13-4b65-9d5f-b2e9de856347",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\">üß¨ Modeling</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f595f6-7c11-4ce6-9194-16c522350b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = xgb.XGBRegressor()\n",
    "\n",
    "regressor.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e824b762",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìê Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f15dbeb-7fbc-461a-a712-4da59621dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "xgb_mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"XGBRegressor MAE:\", xgb_mae)\n",
    "\n",
    "metrics = {\n",
    "    'mae': xgb_mae\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23944997",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(12,5))\n",
    "\n",
    "x_ax = range(len(y_test))\n",
    "ax = plt.scatter(x_ax, y_test, s=5, color=\"blue\", label=\"original\")\n",
    "ax = plt.plot(x_ax, y_pred, lw=0.8, color=\"red\", label=\"predicted\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Regression Quality',fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c38c62",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style='color:#ff5f27'>üóÑ Model Registry</span>\n",
    "\n",
    "One of the features in Hopsworks is the model registry. This is where you can store different versions of models and compare their performance. Models from the registry can then be served as API endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838c0514",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937d7bfd",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">‚öôÔ∏è Model Schema</span>\n",
    "\n",
    "The model needs to be set up with a [Model Schema](https://docs.hopsworks.ai/machine-learning-api/latest/generated/model_schema/), which describes the inputs and outputs for a model.\n",
    "\n",
    "A Model Schema can be automatically generated from training examples, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad379589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "input_schema = Schema(X)\n",
    "output_schema = Schema(y)\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)\n",
    "\n",
    "model_schema.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb75afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir=\"air_quality_model\"\n",
    "if os.path.isdir(model_dir) == False:\n",
    "    os.mkdir(model_dir)\n",
    "    \n",
    "model_path = model_dir + '/air_quality_model.pkl'\n",
    "fig.savefig(model_dir + '/regression_quality.png') # save plot also\n",
    "joblib.dump(regressor, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96db7f3b-eeac-461b-84a8-7f7769329786",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mr.python.create_model(\n",
    "    name=\"air_quality_model\",\n",
    "    metrics=metrics,\n",
    "    description=\"XGBoost Regressor.\",\n",
    "    input_example=X_test.sample(),\n",
    "    model_schema=model_schema\n",
    ")\n",
    "\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d92da6-c32c-4d06-a4d9-32db44865e7f",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üóÑ Retrieving model from Model Registry </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b547c721",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_model = mr.get_model(\n",
    "    name=\"air_quality_model\",\n",
    "    version=1\n",
    ")\n",
    "saved_model_dir = retrieved_model.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087c360c-5afa-4d8b-aad2-d271f2341100",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_xgboost_model = joblib.load(saved_model_dir + \"/air_quality_model.pkl\")\n",
    "retrieved_xgboost_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7762145d-2503-4d12-bca6-228cb1623874",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ü§ñ Making the predictions </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cc048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = retrieved_xgboost_model.predict(X_test)\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d5c1aa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <span style=\"color:#ff5f27;\">ü•≥ <b> Next Steps  </b> </span>\n",
    "Congratulations you've now completed the Air Quality tutorial for Managed Hopsworks.\n",
    "\n",
    "Check out our other tutorials on ‚û° https://github.com/logicalclocks/hopsworks-tutorials\n",
    "\n",
    "Or documentation at ‚û° https://docs.hopsworks.ai"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
