{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "636716e7",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 04: Model Training</span>\n",
    "\n",
    "\n",
    "## üóíÔ∏è In this notebook you will see how to create and deploy a model using  Hopsworks Feature Store : \n",
    "\n",
    "1. Loading the training data.\n",
    "2. Train the model.\n",
    "3. Register model in Hopsworks model registry.\n",
    "\n",
    "![part3](images/03_model.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bce35f1",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üîÆ Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef41b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d65895e",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\"> üìù Imports</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b33b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina', quality=100)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9c79b9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\">ü™ù Feature View and Training Dataset Retrieval</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27dc2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.get_feature_view(\n",
    "    name = 'bitcoin_feature_view',\n",
    "    version = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d115c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, _ = feature_view.get_training_data(1)\n",
    "val_x, _ = feature_view.get_training_data(2)\n",
    "test_x, _ = feature_view.get_training_data(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ad4b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_x[[\"close\"]]\n",
    "val_y = val_x[[\"close\"]]\n",
    "test_y = test_x[[\"close\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e668d0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\">ü§ñ Time series model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d35633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets define Tensorflow Dataset as we are going to train keras tensorflow model\n",
    "\n",
    "def windowed_dataset(dataset, target, window_size, batch_size):\n",
    "    ds = dataset.window(window_size, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda x: x.batch(window_size))\n",
    "    ds = ds.map(lambda window: tf.reshape(window[-1:], [-1, 34]))\n",
    "        \n",
    "    target_ds = target.window(window_size, shift=1, drop_remainder=True)\n",
    "    target_ds = target_ds.flat_map(lambda window: window.batch(window_size))\n",
    "    target_ds = target_ds.map(lambda window: window[-1:])\n",
    "    \n",
    "    ds = tf.data.Dataset.zip((ds, target_ds))\n",
    "    ds = ds.batch(batch_size,True)\n",
    "    ds = ds.prefetch(1)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15953ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices(tf.cast(train_x.values, tf.float32)) \n",
    "training_target = tf.data.Dataset.from_tensor_slices(train_y.values.flatten().tolist()) \n",
    "training_dataset = training_dataset.repeat(500)\n",
    "training_dataset = windowed_dataset(training_dataset, training_target, window_size=2, batch_size=16)\n",
    "training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420a12ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = tf.data.Dataset.from_tensor_slices(tf.cast(val_x.values, tf.float32))\n",
    "validation_target = tf.data.Dataset.from_tensor_slices(val_y.values.flatten().tolist()) \n",
    "training_dataset = training_dataset.repeat(500)\n",
    "validation_dataset = windowed_dataset(validation_dataset, validation_target, window_size=2, batch_size=16)\n",
    "validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7035b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices(tf.cast(test_x.values, tf.float32))\n",
    "test_target = tf.data.Dataset.from_tensor_slices(test_y.values.flatten().tolist()) \n",
    "test_dataset = windowed_dataset(test_dataset, test_target, window_size=2, batch_size=1)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f18b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim):\n",
    "    inputs = tf.keras.layers.Input(shape=(input_dim[0],input_dim[1]))\n",
    "    x = tf.keras.layers.Conv1D(filters = 128, kernel_size=1, padding='same', kernel_initializer=\"uniform\")(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)    \n",
    "    x = tf.keras.layers.MaxPooling1D(pool_size=2, padding='same')(x)\n",
    "    x = tf.keras.layers.Conv1D(filters = input_dim[1], kernel_size= 1,padding='same',  kernel_initializer=\"uniform\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)    \n",
    "    x = tf.keras.layers.MaxPooling1D(pool_size=2, padding='same')(x)    \n",
    "\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(34, activation=\"relu\", kernel_initializer=\"uniform\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(1, activation=\"relu\", kernel_initializer=\"uniform\")(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    model.summary()\n",
    "    model.compile(loss='mse',optimizer='adam',metrics=['mae'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e611c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model([1, 34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccdce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "start = timer()\n",
    "history = model.fit(training_dataset,\n",
    "                    epochs=100,\n",
    "                    verbose=0,\n",
    "                    steps_per_epoch=500,\n",
    "                    validation_data=validation_dataset,\n",
    "                    validation_steps=1,                    \n",
    "                   )\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b886783",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a31cbc",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'>üëÆüèª‚Äç‚ôÇÔ∏è Model Validation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a32fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = history_dict['mae']\n",
    "val_loss_values = history_dict['val_mae']\n",
    "\n",
    "loss_values50 = loss_values\n",
    "val_loss_values50 = val_loss_values\n",
    "epochs = range(1, len(loss_values50) + 1)\n",
    "plt.plot(epochs, loss_values50, 'b',color = 'blue', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values50, 'b',color='red', label='Validation loss')\n",
    "plt.rc('font', size = 18)\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.xticks(epochs)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15,7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd06ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_close = model.predict(test_x.values.reshape(-1, 1, 34))\n",
    "plt.plot(prediction_close,color='red', label='prediction_test')\n",
    "plt.plot(test_y.values, color='blue', label='prediction actual')\n",
    "plt.xlabel('No. of Trading Days')\n",
    "plt.ylabel('Close Value (scaled)')\n",
    "plt.legend(loc='upper left')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a2440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "metrics.mean_absolute_error(test_y,prediction_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70070d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['darkslategrey']\n",
    "\n",
    "fig=plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "\n",
    "ax.plot(test_y, 'black')\n",
    "ax.plot(prediction_close, 'yellow')\n",
    "ax.set_ylabel('$price$')\n",
    "ax.set_xlabel('$time$')\n",
    "ax.grid(True)\n",
    "ax.legend([\"actual\", \"pred\"])\n",
    "ax.set_title(\"Random Forest Regressor\", loc='right')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6ff019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect \n",
    "# Recall that you applied transformation functions, such as min max scaler and laber encoder. \n",
    "# Now you want to transform them back to human readable format.\n",
    "feature_view.init_serving(1)\n",
    "td_transformation_functions = feature_view._single_vector_server._transformation_functions\n",
    "\n",
    "pred_y = pd.DataFrame(prediction_close, columns=[\"close\"])\n",
    "\n",
    "for feature_name in td_transformation_functions:\n",
    "    if feature_name == \"close\":\n",
    "        td_transformation_function = td_transformation_functions[feature_name]\n",
    "        sig, foobar_locals = inspect.signature(td_transformation_function.transformation_fn), locals()\n",
    "        param_dict = dict([(param.name, param.default) for param in sig.parameters.values() if param.default != inspect._empty])\n",
    "        if td_transformation_function.name == \"min_max_scaler\":\n",
    "            pred_y[feature_name] = pred_y[feature_name].map(lambda x: x*(param_dict[\"max_value\"]-param_dict[\"min_value\"])+param_dict[\"min_value\"])\n",
    "            test_y[feature_name] = test_y[feature_name].map(lambda x: x*(param_dict[\"max_value\"]-param_dict[\"min_value\"])+param_dict[\"min_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12954dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['darkslategrey']\n",
    "\n",
    "fig=plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "\n",
    "ax.plot(test_y, 'black')\n",
    "ax.plot(pred_y, 'yellow')\n",
    "ax.set_ylabel('$price$')\n",
    "ax.set_xlabel('$time$')\n",
    "ax.grid(True)\n",
    "ax.legend([\"actual\", \"pred\"])\n",
    "ax.set_title(\"Random Forest Regressor\", loc='right')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe69164",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style='color:#ff5f27'>üëÆüèº‚Äç‚ôÄÔ∏è Model Registry</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7572a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = \"aml_model\"\n",
    "print('Exporting trained model to: {}'.format(export_path))\n",
    "    \n",
    "tf.saved_model.save(model, export_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04b5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = project.get_model_registry()\n",
    "metrics={'loss': history_dict['val_mae'][0]} \n",
    "\n",
    "mr_model = mr.tensorflow.create_model(\n",
    "    name=\"bitcoin_price_model\",\n",
    "    metrics=metrics,\n",
    "    description=\"bitcoin daily price detection model.\",\n",
    "    input_example=[\"1615240800000\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1fd404",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_model.save(export_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1ac90b",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\">üöÄ Model Deployment</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58773c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile btc_model_transformer.py\n",
    "\n",
    "import os\n",
    "import hsfs\n",
    "import numpy as np\n",
    "\n",
    "class Transformer(object):\n",
    "    \n",
    "    def __init__(self):        \n",
    "        # get feature store handle\n",
    "        fs_conn = hsfs.connection()\n",
    "        self.fs = fs_conn.get_feature_store()\n",
    "        \n",
    "        # get feature views\n",
    "        self.fv = self.fs.get_feature_view(\"bitcoin_feature_view\", 1)\n",
    "        \n",
    "        # initialise serving\n",
    "        self.fv.init_serving(1)\n",
    "\n",
    "    def flat2gen(self, alist):\n",
    "        for item in alist:\n",
    "            if isinstance(item, list):\n",
    "                for subitem in item: yield subitem\n",
    "            else:\n",
    "                yield item\n",
    "        \n",
    "    def preprocess(self, inputs):\n",
    "        feature_vector = self.fv.get_feature_vector({\"unix\": inputs[\"inputs\"][0]})\n",
    "        return { \"inputs\" :  np.array(list(self.flat2gen(feature_vector))).reshape(-1, 1, 34).tolist() }\n",
    "\n",
    "    def postprocess(self, outputs):\n",
    "        return outputs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c57f2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from hsml.transformer import Transformer\n",
    "dataset_api = project.get_dataset_api()\n",
    "\n",
    "uploaded_file_path = dataset_api.upload(\"btc_model_transformer.py\", \"Models\", overwrite=True)\n",
    "transformer_script_path = os.path.join(\"/Projects\", project.name, uploaded_file_path)\n",
    "transformer_script = Transformer(script_file=transformer_script_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9124a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model name from the previous notebook.\n",
    "model = mr.get_model(\"bitcoin_price_model\", version = 1)\n",
    "\n",
    "deployment = model.deploy(\n",
    "    name=\"btcmodeldeployment\",\n",
    "    model_server=\"TENSORFLOW_SERVING\", \n",
    "    serving_tool=\"KSERVE\",\n",
    "    transformer=transformer_script\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494536d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Deployment: \" + deployment.name)\n",
    "deployment.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf25c66",
   "metadata": {},
   "source": [
    "The deployment has now been registered. However, to start it you need to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc35a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dd9f27",
   "metadata": {},
   "source": [
    "For trouble shooting one can use get_logs method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a398e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef43555",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\">üîÆ Predicting</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021e1292",
   "metadata": {},
   "source": [
    "Using the deployment let's use the input example that we registered together with the model to query the deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c380deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"inputs\": model.input_example\n",
    "}\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b341cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb49d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For trouble shooting one you can use get_logs method.\n",
    "deployment.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c174e6f5",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
