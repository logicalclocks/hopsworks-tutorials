{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df2ee018",
   "metadata": {},
   "source": [
    "# A Guide for Llama3.1 8B-Instruct on Hopsworks\n",
    "\n",
    "For details about this Large Language Model (LLM) visit the model page in the HuggingFace repository ‚û°Ô∏è [link](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191915f4",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£ Download Llama3.1 8B-Instruct using the huggingface_hub library\n",
    "\n",
    "First, we download the Llama3.1 model files (e.g., weights, configuration files) directly from the HuggingFace repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "174751e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31b01df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place your HuggingFace token in the HF_TOKEN environment variable\n",
    "\n",
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = \"<INSERT_YOUR_HF_TOKEN>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b78a085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bedd0a8884e4f48887d2a3d10944592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 14 files:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "llama31_local_dir = snapshot_download(\"meta-llama/Llama-3.1-8B-Instruct\", ignore_patterns=\"original/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865bbd91",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Register Llama3.1 8B-Instruct into Hopsworks Model Registry\n",
    "\n",
    "Once the model files are downloaded from the HuggingFace repository, we can register the models files into the Hopsworks Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b7cba39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-27 14:53:39,802 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://hopsworks.ai.local/p/119\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e005f6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following instantiates a Hopsworks LLM model, not yet saved in the Model Registry\n",
    "\n",
    "llama31 = mr.llm.create_model(\n",
    "    name=\"llama31_instruct\",\n",
    "    description=\"Llama3.1 8B-Instruct model (via HF)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05ed4ee6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3596ef2b3b504ec8b7fcda36b4ddd48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://hopsworks.ai.local/p/119/models/llama31_instruct/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'llama31_instruct', version: 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register the Llama model pointing to the local model files\n",
    "\n",
    "llama31.save(llama31_local_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce98024e",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Deploy Llama3.1 8B-Instruct\n",
    "\n",
    "After registering the LLM model into the Model Registry, we can create a deployment that serves it using the vLLM engine.\n",
    "\n",
    "Hopsworks provides two types of deployments to serve LLMs with the vLLM engine:\n",
    "\n",
    "- **Using the official vLLM OpenAI server**: an OpenAI API-compatible server implemented by the creators of vLLM where the vLLM engine is configured with a user-provided configuration (yaml) file.\n",
    "\n",
    "- **Using the KServe built-in vLLM server**: a KServe-based implementation of an OpenAI API-compatible server for more advanced users who need to provide a predictor script for the initialization of the vLLM engine and (optionally) the implementation of the *completions* and *chat/completions* endpoints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a75117e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-27 14:58:26,221 WARNING: VersionWarning: No version provided for getting model `llama31_instruct`, defaulting to `1`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get a reference to the Llama model if not obtained yet\n",
    "\n",
    "llama31 = mr.get_model(\"llama31_instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9b080ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bd52e2b6884ab180e43f5f8fc55496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/62 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Upload vllm engine config file for the deployments\n",
    "\n",
    "ds_api = project.get_dataset_api()\n",
    "\n",
    "path_to_config_file = f\"/Projects/{project.name}/\" + ds_api.upload(\"llama_vllmconfig.yaml\", \"Resources\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54014afa",
   "metadata": {},
   "source": [
    "### üü® Using KServe vLLM server\n",
    "\n",
    "Create a model deployment by providing a predictor script and (optionally) a configuration file with the arguments for the vLLM engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe74238b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc20d19b7bba42089042d5b6aabfbc7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/1714 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment created, explore it at https://hopsworks.ai.local/p/119/deployments/38\n",
      "Before making predictions, start the deployment by using `.start()`\n"
     ]
    }
   ],
   "source": [
    "# upload predictor script\n",
    "path_to_predictor_script = f\"/Projects/{project.name}/\" + ds_api.upload(\"llama_predictor.py\", \"Resources\", overwrite=True)\n",
    "\n",
    "llama31_depl = llama31.deploy(\n",
    "    name=\"llama31v1\",\n",
    "    description=\"Llama3.1 8B-Instruct from HuggingFace\", \n",
    "    script_file=path_to_predictor_script,\n",
    "    config_file=path_to_config_file,  # optional\n",
    "    resources={\"num_instances\": 1, \"requests\": {\"cores\": 2, \"memory\": 1024*16, \"gpus\": 1}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3e5133",
   "metadata": {},
   "source": [
    "### üü® Using vLLM OpenAI server\n",
    "\n",
    "Create a model deployment by providing a configuration file with the arguments for the vLLM engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d914f7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment created, explore it at https://hopsworks.ai.local/p/119/deployments/39\n",
      "Before making predictions, start the deployment by using `.start()`\n"
     ]
    }
   ],
   "source": [
    "llama31_depl = llama31.deploy(\n",
    "    name=\"llama31v2\",\n",
    "    description=\"Llama3.1 8B-Instruct from HuggingFace\",\n",
    "    config_file=path_to_config_file,\n",
    "    resources={\"num_instances\": 1, \"requests\": {\"cores\": 2, \"memory\": 1024*12, \"gpus\": 1}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8315fe0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d23937ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve one of the deployments created above\n",
    "\n",
    "ms = project.get_model_serving()\n",
    "llama31_depl = ms.get_deployment(\"llama31v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02df5c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76ff714cde74abeb5ea4b97c2f97615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start making predictions by using `.predict()`\n"
     ]
    }
   ],
   "source": [
    "llama31_depl.start(await_running=60*15) # wait for 15 minutes maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "210b7d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama31_depl.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c58b989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictorState(status: 'Running')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama31_depl.get_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d198f9e4",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Prompting Llama3.1 8B-Instruct\n",
    "\n",
    "Once the Llama31 deployment is up and running, we can start sending user prompts to the LLM. You can either use an OpenAI API-compatible client (e.g., openai library) or any other http client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd95dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the istio endpoint from the Llama deployment page in the Hopsworks UI.\n",
    "istio_endpoint = \"<ISTIO_ENDPOINT>\" # with format \"http://<ip-address>\"\n",
    "    \n",
    "# Resolve base uri. NOTE: KServe's vLLM server prepends the URIs with /openai\n",
    "base_uri = \"/openai\" if llama31_depl.predictor.script_file is not None else \"\"\n",
    "\n",
    "openai_v1_uri = istio_endpoint + base_uri + \"/v1\"\n",
    "completions_url = openai_v1_uri + \"/completions\" \n",
    "chat_completions_url = openai_v1_uri + \"/chat/completions\"\n",
    "\n",
    "# Resolve API key for request authentication\n",
    "if \"SERVING_API_KEY\" in os.environ:\n",
    "    # if running inside Hopsworks\n",
    "    api_key_value = os.environ[\"SERVING_API_KEY\"]\n",
    "else:\n",
    "    # Create an API KEY using the Hopsworks UI and place the value below\n",
    "    api_key_value = \"<API_KEY>\"\n",
    "    \n",
    "# Prepare request headers\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': 'ApiKey ' + api_key_value,\n",
    "    'Host': f\"{llama31_depl.name}.{project.name.lower().replace('_', '-')}.hopsworks.ai\", # also provided in the Hopsworks UI\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d78906",
   "metadata": {},
   "source": [
    "### üü® Using httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d3b5073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aad58347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion request:  {'model': 'llama31v2', 'messages': [{'role': 'user', 'content': 'Who is the best French painter. Answer with detailed explanations.'}]}\n",
      "2025-01-27 15:01:45,144 INFO: HTTP Request: POST http://51.89.4.22/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "<Response [200 OK]>\n",
      "Choosing the \"best\" French painter is subjective, as it depends on personal taste and historical context. However, I can provide you with some of the most renowned French painters and highlight their unique contributions to the world of art.\n",
      "\n",
      "1. **Claude Monet** (1840-1926)\n",
      "Monet is often considered one of the greatest French painters. He was a founding member of the Impressionist movement, which emphasized capturing the fleeting effects of light and color in outdoor settings. Monet's brushstrokes were spontaneous and expressive, and he is famous for his series of water lily paintings (Nymph√©as) and his iconic depictions of London's fog-shrouded streets.\n",
      "\n",
      "Monet's innovative techniques and his focus on light, color, and atmosphere paved the way for future generations of artists. His paintings continue to be celebrated for their beauty, simplicity, and emotional resonance.\n",
      "\n",
      "2. **Pierre-Auguste Renoir** (1841-1919)\n",
      "Renoir was another key figure in the Impressionist movement. His paintings are characterized by their warmth, sensitivity, and technical mastery. He was particularly drawn to capturing the beauty of everyday life, from the bustling streets of Paris to the private moments of intimacy among friends and family.\n",
      "\n",
      "Renoir's colorful and expressive portraits, such as \"Dance at Le Moulin de la Galette\" and \"Girl with a Hoop,\" showcase his ability to convey the joy and vitality of life through his art. His influence can be seen in many subsequent artists, from Fauvism to Expressionism.\n",
      "\n",
      "3. **Jean-Honor√© Fragonard** (1732-1806)\n",
      "Fragonard was a Rococo painter known for his delicate and enigmatic depictions of love, nature, and everyday life. His paintings often feature elegant, ornate settings, and his use of pastel colors created a dreamy, ethereal atmosphere.\n",
      "\n",
      "Fragonard's most famous works, such as \"The Happy Accidents of the Swing\" and \"The Stolen Kiss,\" showcase his ability to convey the subtleties of human emotion and the fleeting nature of pleasure. His romantic and idyllic visions of the world have inspired artists for centuries.\n",
      "\n",
      "4. **√âdouard Manet** (1832-1883)\n",
      "Manet was a pioneer of modern art, and his influence can be seen in many subsequent movements, including Impressionism and Expressionism. His paintings often blurred the lines between fine art and popular culture, incorporating elements of everyday life, fashion, and celebrity.\n",
      "\n",
      "Manet's most famous works, such as \"Olympia\" and \"A Bar at the Folies-Berg√®re,\" showcase his ability to challenge traditional notions of beauty and representation. His innovative approach to composition and his use of bold, pure colors paved the way for the development of modern art.\n",
      "\n",
      "5. **Paul C√©zanne** (1839-1906)\n",
      "C√©zanne was a Post-Impressionist painter who redefined the way artists approached representation and color. His paintings often feature complex, layered perspectives, which\n",
      " challenge the viewer to engage with the artwork on multiple levels.\n",
      "\n",
      "C√©zanne's most famous works, such as \"Still Life with Apples\" and \"The Bathers,\" showcase his ability to capture the essence of color and form through sheer painterly bravura. His influence can be seen in many subsequent artists, from Fauvism to Cubism.\n",
      "\n",
      "While it's difficult to identify a single \"best\" French painter, these individuals have greatly contributed to the world of art and continue to inspire and influence artists today.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Chat Completion for a user message\n",
    "#\n",
    "\n",
    "user_message = \"Who is the best French painter. Answer with detailed explanations.\"\n",
    "\n",
    "completion_request = {\n",
    "    \"model\": llama31_depl.name,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_message\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Completion request: \", completion_request, end=\"\\n\")\n",
    "\n",
    "response = httpx.post(chat_completions_url, headers=headers, json=completion_request, timeout=45.0)\n",
    "print(response)\n",
    "print(response.json()[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7923fe72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion request:  {'model': 'llama31v2', 'messages': [{'role': 'user', 'content': 'Hi! How are you doing today?'}, {'role': 'assistant', 'content': \"I'm doing well! How can I help you?\"}, {'role': 'user', 'content': 'Can you tell me what the temperate will be in Dallas, in fahrenheit?'}]}\n",
      "2025-01-27 15:01:50,060 INFO: HTTP Request: POST http://51.89.4.22/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "However, I'm a large language model, I don't have real-time access to current weather information. But I can suggest some options to help you find the current temperature in Dallas, Texas:\n",
      "\n",
      "1. **Check online weather websites**: You can visit websites like weather.com, accuweather.com, or wunderground.com and enter \"Dallas, TX\" in the search bar to get the current temperature.\n",
      "2. **Use a voice assistant**: If you have a smart speaker or virtual assistant like Siri, Google Assistant, or Alexa, you can ask them to give you the current temperature in Dallas.\n",
      "3. **Check a mobile app**: Download a weather app like Dark Sky, Weather Underground, or The Weather Channel, and search for \"Dallas, TX\" to get the current temperature.\n",
      "\n",
      "If you want a general idea of the temperature in Dallas, I can tell you that Dallas has a humid subtropical climate, with hot summers and mild winters. The average high temperature in July (Dallas's hottest month) is around 95¬∞F (35¬∞C), while the average high temperature in January (Dallas's coldest month) is around 53¬∞F (12¬∞C).\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Chat Completion for list of messages\n",
    "#\n",
    "\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Hi! How are you doing today?\"\n",
    "}, {\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": \"I'm doing well! How can I help you?\",\n",
    "}, {\n",
    "    \"role\": \"user\",\n",
    "     \"content\": \"Can you tell me what the temperate will be in Dallas, in fahrenheit?\"\n",
    "}]\n",
    "\n",
    "\n",
    "completion_request = {\n",
    "    \"model\": llama31_depl.name,\n",
    "    \"messages\": messages\n",
    "}\n",
    "\n",
    "print(\"Completion request: \", completion_request, end=\"\\n\")\n",
    "\n",
    "response = httpx.post(chat_completions_url, headers=headers, json=completion_request, timeout=45.0)\n",
    "\n",
    "print(response.json()[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5d4b7a",
   "metadata": {},
   "source": [
    "### üü® Using OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e5ccec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4b1afc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "241e1a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=openai_v1_uri,\n",
    "    api_key=\"X\",\n",
    "    default_headers=headers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a12fda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-27 15:01:59,744 INFO: HTTP Request: POST http://51.89.4.22/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Determining the \"best\" French painter can be subjective as opinions vary based on personal taste and artistic preferences. However, here are some of the most renowned French painters:\n",
      "\n",
      "1. **Claude Monet** (1840-1926): A founder of Impressionism, Monet is famous for his captivating landscapes, water lilies, and sunsets. His soft, dreamy brushstrokes revolutionized the art world.\n",
      "2. **Pierre-Auguste Renoir** (1841-1919): A leading figure in Impressionism, Renoir is celebrated for his vibrant depictions of everyday life, often focusing on the beauty of the human body.\n",
      "3. **Henri Matisse** (1869-1954): A pioneer of Fauvism, Matisse is renowned for his bold, colorful works that blended elements of modern art and craftsmanship. His intricate cut-outs and paper sculptures are highly acclaimed.\n",
      "4. **Paul C√©zanne** (1839-1906): A Post-Impressionist master, C√©zanne played a crucial role in the development of Cubism. His still-life paintings and landscapes feature innovative uses of color and form.\n",
      "5. **Jean-Honor√© Fragonard** (1732-1806): A Rococo painter, Fragonard is famous for his delicate, intimate works that capture the essence of 18th-century French life. His sensual landscapes and exquisite portraits are highly regarded.\n",
      "\n",
      "These artists have made significant contributions to the history of French art, and their works continue to inspire and awe audiences around the world.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Chat Completion for a user message\n",
    "#\n",
    "\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=llama31_depl.name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Who is the best French painter. Answer with a short explanations.\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a26c42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-27 15:02:02,872 INFO: HTTP Request: POST http://51.89.4.22/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "However, I'm a large language model, I don't have real-time access to current weather conditions. Nevertheless, I can suggest some options to find the current temperature in Dallas, Texas:\n",
      "\n",
      "1. Check online weather websites: You can visit websites like weather.com, accuweather.com, or wunderground.com to get the current temperature in Dallas.\n",
      "2. Use a virtual assistant: You can ask virtual assistants like Siri, Google Assistant, or Alexa to provide you with the current temperature in Dallas.\n",
      "3. Check a weather app: You can download a weather app on your smartphone to get the current temperature in Dallas.\n",
      "\n",
      "If you'd like, I can provide you with the average temperature ranges for Dallas during different times of the year.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Chat Completion for list of messages\n",
    "#\n",
    "\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=llama31_depl.name,\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hi! How are you doing today?\"\n",
    "    }, {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"I'm doing well! How can I help you?\",\n",
    "    }, {\n",
    "        \"role\": \"user\",\n",
    "         \"content\": \"Can you tell me what the temperate will be in Dallas, in fahrenheit?\"\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af680e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
