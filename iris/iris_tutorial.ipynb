{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"../images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store Quickstart** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Iris Classification</span>\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/logicalclocks/hopsworks-tutorials/blob/master/iris_tutorial.ipynb)\n",
    "\n",
    "**Note**: you may get an error when installing hopsworks on Colab, and it is safe to ignore it.\n",
    "\n",
    "This is the quickstart tutorial about Hopsworks Feature Store. Here you will work with data related to iris flower classification.\n",
    "\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into next sections:\n",
    "1. Import libraries and connect to Hopsworks Feature Store\n",
    "2. Load the Iris flower dataset\n",
    "3. Create a feature group and upload to the feature store\n",
    "4. Create a feature view from the feature group\n",
    "5. Create a training dataset\n",
    "6. Train a model using XGBoost\n",
    "7. Save the trained model to Hopsworks\n",
    "8. Launch a serving instance.\n",
    "9. Model deployment in Hopsworks\n",
    "10. Send a prediction request to the served model\n",
    "11. Try out your Model Interactively with a Gradio UI \n",
    "\n",
    "![tutorial-flow](../images/03_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vVDAHU_bpG4"
   },
   "outputs": [],
   "source": [
    "!pip install -U hopsworks --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U xgboost --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRtpj-psbpG8"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Mute warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVCqQYDhbpG_"
   },
   "source": [
    "## <span style=\"color:#ff5f27;\"> üíΩ Loading the Data </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRmFM7vcbpHA"
   },
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv(\"https://repo.hops.works/master/hopsworks-tutorials/data/iris.csv\")\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JR8HeEs6bpHB"
   },
   "outputs": [],
   "source": [
    "iris_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2H3XTfhMbpHB"
   },
   "source": [
    "## <span style=\"color:#ff5f27;\"> ü™Ñ Creating Feature Groups </span>\n",
    "\n",
    "Lets save a feature group (hive table) called `iris` that contains the iris features and the corresponding numeric labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4By1zTHIbpHC"
   },
   "outputs": [],
   "source": [
    "iris_fg = fs.get_or_create_feature_group(name=\"iris\",\n",
    "                                         version=1,\n",
    "                                         primary_key=[\n",
    "                                             \"sepal_length\", \"sepal_width\",\n",
    "                                             \"petal_length\", \"petal_width\"\n",
    "                                         ],\n",
    "                                         description=\"Iris flower dataset\")\n",
    "\n",
    "iris_fg.insert(iris_df, write_options={\"wait_for_job\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚öôÔ∏è Feature View Creation </span>\n",
    "\n",
    "Feature views are used to read features for training and inference.\n",
    "If the feature view already exists, get it. If not, create the feature view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = iris_fg.select_all()\n",
    "\n",
    "feature_view = fs.get_or_create_feature_view(name=\"iris\",\n",
    "                                             version=1,\n",
    "                                             description=\"Read from Iris flower dataset\",\n",
    "                                             labels=[\"variety\"],\n",
    "                                             query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = query.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è Training Dataset Creation</span>\n",
    "\n",
    "In Hopsworks training data is a query where the projection (set of features) is determined by the parent FeatureView with an optional snapshot on disk of the data returned by the query.\n",
    "\n",
    "**Training Dataset  may contain splits such as:** \n",
    "* Training set - the subset of training data used to train a model.\n",
    "* Validation set - the subset of training data used to evaluate hparams when training a model\n",
    "* Test set - the holdout subset of training data used to evaluate a mode\n",
    "\n",
    "Training dataset is created using `fs.create_train_validation_test_split()` method.\n",
    "\n",
    "* `X_train` is the train set features\n",
    "* `X_val` is the validation set features\n",
    "* `X_test` is the test set features\n",
    "* `Y_train` is the train set labels\n",
    "* `Y_val` is the validation set labels\n",
    "* `Y_test` is the test set labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_version, td_job = feature_view.create_train_validation_test_split(\n",
    "    description='iris tutorial',\n",
    "    data_format='csv',\n",
    "    validation_size=0.2,\n",
    "    test_size=0.1,\n",
    "    write_options={'wait_for_job': True},\n",
    "    coalesce = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = feature_view.get_train_validation_test_split(td_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üß¨ Modeling</span>\n",
    "\n",
    "Train the XGBoost Classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use a label encoder to map the categorical labels to numbers.\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train_encoded=le.fit_transform(y_train['variety'])\n",
    "y_test_encoded = le.transform(y_test['variety'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = xgb.XGBClassifier()\n",
    "\n",
    "classifier.fit(X_train.values, y_train_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìê Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(classifier, max_num_features=10, importance_type='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8EC4_SvbpHE"
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test_encoded, y_pred, average=\"macro\")\n",
    "\n",
    "metrics = {\n",
    "    \"f1_score\" : f1\n",
    "}\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = confusion_matrix(y_test_encoded, y_pred)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(results, ['True Setosa', 'True Versicolor', 'True Virginica'],\n",
    "                     ['Pred Setosa', 'Pred Versicolor', 'Pred Virginica'])\n",
    "\n",
    "cm = sns.heatmap(df_cm, annot=True)\n",
    "\n",
    "fig = cm.get_figure()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">‚öôÔ∏è Model Schema</span>\n",
    "\n",
    "The model needs to be set up with a [Model Schema](https://docs.hopsworks.ai/3.0/user_guides/mlops/registry/model_schema/), which describes the inputs and outputs for a model.\n",
    "\n",
    "A Model Schema can be automatically generated from training examples, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "input_schema = Schema(X_train.values)\n",
    "output_schema = Schema(y_train)\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)\n",
    "\n",
    "model_schema.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üìù Register model</span>\n",
    "\n",
    "One of the features in Hopsworks is the model registry. This is where we can store different versions of models and compare their performance. Models from the registry can then be served as API endpoints.\n",
    "\n",
    "Save the following objects as pickle files locally to a directory that will be uploaded later to the model registry:\n",
    "\n",
    " * the model object, `classifier` saved as `iris_xgboost_model.pkl`\n",
    " * the label encoder object, `le` saved as `iris_encoder.pkl`, so that we can reconstruct categorical names \n",
    "    from the encoded predictions (numbers) \n",
    "    \n",
    "The model input schema is the same set of features as in the `X_train` DataFrame.\n",
    "\n",
    "The model output schema is the same label as in the `y_train_encoded` array.\n",
    "\n",
    "Finally, lazily create the model that will be register, including all files (artifacts) in the directory (containing the pickled label encoder object and the pickled model object), the model's input/output schema, and a sample input row (`input_example`). The model registry is the `mr` object, and for our Scikit-Learn model, we create a model of type Python with `mr.python.create_model()`. For TensorFlow, there is `mr.tensorflow.create_model()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "\n",
    "# The 'iris_model' directory will be saved to the model registry\n",
    "model_dir=\"iris_model\"\n",
    "if os.path.isdir(model_dir) == False:\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "joblib.dump(classifier, model_dir + '/xgboost_iris_model.pkl')\n",
    "joblib.dump(le, model_dir + '/iris_encoder.pkl')\n",
    "\n",
    "# lets also save confusion matrix for this model version\n",
    "fig.savefig(model_dir + \"/confusion_matrix.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = project.get_model_registry()\n",
    "\n",
    "iris_model = mr.python.create_model(\n",
    "    name=\"xgboost_iris_model\", \n",
    "    metrics=metrics,\n",
    "    model_schema=model_schema,\n",
    "    input_example=X_train.sample(), \n",
    "    description=\"Iris Flower Predictor\")\n",
    "\n",
    "iris_model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"1.5_bullet\" style=\"color:#ff5f27\"> üöÄ Model Deployment</a>\n",
    "\n",
    "Models can be served via KFServing or \"default\" serving, which means a Docker container exposing a Flask server. For KFServing models, or models written in Tensorflow, you do not need to write a prediction file (see the section below). However, for sklearn models using default serving, you do need to proceed to write a prediction file.\n",
    "\n",
    "In order to use KFServing, you must have Kubernetes installed and enabled on your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">üìé Predictor script for Python models</span>\n",
    "\n",
    "\n",
    "Scikit-learn and XGBoost models are deployed as Python models, in which case you need to provide a **Predict** class that implements the **predict** method. The **predict()** method invokes the model on the inputs and returns the prediction as a list.\n",
    "\n",
    "The **init()** method is run when the predictor is loaded into memory, loading the model from the local directory it is materialized to, *ARTIFACT_FILES_PATH*.\n",
    "\n",
    "The directive `%%writefile` writes out the cell before to the given Python file. We will use the `predict_example.py` file to create a deployment for our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1k14k_uqbpHF"
   },
   "outputs": [],
   "source": [
    "%%writefile predict_example.py\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "\n",
    "class Predict(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # NOTE: env var ARTIFACT_FILES_PATH has the local path to the model artifact files      \n",
    "        self.model = joblib.load(os.environ[\"ARTIFACT_FILES_PATH\"] + \"/xgboost_iris_model.pkl\")\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\" Serves a prediction request from a trained model\"\"\"\n",
    "        return self.model.predict(inputs).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zEEHKFzdbpHG"
   },
   "outputs": [],
   "source": [
    "dataset_api = project.get_dataset_api()\n",
    "\n",
    "uploaded_file_path = dataset_api.upload(\"predict_example.py\", \"Models\", overwrite=True)\n",
    "predictor_script_path = os.path.join(\"/Projects\", project.name, uploaded_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = iris_model.deploy(name=\"irisdeployed\",\n",
    "                               script_file=predictor_script_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Deployment: \" + deployment.name)\n",
    "deployment.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deployment has now been registered. However, to start it you need to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7h4qsnUlbpHG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deployment.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Deployment is warming up...\")\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.get_state().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0iRFs0FbpHH"
   },
   "source": [
    "### <span style='color:#ff5f27'>üîÆ Predicting using deployment</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ICAE38pzbpHH"
   },
   "outputs": [],
   "source": [
    "res = deployment.predict(inputs=iris_model.input_example)\n",
    "# or deployment.predict({ \"instances\": [iris_model.input_example] })\n",
    "\n",
    "print(le.inverse_transform([res[\"predictions\"][0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSFCgRWcbpHH"
   },
   "source": [
    "## <span style=\"color:#ff5f27;\"> üëæ Try out your Model Interactively </span> \n",
    "\n",
    "\n",
    "We will build a user interface with Gradio to allow you to enter the 4 feature values (sepal length/width and petal length/width), producing a prediction of the type of iris flower.\n",
    "\n",
    "First, we have to install the gradio library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdMNftbQbpHI"
   },
   "outputs": [],
   "source": [
    "!pip install gradio --quiet\n",
    "!pip install typing-extensions==4.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Gradio\n",
    "\n",
    "Start the Gradio UI. Users enter the 4 feature values and a prediction is returned. We use the label encoder object to transform the number returned to the categorical value (stringified name of the Iris Flower)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h3DyKEOLbpHI"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def iris(sl, sw, pl, pw):\n",
    "    list_inputs = []\n",
    "    list_inputs.append(sl)\n",
    "    list_inputs.append(sw)\n",
    "    list_inputs.append(pl)\n",
    "    list_inputs.append(pw)\n",
    "    data = {\n",
    "        \"instances\": [list_inputs]\n",
    "    }\n",
    "    res = deployment.predict(data)\n",
    "    # Convert the numerical representation of the label back to it's original iris flower name.\n",
    "    return le.inverse_transform([res[\"predictions\"][0]])[0]\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=iris,\n",
    "    title=\"Iris Flower Predictive Analytics\",\n",
    "    description=\"Experiment with sepal/petal lengths/widths to predict which flower it is.\",\n",
    "    allow_flagging=\"never\",\n",
    "    inputs=[\n",
    "        gr.inputs.Number(default=1.0, label=\"sepal length (cm)\"),\n",
    "        gr.inputs.Number(default=1.0, label=\"sepal width (cm)\"),\n",
    "        gr.inputs.Number(default=1.0, label=\"petal length (cm)\"),\n",
    "        gr.inputs.Number(default=1.0, label=\"petal width (cm)\"),\n",
    "        ],\n",
    "    outputs=\"text\")\n",
    "\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "August 2022 iris_sklearn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a3502d2fd240c5a16c1ad36292676af1ecc0e366e100e74e6e336a5116ced841"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
