{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"../images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 02: Training Data & Feature views</span>\n",
    "\n",
    "<span style=\"font-width:bold; font-size: 1.4rem;\">This is the second part of the quick start series of tutorials about Hopsworks Feature Store. This notebook explains how to read from a feature group and create training dataset within the feature store</span>\n",
    "\n",
    "## **üóíÔ∏è In this notebook we will see how to create a training dataset from the feature groups:** \n",
    "1. **Select the features** we want to train our model on,\n",
    "2. **How the features should be preprocessed,**\n",
    "3. **Create a dataset** for training anomaly detection model.\n",
    "\n",
    "![tutorial-flow](../images/02_training-dataset.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a connection to hsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "# Get the feature store handle for the project's feature store\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üî™ Feature Selection </span>\n",
    "\n",
    "### We start by selecting all the features we want to include for model training/inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retrieve alert nodes feature group from hsfs\n",
    "transactions_monthly_fg = fs.get_feature_group(\"transactions_monthly_aml_fg\", 1)\n",
    "graph_embeddings_fg = fs.get_feature_group(\"graph_embeddings_aml_fg\", 1) \n",
    "party_fg = fs.get_feature_group(\"party_aml_fg\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AML model query \n",
    "aml_model_query = party_fg.select([\"type\", \"is_sar\"])\\\n",
    "                            .join(transactions_monthly_fg.select([\"monthly_in_count\", \n",
    "                                                                  \"monthly_in_total_amount\", \n",
    "                                                                  \"monthly_in_mean_amount\", \n",
    "                                                                  \"monthly_in_std_amount\", \n",
    "                                                                  \"monthly_out_count\", \n",
    "                                                                  \"monthly_out_total_amount\", \n",
    "                                                                  \"monthly_out_mean_amount\", \n",
    "                                                                  \"monthly_out_std_amount\"]))\\\n",
    "                            .join(graph_embeddings_fg.select([\"graph_embeddings\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncommnet this line if you would like to see query results\n",
    "#aml_model_query.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation Functions\n",
    "Transformation functions are a mathematical mapping of input data that may be stateful - requiring statistics from the partent feature view (such as number of instances of a category, or mean value of a numerical feature)\n",
    "\n",
    "We will preprocess our data using *min-max scaling* on numerical features and *label encoding* on categorical features. To do this we simply define a mapping between our features and transformation functions. This ensures that transformation functions such as *min-max scaling* are fitted only on the training data (and not the validation/test data), which ensures that there is no data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load built in transformation functions.\n",
    "min_max_scaler = fs.get_transformation_function(name=\"min_max_scaler\")\n",
    "\n",
    "# Map features to transformations.\n",
    "transformation_functions = {\n",
    "    \"monthly_in_count\": min_max_scaler,\n",
    "    \"monthly_in_total_amount\": min_max_scaler,\n",
    "    \"monthly_in_mean_amount\": min_max_scaler,\n",
    "    \"monthly_in_std_amount\": min_max_scaler,\n",
    "    \"monthly_out_count\": min_max_scaler,\n",
    "    \"monthly_out_total_amount\": min_max_scaler,\n",
    "    \"monthly_out_mean_amount\": min_max_scaler,\n",
    "    \"monthly_out_std_amount\": min_max_scaler\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚öôÔ∏è Feature View Creation </span>\n",
    "\n",
    "In Hopsworks, you write features to feature groups (where the features are stored) and you read features from feature views. A feature view is a logical view over features, stored in feature groups, and a feature view typically contains the features used by a specific model. This way, feature views enable features, stored in different feature groups, to be reused across many different models. The Feature Views allows schema in form of a query with filters, define a model target feature/label and additional transformation functions.\n",
    "In order to create a Feature View we may use `fs.create_feature_view()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.create_feature_view(\n",
    "    name='aml_feature_view',\n",
    "    query=aml_model_query,\n",
    "    labels=[\"is_sar\"],\n",
    "    transformation_functions=transformation_functions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è Training Dataset Creation</span>\n",
    "\n",
    "In Hopsworks training data is a query where the projection (set of features) is determined by the parent FeatureView with an optional snapshot on disk of the data returned by the query.\n",
    "\n",
    "**Training Dataset  may contain splits such as:** \n",
    "* Training set - the subset of training data used to train a model.\n",
    "* Validation set - the subset of training data used to evaluate hparams when training a model\n",
    "* Test set - the holdout subset of training data used to evaluate a mode\n",
    "\n",
    "Training dataset is created using `feature_view.create_training_data()` or `feature_view.get_training_data()` methods.\n",
    "\n",
    "**From feature view APIs we can also create training datasts based on even time filters specifing `start_time` and `end_time`** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = feature_view.training_data(description = 'aml training dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üëì Exploration </span>\n",
    "\n",
    "### Similar to Feature Groups Feature Views and Training Tatasets are now accessible and searchable in the UI\n",
    "![fv-overview](images/feature_views_explore.gif)\n",
    "\n",
    "## üìä Statistics\n",
    "We can explore feature statistics in the feature views. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fv-stats](images/feature_view_stats.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚è≠Ô∏è **Next:** Part 03 </span>\n",
    "    \n",
    "In the following notebook you will train adversarial anomaly detection model, deploy the model on KServe behind Hopsworks for real-time inference requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
