{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f17430dc",
   "metadata": {},
   "source": [
    "# Tweets processing with [TextBlob](https://textblob.readthedocs.io/en/dev/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830382e9",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üìù Imports</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f215bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "import re\n",
    "import time\n",
    "import os.path\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from datetime import timedelta, datetime\n",
    "from dateutil import parser\n",
    "\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a02cb7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_processed = pd.read_csv(\"tweets_processed.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c4e5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-05 10:52:04</th>\n",
       "      <td>üìñ  Weekend Read üìñ\\n\\nKeen to learn about crypt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-05 10:52:04</th>\n",
       "      <td>2‚É£   Debunking 9 Bitcoin Myths by ‚¨áÔ∏è  \\n\\ncryp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-05 10:52:06</th>\n",
       "      <td>4‚É£  üéôÔ∏è Bloomberg LP CryptoOutlook 2021 with ‚¨áÔ∏è...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-05 10:52:07</th>\n",
       "      <td>5‚É£   Blockchain 50 2021 by , , ‚¨áÔ∏è\\n\\ncryptocur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-05 10:52:26</th>\n",
       "      <td>reddcoin rdd to the moon altcoin turnreddcoini...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                tweets\n",
       "date                                                                  \n",
       "2021-02-05 10:52:04  üìñ  Weekend Read üìñ\\n\\nKeen to learn about crypt...\n",
       "2021-02-05 10:52:04  2‚É£   Debunking 9 Bitcoin Myths by ‚¨áÔ∏è  \\n\\ncryp...\n",
       "2021-02-05 10:52:06  4‚É£  üéôÔ∏è Bloomberg LP CryptoOutlook 2021 with ‚¨áÔ∏è...\n",
       "2021-02-05 10:52:07  5‚É£   Blockchain 50 2021 by , , ‚¨áÔ∏è\\n\\ncryptocur...\n",
       "2021-02-05 10:52:26  reddcoin rdd to the moon altcoin turnreddcoini..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_processed = df_tweets_processed[['text']] \n",
    "df_tweets_processed.columns = ['tweets']\n",
    "df_tweets_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8ddc38",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>üßπ Additional text cleaning </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3ec70b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_2_time(x):\n",
    "    dt_obj = datetime.datetime.strptime(str(x), '%Y-%m-%d %H:%M:%S')\n",
    "    dt_obj = dt_obj.timestamp() * 1000\n",
    "    return int(dt_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "276ebebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text2(df):\n",
    "    \"\"\"Second cleaning using 'nltk' module. Processes 'text' feature. \"\"\"\n",
    "    \n",
    "    stop_words = nltk.corpus.stopwords.words(['english'])\n",
    "    lem = WordNetLemmatizer()\n",
    "\n",
    "    def cleaning(data):\n",
    "        # remove urls\n",
    "        tweet_without_url = re.sub(r'http\\S+',' ', data)\n",
    "\n",
    "        # remove hashtags\n",
    "        tweet_without_hashtag = re.sub(r'#\\w+', ' ', tweet_without_url)\n",
    "\n",
    "        # Remove mentions and characters that not in the English alphabets\n",
    "        tweet_without_mentions = re.sub(r'@\\w+',' ', tweet_without_hashtag)\n",
    "        precleaned_tweet = re.sub('[^A-Za-z]+', ' ', tweet_without_mentions)\n",
    "\n",
    "        # Tokenize\n",
    "        tweet_tokens = TweetTokenizer().tokenize(precleaned_tweet)\n",
    "\n",
    "        # Remove Puncs\n",
    "        tokens_without_punc = [w for w in tweet_tokens if w.isalpha()]\n",
    "\n",
    "        # Removing Stopwords\n",
    "        tokens_without_sw = [t for t in tokens_without_punc if t not in stop_words]\n",
    "\n",
    "        # lemma\n",
    "        text_cleaned = [lem.lemmatize(t) for t in tokens_without_sw]\n",
    "\n",
    "        # Joining\n",
    "        return \" \".join(text_cleaned)\n",
    "    \n",
    "    df['cleaned_tweets'] = df['text'].apply(cleaning)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bd5e9d",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>ü§ñ TextBlob applying </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7697a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textblob_processing(df):\n",
    "    \"\"\"\n",
    "    Applies TextBlob sentiment analisys to 'cleaned_tweets' feature in the DataFrame df\n",
    "    \"\"\"\n",
    "    df = clean_text2(df)\n",
    "    \n",
    "    def getSubjectivity(tweet):\n",
    "        return TextBlob(tweet).sentiment.subjectivity\n",
    "\n",
    "    def getPolarity(tweet):\n",
    "        return TextBlob(tweet).sentiment.polarity\n",
    "    \n",
    "    correct_dates = df['date'].copy()\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')\n",
    "    df.cleaned_tweets = df.cleaned_tweets.astype(str)\n",
    "    \n",
    "    df['subjectivity'] = df['cleaned_tweets'].apply(getSubjectivity)\n",
    "    df['polarity'] = df['cleaned_tweets'].apply(getPolarity)\n",
    "    \n",
    "    df.date = correct_dates\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    df = df.set_index(\"date\")\n",
    "    df = df.resample('1D').sum()\n",
    "    df = df[[\"subjectivity\", \"polarity\"]].reset_index()\n",
    "    \n",
    "    df['date'] = df['date'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df['unix'] = df.date.apply(timestamp_2_time)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9490e3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_textblob = textblob_processing(df_tweets_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2995bf2f",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üì• Save the results</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "068a6cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_textblob.to_csv(\"tweets_textblob.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
