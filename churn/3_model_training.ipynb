{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b46ab6c1",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"../images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span>\n",
    "\n",
    "<span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 03: Model training & UI Exploration</span>\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/logicalclocks/hopsworks-tutorials/blob/master/churn/3_model_training.ipynb)\n",
    "\n",
    "\n",
    "**Note**: you may get an error when installing hopsworks on Colab, and it is safe to ignore it.\n",
    "\n",
    "\n",
    "In this notebook you will train a model on the dataset you created in the previous tutorial. You will train the model using standard Python and Scikit-learn, although it could just as well be trained with other machine learning frameworks such as PySpark, TensorFlow, and PyTorch. You will also perform some of the exploration that can be done in Hopsworks, notably the search functions and the lineage.\n",
    "\n",
    "## üóíÔ∏è This notebook is divided in 3 main sections:\n",
    "1. **Loading the training data**\n",
    "2. **Train the model**\n",
    "3. **Explore feature groups and views** via the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf1ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U hopsworks --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8fb822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8bba25",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\"> ‚ú® Load Training Data </span>\n",
    "\n",
    "First, you will need to fetch the training dataset that you created in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b7ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data.\n",
    "feature_view = fs.get_feature_view(\n",
    "    name = 'churn_feature_view',\n",
    "    version = 1\n",
    ")\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = feature_view.get_train_validation_test_split(\n",
    "    training_dataset_version = 1\n",
    ")\n",
    "\n",
    "X_train.drop('customerid', axis = 1, inplace = True)\n",
    "X_val.drop('customerid', axis = 1, inplace = True)\n",
    "X_test.drop('customerid', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8547a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b62171",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b1f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fc2ed4",
   "metadata": {},
   "source": [
    "Notice that the distribution is skewed, which is good news for the company considering that customers at risk of churning make up smaller part of customer base. However, as a data scientist should somehow address the class imbalance. There are many approaches for this, such as weighting the loss function, over- or undersampling, creating synthetic data, or modifying the decision threshold. In this example, you will use the simplest method which is to just supply a class weight parameter to our learning algorithm. The class weight will affect how much importance is attached to each class, which in our case means that higher importance will be placed on positive (curn) samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe057ebf",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\"> üèÉ Train Model</span>\n",
    "\n",
    "Next you will train a model and set the bigger class weight for the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce49665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model.\n",
    "pos_class_weight = 0.9\n",
    "\n",
    "clf = LogisticRegression(class_weight={0: 1.0 - pos_class_weight, 1: pos_class_weight}, solver='liblinear')\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17470645",
   "metadata": {},
   "source": [
    "Let's see how well it performs on our validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c7173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "preds = clf.predict(X_val)\n",
    "\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(y_val, preds, average=\"binary\")\n",
    "\n",
    "metrics = {\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'fscore': fscore\n",
    "}\n",
    "\n",
    "print(classification_report(y_val, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe61e70a",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\"> Model Registry</span>\n",
    "\n",
    "One of the features in Hopsworks is the model registry. This is where you can store different versions of models and compare their performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4696ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149a4d0d",
   "metadata": {},
   "source": [
    "The model needs to be set up with a Model Schema, which describes the inputs and outputs for a model.\n",
    "\n",
    "A Model Schema can be automatically generated from training examples, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d496339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "input_schema = Schema(X_train)\n",
    "output_schema = Schema(y_train)\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)\n",
    "\n",
    "model_schema.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63af4853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "pkl_file_name = \"churnmodel.pkl\"\n",
    "\n",
    "joblib.dump(clf, pkl_file_name)\n",
    "\n",
    "model = mr.sklearn.create_model(\n",
    "    name=\"churnmodel\",\n",
    "    description = \"Churn Model\",\n",
    "    input_example = X_train.sample().to_numpy(),\n",
    "    model_schema = model_schema\n",
    ")\n",
    "\n",
    "model.save(pkl_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba49401",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style='color:#ff5f27'>üöÄ Fetch and test the model</span>\n",
    "\n",
    "Finally you can start making predictions with your model! To identify customers at risk of churn lets retrieve your churn prediction model from Hopsworks model registry  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71912764",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mr.get_model(\"churnmodel\", version = 1)\n",
    "\n",
    "model_dir = model.download()\n",
    "model = joblib.load(model_dir + \"/churnmodel.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfb97a2",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\">üîÆ  Use trained model to identify customers at risk of churn </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_preds(predictions):\n",
    "    return ['Churn' if pred == 1 else 'Not Churn' for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adb2463",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = feature_view.get_batch_data()\n",
    "\n",
    "batch_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9308a4b",
   "metadata": {},
   "source": [
    "Let's predict the all for all customer data and then visualize predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906a9ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data.drop('customerid',axis = 1, inplace = True)\n",
    "\n",
    "predictions = model.predict(batch_data)\n",
    "predictions = transform_preds(predictions)\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146c2bbf",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\">üë®üèª‚Äçüé® Prediction Visualisation</span>\n",
    "\n",
    "Now you got your predictions but you also would like to exlain predictions to make informed decisions. Lets visualise them and explain important features that influences on the risk of churning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8462189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect \n",
    "\n",
    "# Recall that you applied transformation functions, such as min max scaler and laber encoder. \n",
    "# Now you want to transform them back to human readable format.\n",
    "df_all = batch_data.copy()\n",
    "td_transformation_functions = feature_view._batch_scoring_server._transformation_functions\n",
    "for feature_name in td_transformation_functions:\n",
    "    td_transformation_function = td_transformation_functions[feature_name]\n",
    "    sig, foobar_locals = inspect.signature(td_transformation_function.transformation_fn), locals()\n",
    "    param_dict = dict([(param.name, param.default) for param in sig.parameters.values() if param.default != inspect._empty])\n",
    "    if td_transformation_function.name == \"label_encoder\":\n",
    "        rev_dict = {v: k for k, v in param_dict[\"value_to_index\"].items()}\n",
    "        df_all[feature_name] = df_all[feature_name].map(lambda x: rev_dict[x])\n",
    "    if td_transformation_function.name == \"min_max_scaler\":\n",
    "        df_all[feature_name] = df_all[feature_name].map(lambda x: x*(param_dict[\"max_value\"]-param_dict[\"min_value\"])+param_dict[\"min_value\"])\n",
    "\n",
    "            \n",
    "df_all = df_all\n",
    "df_all['Churn'] = predictions\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca58420",
   "metadata": {},
   "source": [
    "Lets plot feature importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc821fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "feature_names = batch_data.columns\n",
    "\n",
    "feature_importance = pd.DataFrame(feature_names, columns = [\"feature\"])\n",
    "feature_importance[\"importance\"] = pow(math.e, model.coef_[0])\n",
    "feature_importance = feature_importance.sort_values(by = [\"importance\"], ascending = False)\n",
    "\n",
    "plt.figure(figsize = (16,6)) \n",
    "sns.barplot(x = 'feature', y = 'importance', data = feature_importance)\n",
    "\n",
    "plt.title('Feature Importance Plot', fontsize = 20)\n",
    "plt.xticks(rotation = 20)\n",
    "plt.xlabel('Feature', fontsize = 13)\n",
    "plt.ylabel('Importance', fontsize = 13)\n",
    "\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2294fe10",
   "metadata": {},
   "source": [
    "As you can see `internetservice` has the biggest effect on the risk of churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d628766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13,6))\n",
    "\n",
    "sns.countplot(\n",
    "    data = df_all,\n",
    "    x = 'internetservice',\n",
    "    hue = 'Churn'\n",
    ")\n",
    "\n",
    "plt.title('Churn rate according to internet service subscribtion', fontsize = 20)\n",
    "plt.xlabel(\"internetservice\", fontsize = 13)\n",
    "plt.ylabel('Number of customers', fontsize = 13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae667f8e",
   "metadata": {},
   "source": [
    "Lets visualise couple of more imporant features such as `streamingtv` and `streamingmovies`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70e2ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13,6))\n",
    "\n",
    "sns.countplot(\n",
    "    data = df_all,\n",
    "    x = 'streamingtv',\n",
    "    hue = 'Churn'\n",
    ")\n",
    "\n",
    "plt.title('Churn rate according to internet streaming tv subscribtion', fontsize = 20)\n",
    "plt.xlabel(\"streamingtv\", fontsize = 13)\n",
    "plt.ylabel('Number of customers', fontsize = 13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f126a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13,6))\n",
    "\n",
    "sns.countplot(\n",
    "    data = df_all,\n",
    "    x = 'streamingtv',\n",
    "    hue = 'Churn'\n",
    ")\n",
    "\n",
    "plt.title('Churn rate according to streaming movies service subscribtion', fontsize = 20)\n",
    "plt.xlabel(\"streamingmovies\", fontsize = 13)\n",
    "plt.ylabel('Number of customers', fontsize = 13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e003a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13,6))\n",
    "\n",
    "sns.countplot(\n",
    "    data = df_all,\n",
    "    x = 'gender',\n",
    "    hue = 'Churn'\n",
    ")\n",
    "\n",
    "plt.title('Churn rate according to Gender', fontsize = 20)\n",
    "plt.xlabel(\"Gender\", fontsize = 13)\n",
    "plt.ylabel('Count', fontsize = 13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fea593",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13,6))\n",
    "\n",
    "sns.histplot(\n",
    "    data = df_all,\n",
    "    x = 'totalcharges',\n",
    "    hue = 'Churn'\n",
    ")\n",
    "\n",
    "plt.title('Amount of each Payment Method', fontsize = 20)\n",
    "plt.xlabel(\"Charge Value\", fontsize = 13)\n",
    "plt.ylabel('Count', fontsize = 13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff21309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13,6))\n",
    "\n",
    "sns.countplot(\n",
    "    data = df_all,\n",
    "    x = 'paymentmethod',\n",
    "    hue = 'Churn'\n",
    ")\n",
    "\n",
    "plt.title('Amount of each Payment Method', fontsize = 20)\n",
    "plt.xlabel(\"Payment Method\", fontsize = 13)\n",
    "plt.ylabel('Total Amount', fontsize = 13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f47a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13,6))\n",
    "\n",
    "sns.countplot(\n",
    "    data = df_all,\n",
    "    x = 'partner',\n",
    "    hue = 'Churn'\n",
    ")\n",
    "\n",
    "plt.title('Affect of having a partner on Churn/Not', fontsize = 20)\n",
    "plt.xlabel(\"Have a partner\", fontsize = 13)\n",
    "plt.ylabel('Count', fontsize = 13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfa5732",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\">üßëüèª‚Äçüî¨ StreamLit App </span>\n",
    "\n",
    "If you want to use an **interactive dashboards** - you can use a StreamLit App.\n",
    "\n",
    "Use the following commands in terminal to run a Streamlit App:\n",
    "\n",
    "> `cd {%path_to_hopsworks_tutorials%}/`  </br>\n",
    "> `conda activate ./miniconda/envs/hopsworks` </br>\n",
    "> `python -m streamlit run churn/streamlit_app.py`</br>\n",
    "\n",
    "**‚ö†Ô∏è** If you are running on Colab, you will need to follow a different procedure. As highlighted in this [notebook](https://colab.research.google.com/github/mrm8488/shared_colab_notebooks/blob/master/Create_streamlit_app.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccce098",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\"> üëì  Exploration</span>\n",
    "In the Hopsworks feature store, the metadata allows for multiple levels of explorations and review. Here we will show a few of those capacities. \n",
    "\n",
    "### <span style=\"color:#ff5f27;\">üîé <b>Search</b></span> \n",
    "Using the search function in the ui, you can query any aspect of the feature groups, feature_view and training data that was previously created.\n",
    "\n",
    "### <span style=\"color:#ff5f27;\">üìä <b>Statistics</b> </span>\n",
    "We can also enable statistics in one or all the feature groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f16dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_info_fg = fs.get_feature_group(\"customer_info\", version = 1)\n",
    "customer_info_fg.statistics_config = {\n",
    "    \"enabled\": True,\n",
    "    \"histograms\": True,\n",
    "    \"correlations\": True\n",
    "}\n",
    "\n",
    "customer_info_fg.update_statistics_config()\n",
    "customer_info_fg.compute_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917a743e",
   "metadata": {},
   "source": [
    "![fg-statistics](../churn/images/churn_statistics.gif)\n",
    "\n",
    "\n",
    "### <span style=\"color:#ff5f27;\">‚õìÔ∏è <b> Lineage </b> </span>\n",
    "In all the feature groups and feature view you can look at the relation between each abstractions; what feature group created which training dataset and that is used in which model.\n",
    "This allows for a clear undestanding of the pipeline in relation to each element. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac871910",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <span style=\"color:#ff5f27;\">ü•≥ <b> Next Steps  </b> </span>\n",
    "Congratulations you've now completed the churn risk prediction tutorial for Managed Hopsworks.\n",
    "\n",
    "Check out our other tutorials on ‚û° https://github.com/logicalclocks/hopsworks-tutorials\n",
    "\n",
    "Or documentation at ‚û° https://docs.hopsworks.ai"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
