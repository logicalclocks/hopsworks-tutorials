{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 03: Training Data & Feature views\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/logicalclocks/hopsworks-tutorials/blob/master/advanced_tutorials/nyc_taxi_fares/3_feature_view_and_dataset_creation.ipynb)\n",
    "\n",
    "\n",
    "**Note**: you may get an error when installing hopsworks on Colab, and it is safe to ignore it.\n",
    "\n",
    "This is the second part of the quick start series of tutorials about Hopsworks Feature Store. This notebook explains how to read from a feature group and create training dataset within the feature store\n",
    "\n",
    "## üóíÔ∏è In this notebook we will see how to create a training dataset from the feature groups:\n",
    "1. **Select the features** we want to train our model on,\n",
    "2. **How the features should be preprocessed,**\n",
    "3. **Create a dataset split** for training and validation data.\n",
    "\n",
    "![02_training-dataset](../../images/02_training-dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#ff5f27;\">üìù Importing Libraries</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">‚¨áÔ∏è Data retrieving from Feature Groups</span>\n",
    "\n",
    "We start by selecting all the features we want to include for model training/inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature groups.\n",
    "fares_fg = fs.get_or_create_feature_group(\"fares_fg\",\n",
    "                                          version=1)\n",
    "rides_fg = fs.get_or_create_feature_group(\"rides_fg\",\n",
    "                                          version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for training data.\n",
    "fg_query = fares_fg.select(['total_fare', \"tolls\"])\\\n",
    "                            .join(rides_fg.select_except(['taxi_id', \"driver_id\", \"pickup_datetime\",\n",
    "                                                          \"pickup_longitude\", \"pickup_latitude\",\n",
    "                                                          \"dropoff_longitude\", \"dropoff_latitude\"]),\n",
    "                                  on=['ride_id'])\n",
    "\n",
    "fg_query.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üîÆ Feature View Creation</span>\n",
    "\n",
    "\n",
    "We start by selecting all the features we want to include for model training/inference.\n",
    "\n",
    "After we have made a query from desired features, we should make a corresponding `Feature View`.\n",
    "In order to do it we may use `fs.create_feature_view()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_fares_fv = fs.create_feature_view(\n",
    "    name='nyc_taxi_fares_fv',\n",
    "    query=fg_query,\n",
    "    labels=[\"total_fare\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_fares_fv.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üèãÔ∏è Training Dataset Creation</span>\n",
    "    \n",
    "In Hopsworks training data is a query where the projection (set of features) is determined by the parent FeatureView with an optional snapshot on disk of the data returned by the query.\n",
    "\n",
    "Training Dataset may contain splits such as:\n",
    "\n",
    "    Training set - the subset of training data used to train a model.\n",
    "    Validation set - the subset of training data used to evaluate hparams when training a model\n",
    "    Test set - the holdout subset of training data used to evaluate a mode\n",
    "\n",
    "Training dataset is created using fs.create_train_validation_test_split() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nyc_fares_fv.create_training_data(\n",
    "    description='training_dataset',\n",
    "    data_format='csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = nyc_fares_fv.get_training_data(\n",
    "    training_dataset_version=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_fares_fv.create_train_test_split(\n",
    "    test_size=0.2 # here we can define the test dataset size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = nyc_fares_fv.get_train_test_split(\n",
    "    training_dataset_version=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 04 </span>\n",
    "\n",
    "In the next notebook, we will train a model on the dataset we created in this notebook."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
