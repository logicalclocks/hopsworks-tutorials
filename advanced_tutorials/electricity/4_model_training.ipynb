{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b612e17",
   "metadata": {
    "id": "1b612e17"
   },
   "source": [
    "# Part 04: Model training & UI Exploration\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/logicalclocks/hopsworks-tutorials/blob/master/advanced_tutorials/eletricity/4_model_training_and_registration.ipynb)\n",
    "\n",
    "\n",
    "In this last notebook, you will train a model on the dataset we created in the previous tutorial. You will train the model using standard Python and Scikit-learn, although it could just as well be trained with other machine learning frameworks such as PySpark, TensorFlow, and PyTorch. In the end some exploration that can be done in Hopsworks will be shown, notably the search functions and the lineage.\n",
    "\n",
    "## üóíÔ∏è This notebook is divided in 3 main sections:\n",
    "1. **Loading the training data**\n",
    "2. **Train the model**\n",
    "3. **Register model to Hopsworks model registry**.\n",
    "\n",
    "![tutorial-flow](../../images/03_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eed10e",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">üìù Importing Libraries</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4b3b4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b4b3b4f",
    "outputId": "6b42955b-e019-4d79-faa6-7bb59cf637dc"
   },
   "outputs": [],
   "source": [
    "!pip install -U hopsworks --quiet\n",
    "!pip install -U tensorflow --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3604c7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina', quality=100)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9346974",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a725b8",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üì° Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6041e702",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6041e702",
    "outputId": "8c2597ab-0e77-4c08-ddd3-5de1877fbeb4"
   },
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073728d9",
   "metadata": {
    "id": "073728d9"
   },
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\">ü™ù Feature View and Training Dataset Retrieval</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9c92c8",
   "metadata": {
    "id": "fa9c92c8"
   },
   "outputs": [],
   "source": [
    "feature_view = fs.get_feature_view(\n",
    "    name = 'electricity_feature_view',\n",
    "    version = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d2c382",
   "metadata": {
    "id": "02d2c382"
   },
   "outputs": [],
   "source": [
    "X_train, _ = feature_view.get_training_data(1)\n",
    "X_val, _ = feature_view.get_training_data(2)\n",
    "X_test, _ = feature_view.get_training_data(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18845e8b",
   "metadata": {
    "id": "18845e8b"
   },
   "outputs": [],
   "source": [
    "X_train.sort_values([\"timestamp\"], inplace=True)\n",
    "X_val.sort_values([\"timestamp\"], inplace=True)\n",
    "X_test.sort_values([\"timestamp\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6734e9f",
   "metadata": {
    "id": "c6734e9f"
   },
   "outputs": [],
   "source": [
    "y_train = X_train[[\"price_se1\", \"price_se2\", \"price_se3\", \"price_se4\"]]\n",
    "y_val = X_val[[\"price_se1\", \"price_se2\", \"price_se3\", \"price_se4\"]]\n",
    "y_test = X_test[[\"price_se1\", \"price_se2\", \"price_se3\", \"price_se4\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f7504c",
   "metadata": {
    "id": "43f7504c"
   },
   "outputs": [],
   "source": [
    "X_train.drop([\"day\", \"timestamp\"], axis = 1, inplace = True)\n",
    "X_val.drop([\"day\", \"timestamp\"], axis = 1, inplace = True)\n",
    "X_test.drop([\"day\", \"timestamp\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e43eab9",
   "metadata": {
    "id": "7e43eab9"
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3706d48",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d9a37c",
   "metadata": {
    "id": "03d9a37c"
   },
   "source": [
    "## <span style=\"color:#ff5f27;\">üóÉ Window timeseries dataset </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc2db77",
   "metadata": {
    "id": "9bc2db77"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# https://www.tensorflow.org/tutorials/structured_data/time_series\n",
    "class WindowGenerator():\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "               df_train, val_df, test_df,\n",
    "               label_columns=None, batch_size=32):\n",
    "        # Store the raw data.\n",
    "        self.df_train = df_train\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "\n",
    "        # Work out the label column indices.\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "          self.label_columns_indices = {name: i for i, name in\n",
    "                                        enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in\n",
    "                               enumerate(df_train.columns)}\n",
    "\n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}',\n",
    "            f'Label column name(s): {self.label_columns}'])\n",
    "\n",
    "    def split_window(self, features):\n",
    "      inputs = features[:, self.input_slice, :]\n",
    "      labels = features[:, self.labels_slice, :]\n",
    "      if self.label_columns is not None:\n",
    "        labels = tf.stack(\n",
    "            [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "            axis=-1)\n",
    "\n",
    "      # Slicing doesn't preserve static shape information, so set the shapes\n",
    "      # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "      inputs.set_shape([None, self.input_width, None])\n",
    "      labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "      return inputs, labels\n",
    "\n",
    "    def plot(self, plot_col, model=None, max_subplots=3):\n",
    "      inputs, labels = self.example\n",
    "      plt.figure(figsize=(12, 8))\n",
    "      plot_col_index = self.column_indices[plot_col]\n",
    "      max_n = min(max_subplots, len(inputs))\n",
    "      for n in range(max_n):\n",
    "        plt.subplot(max_n, 1, n+1)\n",
    "        plt.ylabel(f'{plot_col} [normed]')\n",
    "        plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                 label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "        if self.label_columns:\n",
    "          label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "        else:\n",
    "          label_col_index = plot_col_index\n",
    "\n",
    "        if label_col_index is None:\n",
    "          continue\n",
    "\n",
    "        plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                    edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "        if model is not None:\n",
    "          predictions = model(inputs)\n",
    "          plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                      marker='X', edgecolors='k', label='Predictions',\n",
    "                      c='#ff7f0e', s=64)\n",
    "\n",
    "        if n == 0:\n",
    "          plt.legend()\n",
    "\n",
    "      plt.xlabel('Time [h]')\n",
    "\n",
    "    #make_dataset method will take a time series DataFrame and convert it to a tf.data.Dataset of (input_window, label_window) \n",
    "    # pairs using the tf.keras.utils.timeseries_dataset_from_array function:\n",
    "    def make_dataset(self, data):\n",
    "      data = np.array(data, dtype=np.float32)\n",
    "      ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "          data=data,\n",
    "          targets=None,\n",
    "          sequence_length=self.total_window_size,\n",
    "          sequence_stride=1,\n",
    "          shuffle=False,\n",
    "          batch_size=self.batch_size,)    \n",
    "      ds = ds.map(self.split_window)\n",
    "      ds = ds.repeat(1000)\n",
    "      ds = ds.prefetch(10)  \n",
    "      return ds\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "      return self.make_dataset(self.df_train)\n",
    "\n",
    "    @property\n",
    "    def val(self):\n",
    "      return self.make_dataset(self.val_df)\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "      return self.make_dataset(self.test_df)\n",
    "\n",
    "    @property\n",
    "    def example(self):\n",
    "      \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "      result = getattr(self, '_example', None)\n",
    "      if result is None:\n",
    "        # No example batch was found, so get one from the `.train` dataset\n",
    "        result = next(iter(self.test))\n",
    "        # And cache it for next time\n",
    "        self._example = result\n",
    "      return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9907f2f",
   "metadata": {
    "id": "d9907f2f"
   },
   "outputs": [],
   "source": [
    "n_step_window = WindowGenerator(df_train=X_train, val_df=X_val, test_df=X_test, input_width=4, label_width=4, shift=4, label_columns=[\"price_se1\", \"price_se2\", \"price_se3\", \"price_se4\"])\n",
    "n_step_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e3ea35",
   "metadata": {
    "id": "02e3ea35"
   },
   "outputs": [],
   "source": [
    "inputs, labels = n_step_window.example\n",
    "print(inputs.shape)\n",
    "print(labels.shape)\n",
    "print(n_step_window.label_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c38108b",
   "metadata": {
    "id": "6c38108b"
   },
   "outputs": [],
   "source": [
    "# X = np.arange(100)\n",
    "# Y = X * 2\n",
    "# X = pd.DataFrame(X, columns = [\"X\"])\n",
    "# X[\"Y\"] = Y\n",
    "# n_step_window = WindowGenerator(df_train=X, val_df=X, test_df=X, input_width=4, label_width=4, shift=4, label_columns=[\"Y\"], batch_size=4)\n",
    "# a = [i[0].numpy() for i in n_step_window.val]\n",
    "# b = [i[1].numpy() for i in n_step_window.val]\n",
    "# a[0][0]\n",
    "# b[0][0]\n",
    "# n_step_window.plot(plot_col=\"Y\", max_subplots=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f079da",
   "metadata": {
    "id": "74f079da"
   },
   "outputs": [],
   "source": [
    "for example_inputs, example_labels in n_step_window.train.take(1):\n",
    "    print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "    print(f'Labels shape (batch, time, features): {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58979c8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72d7e04",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üß¨ Modeling</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd00bfd",
   "metadata": {
    "id": "1dd00bfd"
   },
   "outputs": [],
   "source": [
    "def build_model(input_dim):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv1D(filters = 64, kernel_size=1, padding='same', kernel_initializer=\"uniform\", input_shape=(input_dim[0], input_dim[1])))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))        \n",
    "\n",
    "    model.add(tf.keras.layers.Conv1D(filters = 32, kernel_size= 1,padding='same',  kernel_initializer=\"uniform\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))       \n",
    "\n",
    "    model.add(tf.keras.layers.Conv1D(filters = 16, kernel_size= 1,padding='same',  kernel_initializer=\"uniform\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))   \n",
    "    model.add(tf.keras.layers.MaxPooling1D(pool_size=1, padding='same'))       \n",
    "    \n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=16, return_sequences=True))) \n",
    "    model.add(tf.keras.layers.Dropout(rate=0.1))\n",
    "    model.add(tf.keras.layers.Dense(units=4))\n",
    "    \n",
    "    model.summary()\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3feca7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "de3feca7",
    "outputId": "93df9741-952e-4ae1-aa87-c3fcc7309fe8"
   },
   "outputs": [],
   "source": [
    "model = build_model([4, 29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a503950",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "6a503950",
    "outputId": "6838e364-b2dc-4002-f4e9-e742afe23fa0"
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "start = timer()\n",
    "\n",
    "history = model.fit(n_step_window.train,\n",
    "                    epochs=50,\n",
    "                    verbose=0,\n",
    "                    steps_per_epoch=200,\n",
    "                    validation_data=n_step_window.train,\n",
    "                    validation_steps=1,                    \n",
    "                   )\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc15b16b",
   "metadata": {
    "id": "dc15b16b"
   },
   "outputs": [],
   "source": [
    "inputs, labels = n_step_window.example\n",
    "prediction_test = model.predict(inputs)\n",
    "print(prediction_test.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035c401c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "035c401c",
    "outputId": "79413a9d-9d26-4081-8e01-1690aa4bc06c"
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21555a11",
   "metadata": {
    "id": "21555a11"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "loss_values50 = loss_values\n",
    "val_loss_values50 = val_loss_values\n",
    "epochs = range(1, len(loss_values50) + 1)\n",
    "plt.plot(epochs, loss_values50, 'b',color = 'blue', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values50, 'b',color='red', label='Validation loss')\n",
    "plt.rc('font', size = 18)\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.xticks(epochs)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15,7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e1669",
   "metadata": {
    "id": "662e1669"
   },
   "outputs": [],
   "source": [
    "n_step_window.plot(plot_col=\"price_se4\", max_subplots=3, model=model.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532ed996",
   "metadata": {
    "id": "532ed996"
   },
   "outputs": [],
   "source": [
    "se1_actual = []\n",
    "se2_actual = []\n",
    "se3_actual = []\n",
    "se4_actual = []\n",
    "\n",
    "inputs, labels = n_step_window.example\n",
    "for batch_n in range(len(labels)):\n",
    "    batch = labels[batch_n]\n",
    "    for window_n in range(4):\n",
    "        se1_actual.append(batch[window_n][0].numpy())\n",
    "        se2_actual.append(batch[window_n][1].numpy())\n",
    "        se3_actual.append(batch[window_n][2].numpy())\n",
    "        se4_actual.append(batch[window_n][3].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927f8497",
   "metadata": {
    "id": "927f8497"
   },
   "outputs": [],
   "source": [
    "se1_pred = []\n",
    "se2_pred = []\n",
    "se3_pred = []\n",
    "se4_pred = []\n",
    "\n",
    "prediction_test = model.predict(inputs)\n",
    "for batch_n in range(len(prediction_test)):\n",
    "    batch = prediction_test[batch_n]\n",
    "    for window_n in range(4):\n",
    "        se1_pred.append(batch[window_n][0])\n",
    "        se2_pred.append(batch[window_n][1])\n",
    "        se3_pred.append(batch[window_n][2])\n",
    "        se4_pred.append(batch[window_n][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91261a61",
   "metadata": {
    "id": "91261a61"
   },
   "outputs": [],
   "source": [
    "y_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aee4bd",
   "metadata": {
    "id": "06aee4bd"
   },
   "outputs": [],
   "source": [
    "se3_actual[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dc2ca9",
   "metadata": {
    "id": "f3dc2ca9"
   },
   "outputs": [],
   "source": [
    "plt.plot(se1_pred,color='red', label='test SE1 price prediction')\n",
    "plt.plot(se1_actual, color='blue', label='test actual')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price (scaled)')\n",
    "plt.legend(loc='upper left')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e7a690",
   "metadata": {
    "id": "c1e7a690"
   },
   "outputs": [],
   "source": [
    "plt.plot(se2_pred,color='red', label='test SE2 price prediction')\n",
    "plt.plot(se2_actual, color='blue', label='test actual')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price (scaled)')\n",
    "plt.legend(loc='upper left')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e20005",
   "metadata": {
    "id": "34e20005"
   },
   "outputs": [],
   "source": [
    "plt.plot(se3_pred,color='red', label='test SE3 price prediction')\n",
    "plt.plot(se3_actual, color='blue', label='test actual')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price (scaled)')\n",
    "plt.legend(loc='upper left')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da679a9",
   "metadata": {
    "id": "4da679a9"
   },
   "outputs": [],
   "source": [
    "plt.plot(se4_pred,color='red', label='test SE4 price prediction')\n",
    "plt.plot(se4_actual, color='blue', label='test actual')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price (scaled)')\n",
    "plt.legend(loc='upper left')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f59af2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed732e2",
   "metadata": {
    "id": "4ed732e2"
   },
   "source": [
    "## <span style='color:#ff5f27'>üóÑ Model Registry</span>\n",
    "\n",
    "One of the features in Hopsworks is the model registry. This is where you can store different versions of models and compare their performance. Models from the registry can then be served as API endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1524a5",
   "metadata": {
    "id": "fc1524a5"
   },
   "outputs": [],
   "source": [
    "export_path = \"electricity_price_model\"\n",
    "print('Exporting trained model to: {}'.format(export_path))\n",
    "tf.saved_model.save(model, export_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680035f0",
   "metadata": {
    "id": "680035f0"
   },
   "outputs": [],
   "source": [
    "mr = project.get_model_registry()\n",
    "metrics={'loss': history_dict['val_loss'][0]} \n",
    "\n",
    "mr_model = mr.tensorflow.create_model(\n",
    "    name=\"electricity_price_prediction_model\",\n",
    "    metrics=metrics,\n",
    "    description=\"Daily electricity price prediction model.\",\n",
    "    input_example=n_step_window.example[0].numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375d68fe",
   "metadata": {
    "id": "375d68fe"
   },
   "outputs": [],
   "source": [
    "mr_model.save(export_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
