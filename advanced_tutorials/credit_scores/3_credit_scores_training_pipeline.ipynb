{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3835d20",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"../../images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 03: Training Pipeline</span>\n",
    "\n",
    "\n",
    "<span style=\"font-width:bold; font-size: 1.4rem;\">This notebook explains how to read from a feature group, create training dataset within the feature store, train a model and save it to model registry.</span>\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into the following sections:\n",
    "\n",
    "1. Fetch Feature Groups.\n",
    "2. Define Transformation functions.\n",
    "3. Create Feature Views.\n",
    "4. Create Training Dataset with training, validation and test splits.\n",
    "5. Train the model.\n",
    "6. Register model in Hopsworks model registry.\n",
    "\n",
    "![part2](../../images/02_training-dataset.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a039456",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a3bd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ef21de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import plot_importance\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e17c271",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üîÆ Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9926d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a751877c",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">ü™Ñ Retrieving Feature Groups</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d2ea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "applications_fg = fs.get_feature_group(\n",
    "    name='applications',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "bureau_balances_fg = fs.get_feature_group(\n",
    "    name='bureau_balances',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "bureaus_fg = fs.get_feature_group(\n",
    "    name='bureaus',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "previous_applications_fg = fs.get_feature_group(\n",
    "    name='previous_applications',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "pos_cash_balances_fg = fs.get_feature_group(\n",
    "    name='pos_cash_balances',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "installment_payments_fg = fs.get_feature_group(\n",
    "    name='installment_payments',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "credit_card_balances_fg = fs.get_feature_group(\n",
    "    name='credit_card_balances',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "previous_loan_counts_fg = fs.get_feature_group(\n",
    "    name='previous_loan_counts',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d1d7fd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\">üïµüèª‚Äç‚ôÇÔ∏è Feature Groups Investigation</span>\n",
    "\n",
    "We can use `FeatureGroup.show()` method to select top n rows. \n",
    "\n",
    "Also we use method `FeatureGroup.read()` in order **to aggregate queries**, which are the output of next methods:\n",
    "\n",
    "- `FeatureGroup.get_feture()` to get specific feature from our Feature Group.\n",
    "\n",
    "- `FeatureGroup.select()` to get a few features from our Feature Group.\n",
    "\n",
    "- `FeatureGroup.select_all()` to get all features from our Feature Group.\n",
    "\n",
    "- `FeatureGroup.select_except()` to get all features except a few from our Feature Group.\n",
    "\n",
    "- `FeatureGroup.filter()` in order to apply specific filter to the feature group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b73ebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "applications_fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be7448",
   "metadata": {},
   "outputs": [],
   "source": [
    "applications_fg.select_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "applications_fg.read().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af51378",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> üíº Feature Selection</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62380318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for training data\n",
    "selected_features = bureaus_fg.select_except(['sk_id_curr','sk_id_bureau','datetime'])\\\n",
    "            .join(applications_fg.select_except(['sk_id_curr',\n",
    "                                                 'datetime',\n",
    "                                                 'flag_mobil',\n",
    "                                                 *[f'flag_document_{num}'\n",
    "                                                   for num\n",
    "                                                   in [2,4,7,10,12,14,17,19,20,21]\n",
    "                                                  ],\n",
    "                                                 'amt_credit', 'weekday_appr_process_start',\n",
    "                                                 'hour_appr_process_start']))\\\n",
    "            .join(bureau_balances_fg.select_except(['sk_id_bureau','months_balance']))\\\n",
    "            .join(previous_applications_fg.select_except(['sk_id_prev', 'sk_id_curr','datetime',\n",
    "                                                          'name_contract_type', 'name_contract_status']))\\\n",
    "            .join(pos_cash_balances_fg.select_except(['sk_id_prev','sk_id_curr', 'months_balance',\n",
    "                                                      'name_contract_status', 'sk_dpd', 'sk_dpd_def']))\\\n",
    "            .join(installment_payments_fg.select_except(['sk_id_prev', 'sk_id_curr', 'datetime']))\\\n",
    "            .join(credit_card_balances_fg.select_except(['sk_id_prev', 'sk_id_curr']))\\\n",
    "            .join(previous_loan_counts_fg.select_except('sk_id_curr'))\n",
    "\n",
    "selected_features_show5 = selected_features.show(5)\n",
    "selected_features_show5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e020793a",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\">ü§ñ Transformation functions</span>\n",
    "\n",
    "Hopsworks Feature Store provides functionality to attach transformation functions to training datasets.\n",
    "\n",
    "Hopsworks Feature Store also comes with built-in transformation functions such as `min_max_scaler`, `standard_scaler`, `robust_scaler` and `label_encoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4add316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the names of all available transformation functions\n",
    "[t_func for t_func in fs.get_transformation_functions()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e22bdc1",
   "metadata": {},
   "source": [
    "We can retrieve transformation function we need .\n",
    "\n",
    "To attach transformation function to training dataset provide transformation functions as dict, where key is feature name and value is online transformation function name.\n",
    "\n",
    "Also training dataset must be created from the Query object. Once attached transformation function will be applied on whenever save, insert and get_serving_vector methods are called on training dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4417311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the names of categorical columns in the 'selected_features_show5query_show5' DataFrame\n",
    "cat_cols = selected_features_show5.dtypes[selected_features_show5.dtypes == 'object'].index\n",
    "\n",
    "# Retrieving the Label Encoder transformation function from Featuretools\n",
    "label_encoder = fs.get_transformation_function(name='label_encoder') \n",
    "\n",
    "# Creating a dictionary of transformation functions, where each categorical column is associated with the Label Encoder\n",
    "transformation_functions = [\n",
    "    label_encoder(col)\n",
    "    for col \n",
    "    in cat_cols\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3194fda2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> ‚öôÔ∏è Feature View Creation </span>\n",
    "\n",
    "`Feature Views` stands between **Feature Groups** and **Training Dataset**. –°ombining **Feature Groups** we can create **Feature Views** which store a metadata of our data. Having **Feature Views** we can create **Training Dataset**.\n",
    "\n",
    "The Feature Views allows schema in form of a query with filters, define a model target feature/label and additional transformation functions.\n",
    "\n",
    "In order to create Feature View we can use `FeatureStore.get_or_create_feature_view()` method.\n",
    "\n",
    "We can specify next parameters:\n",
    "\n",
    "- `name` - name of a feature group.\n",
    "\n",
    "- `version` - version of a feature group.\n",
    "\n",
    "- `labels`- out target variable.\n",
    "\n",
    "- `transformation_functions` - functions to transform our features.\n",
    "\n",
    "- `query` - query object with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2973313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create the 'credit_scores' feature view\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name='credit_scores',\n",
    "    version=1,\n",
    "    labels=['target'],\n",
    "    transformation_functions=transformation_functions,\n",
    "    query=selected_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28671167",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è Training Dataset Creation</span>\n",
    "\n",
    "In Hopsworks training data is a query where the projection (set of features) is determined by the parent FeatureView with an optional snapshot on disk of the data returned by the query.\n",
    "\n",
    "**Training Dataset  may contain splits such as:** \n",
    "* Training set - the subset of training data used to train a model.\n",
    "* Validation set - the subset of training data used to evaluate hparams when training a model\n",
    "* Test set - the holdout subset of training data used to evaluate a mode\n",
    "\n",
    "To create training dataset you will use the `FeatureView.train_test_split()` method.\n",
    "\n",
    "Here are some importand things:\n",
    "\n",
    "- It will inherit the name of FeatureView.\n",
    "\n",
    "- The feature store currently supports the following data formats for\n",
    "training datasets: **tfrecord, csv, tsv, parquet, avro, orc**.\n",
    "\n",
    "- You can choose necessary format using **data_format** parameter.\n",
    "\n",
    "- **start_time** and **end_time** in order to filter dataset in specific time range.\n",
    "\n",
    "- You can create **train, test** splits using `train_test_split()`. \n",
    "\n",
    "- You can create **train,validation, test** splits using `train_validation_test_splits()` methods.\n",
    "\n",
    "- The only thing is that we should specify desired ratio of splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7b350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = feature_view.train_test_split(\n",
    "    test_size=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d287f1",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\"> üß¨ Modeling</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d07c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an XGBoost Classifier model\n",
    "xgboost_model = xgb.XGBClassifier()\n",
    "\n",
    "# Training the XGBoost model on the training data\n",
    "xgboost_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3195458",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\"> üë®üèª‚Äç‚öñÔ∏è Model Evaluation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f5b547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the F1 score on the test set using the trained XGBoost model\n",
    "score = f1_score(\n",
    "    y_test, \n",
    "    xgboost_model.predict(X_test), \n",
    "    average=\"macro\",\n",
    ")\n",
    "\n",
    "# Displaying the F1 score\n",
    "print(f'‚õ≥Ô∏è F1 score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d781e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix on the test set using the trained XGBoost model\n",
    "conf_matrix = confusion_matrix(\n",
    "    y_test, \n",
    "    xgboost_model.predict(X_test),\n",
    ")\n",
    "\n",
    "# Creating a heatmap to visualize the confusion matrix\n",
    "figure_cm = plt.figure(figsize=(10, 7))\n",
    "figure_cm = sns.heatmap(\n",
    "    conf_matrix, \n",
    "    annot=True, \n",
    "    annot_kws={\"size\": 14},\n",
    "    fmt='.10g',\n",
    ")\n",
    "\n",
    "# Adding title to the heatmap\n",
    "plt.title('Confusion Matrix', fontsize=17)\n",
    "\n",
    "# Displaying the heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff26ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting feature importance using the plot_importance function from XGBoost\n",
    "# Displaying the top 10 features based on their weight importance\n",
    "# 'importance_type' is set to 'weight' to use the number of times a feature appears in a tree\n",
    "figure_imp = plot_importance(\n",
    "    xgboost_model, \n",
    "    max_num_features=10, \n",
    "    importance_type='weight',\n",
    ")\n",
    "\n",
    "# Displaying the feature importance plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e841906",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\">üóÑ Model Registry</span>\n",
    "\n",
    "One of the features in Hopsworks is the model registry. This is where you can store different versions of models and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1978dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the model registry\n",
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e435716f",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">‚öôÔ∏è Model Schema</span>\n",
    "\n",
    "The model needs to be set up with a [Model Schema](https://docs.hopsworks.ai/machine-learning-api/latest/generated/model_schema/), which describes the inputs and outputs for a model.\n",
    "\n",
    "A Model Schema can be automatically generated from training examples, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7863e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "# Creating input and output schemas\n",
    "input_schema = Schema(X_train.values)\n",
    "output_schema = Schema(y_train)\n",
    "\n",
    "# Creating a model schema\n",
    "model_schema = ModelSchema(\n",
    "    input_schema=input_schema, \n",
    "    output_schema=output_schema,\n",
    ")\n",
    "\n",
    "# Converting the model schema to a dictionary representation\n",
    "schema_dict = model_schema.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68f4493",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">üíΩ Save a model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c58e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a directory for the model artifacts if it doesn't exist\n",
    "model_dir = \"credit_scores_model\"\n",
    "if os.path.isdir(model_dir) == False:\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "# Saving the trained XGBoost model as a json file in the model directory\n",
    "xgboost_model.save_model(model_dir + \"/model.json\")\n",
    "\n",
    "# Saving the confusion matrix and feature importance plots as images in the model directory\n",
    "figure_cm.figure.savefig(model_dir + '/confusion_matrix.png')\n",
    "figure_imp.figure.savefig(model_dir + '/feature_importance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70342ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Python model in the model registry named 'credit_scores_model'\n",
    "model = mr.python.create_model(\n",
    "    name=\"credit_scores_model\",\n",
    "    metrics={\"f1_score\": score}, \n",
    "    description=\"XGB for Credit Scores Project\",\n",
    "    input_example=X_train.sample(),\n",
    "    model_schema=model_schema,\n",
    ")\n",
    "\n",
    "# Saving the model artifacts to the 'credit_scores_model' directory in the model registry\n",
    "model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00656e4d",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 04: Batch Inference </span>\n",
    "\n",
    "In the next notebook you will use your registered model to predict batch data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
