{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a6deb7",
   "metadata": {},
   "source": [
    "![hopsworks_logo](../images/hopsworks_logo.png)\n",
    "\n",
    "# Part 03: Model training & UI Exploration\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/logicalclocks/hopsworks-tutorials/blob/master/fraud_batch/3_model_training.ipynb)\n",
    "\n",
    "**Note**: you may get an error when installing hopsworks on Colab, and it is safe to ignore it.\n",
    "\n",
    "In this last notebook, we will train a model on the dataset we created in the previous tutorial. We will train our model using standard Python and Scikit-learn, although it could just as well be trained with other machine learning frameworks such as PySpark, TensorFlow, and PyTorch. We will also show some of the exploration that can be done in Hopsworks, notably the search functions and the lineage.\n",
    "\n",
    "## üóíÔ∏è This notebook is divided in 3 main sections:\n",
    "1. **Loading the training data**\n",
    "2. **Train the model**\n",
    "3. **Explore feature groups and views** via the UI.\n",
    "\n",
    "![tutorial-flow](../images/03_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e953f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U hopsworks --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acebff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8577dd79",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2177587e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚ú® Load Training Data </span>\n",
    "\n",
    "First, we'll need to fetch the training dataset that we created in the previous notebook. We will use January - February data training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2296852e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.get_feature_view(\"transactions_fraud_online_fv\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e789c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = feature_view.get_training_data(1)\n",
    "X_test, y_test = feature_view.get_training_data(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da92dac1",
   "metadata": {},
   "source": [
    "We will train a model to predict `fraud_label` given the rest of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e20344e",
   "metadata": {},
   "source": [
    "Let's check the distribution of our target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de0249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac885de4",
   "metadata": {},
   "source": [
    "Notice that the distribution is extremely skewed, which is natural considering that fraudulent transactions make up a tiny part of all transactions. Thus we should somehow address the class imbalance. There are many approaches for this, such as weighting the loss function, over- or undersampling, creating synthetic data, or modifying the decision threshold. In this example, we'll use the simplest method which is to just supply a class weight parameter to our learning algorithm. The class weight will affect how much importance is attached to each class, which in our case means that higher importance will be placed on positive (fraudulent) samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4959ab5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb576f8",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚öúÔ∏è Weights and Biases </span>\n",
    "\n",
    "[Weights and Biases](https://wandb.ai/) is a free Python library that allows you to track, compare, and visualize ML experiments -> build better models faster. \n",
    "\n",
    "In our case we will use **W&B** to track Data Lineage using **Artifacts**, find the best hyperparameters using **Sweep** and visualize model performance.\n",
    "\n",
    "To begin with, let's install `wandb` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf04b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392e7fd",
   "metadata": {},
   "source": [
    "Sign up for a free account by going to the [sign up page](https://wandb.ai/home).\n",
    "\n",
    "After that you should login."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010ebfd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2daa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'fraud_online'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0129bd3f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b85f1bf",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üóÉ W&B Artifacts </span>\n",
    "\n",
    "Use W&B Artifacts for dataset versioning, model versioning, and tracking dependencies and results across machine learning pipelines. Think of an artifact as a versioned folder of data. You can store entire datasets directly in artifacts, or use artifact references to point to data in other systems like S3, GCP, or your own system. \n",
    "\n",
    "Also you can visualize Data Lineage for better understanding of project pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d17dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a run in W&B\n",
    "run = wandb.init(\n",
    "    project=PROJECT_NAME,\n",
    "    job_type=\"upload_feature_view\",\n",
    "    name='metadata'\n",
    ")\n",
    "\n",
    "# create an artifact for all the raw data\n",
    "raw_data_at = wandb.Artifact(\n",
    "    \"transactions_view_fraud_online_fv_version1\", \n",
    "    type=\"feature_view\",\n",
    "    metadata = {key:value.__repr__() for key,value in feature_view.to_dict().items()}\n",
    ")\n",
    "\n",
    "# save artifact to W&B\n",
    "run.log_artifact(raw_data_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    project=PROJECT_NAME,\n",
    "    name=\"train_validation_test_split\",\n",
    "    job_type='split'\n",
    ")\n",
    "\n",
    "data_at = run.use_artifact(\"transactions_view_fraud_online_fv_version1:latest\")\n",
    "data_dir = data_at.download()\n",
    "\n",
    "artifacts = {}\n",
    "\n",
    "for split in ['train','validation','test']:\n",
    "    artifacts[split] = wandb.Artifact(f'{split}_split', type=\"split\")  \n",
    "    \n",
    "for split, artifact in artifacts.items():\n",
    "    run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfa2e4c",
   "metadata": {},
   "source": [
    "To check Data Lineage follow next steps:\n",
    "\n",
    "1. Go to the [W&B main page](https://wandb.ai/home).\n",
    "\n",
    "2. Select **\"nyc_taxi_fares\"** project.\n",
    "\n",
    "3. Select the **\"Artifacts\"** icon in the left sidebar.\n",
    "\n",
    "4. Inspect the `transactions_view_fraud_online_fv_version1` type artifact.\n",
    "\n",
    "5. Go to the **\"Lineage\"** and then press **\"Explode\"**.\n",
    "\n",
    "So for now Data Lineage should look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb092d2d",
   "metadata": {},
   "source": [
    "![image.png](../images/wandb_fraud_online_lineage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0ec3ea",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è‚Äç‚ôÄÔ∏è Define Model Training Function</span>\n",
    "\n",
    "It is important to define a function which will be used by the Sweep agent.\n",
    "\n",
    "In this function we:\n",
    "\n",
    "- Set default hyperparameters for the model.\n",
    "\n",
    "- Initialize a new W&B Run using `wandb.init`.\n",
    "\n",
    "- Register all hyperparameters through `wandb.config`.\n",
    "\n",
    "- Create a RandomForestClassifier with a set of hyperparameters.\n",
    "\n",
    "- Fit a RandomForestClassifier.\n",
    "\n",
    "- Predict and evaluate.\n",
    "\n",
    "- Log all metrics using `wandb.log`.\n",
    "\n",
    "- Plot beautiful plots using `wandb.sklearn.plot_classifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360c07a9",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#ff5f27;\"> üìù Importing Libraries</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb6d56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec2daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train=X_train, y_train=y_train,X_test=X_test, y_test=y_test):\n",
    "\n",
    "    config_defaults = {\n",
    "        'n_estimators': 100, \n",
    "        'criterion': 'gini',\n",
    "        'min_samples_split': 10\n",
    "    }\n",
    "    features = X_train.columns\n",
    "\n",
    "    wandb.init(config=config_defaults)\n",
    "    config = wandb.config\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=config.n_estimators, \n",
    "        criterion=config.criterion,\n",
    "        min_samples_split=config.min_samples_split,\n",
    "        max_features='sqrt',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        class_weight={0: 0.1, 1: 0.9}\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_preds = model.predict(X_test)\n",
    "    y_probas = model.predict_proba(X_test)\n",
    "  \n",
    "    score = f1_score(y_test, y_preds)\n",
    "    print(f\"F1_score: {round(score, 4)}\")\n",
    "\n",
    "    wandb.log({\"F1_score\": score})\n",
    "    \n",
    "    wandb.sklearn.plot_classifier(model, X_train, X_test, y_train, y_test, \n",
    "                                y_preds, y_probas, features, model_name='RandomForestClassifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e6b76d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bfe766",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üîß Define Sweep Configurations</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb28fef1",
   "metadata": {},
   "source": [
    "The next step is to define configurations for Sweep.\n",
    "\n",
    "**Weights & Biases Sweeps** are used to automate hyperparameter optimization and explore the space of possible models.\n",
    "\n",
    "You will initialize Sweep in form of a dictionary.\n",
    "\n",
    "You should include next steps:\n",
    "\n",
    "- `method`: specify your search strategy (**Bayesian**, **Grid** and **Random** searches.)\n",
    "\n",
    "- `metric`: define the name and goal (maximize or minimize) of the metric. **Example**: *name: MSE, goal: minimize*.\n",
    "\n",
    "- `parameters`: define the hyperparameters as the keys of a dictionary and their corresponding values to search over in the form of a list stored as the values of this dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8420450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_configs = {\n",
    "    \"method\": \"grid\",\n",
    "    \"metric\": {\n",
    "        \"name\": \"f1_score\",\n",
    "        \"goal\": \"maximize\"\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"n_estimators\": {\n",
    "            \"values\": [75,150]\n",
    "        },\n",
    "        \"criterion\": {\n",
    "            \"values\": ['gini','entropy']\n",
    "        },\n",
    "        \"min_samples_split\": {\n",
    "            \"values\": [5,15]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd30c89",
   "metadata": {},
   "source": [
    "Then we initialize the sweep and run the sweep agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae50285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(\n",
    "    sweep=sweep_configs,\n",
    "    project=PROJECT_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0a598e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wandb.agent(\n",
    "    sweep_id=sweep_id,\n",
    "    function=train_model,\n",
    "    count=5\n",
    ")\n",
    "\n",
    "# if this cell crushes, restart the kernel and dont run cells with artifacts above\n",
    "# run only Sweep cells instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55efe890",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">üéâ Great! üìà</span>\n",
    "\n",
    "Now you can go to the **Weights & Biases** UI to look at the results\n",
    "\n",
    "There you can find some great plots which will help you to control model development process such as **Feature Importance**, **ROC Curve**, **Confusion Matrix** and others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5e2ae1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28948f66",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üß¨ Modeling</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35087e52",
   "metadata": {},
   "source": [
    "![plots.gif](../images/plots.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ab0ce1",
   "metadata": {},
   "source": [
    "Also you can explore how different hyperparameters affect model.\n",
    "\n",
    "In addition you can sort all observations by desired column. In our case you will sort by F1_score metric in order to find the best set of Hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b326c10",
   "metadata": {},
   "source": [
    "![hyperparams.gif](../images/hyperparams.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afb16ea",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\">üöÄ Fit the best model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c24640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model.\n",
    "pos_class_weight = 0.9\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=150,\n",
    "    criterion='entropy',\n",
    "    min_samples_split=15,\n",
    "    max_features='sqrt',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight={0: 0.1, 1: 0.9}\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beaeec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Predictions\n",
    "y_pred_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e35a313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e719b5f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b994f71",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">üîÆ Saving Model in W&B</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901d5ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "run = wandb.init(project=\"fraud_batch\", job_type=\"model_building\", name = 'rfregressor') \n",
    "\n",
    "data_at = run.use_artifact(\"train_split:latest\")\n",
    "data_dir = data_at.download()\n",
    "\n",
    "model_artifact = wandb.Artifact(\n",
    "            \"RandomForestRegressor\", type=\"model\",\n",
    "            description=\"This model is trained on the data from  `Hopsworks  Feature View`.\\\n",
    "                You can check it on the https://app.hopsworks.ai.\\\n",
    "                Just Login and go to the `Feature Views` page and find **nyc_fares_fv**.\",\n",
    "            metadata=dict(sweep_configs))\n",
    "\n",
    "joblib.dump(clf, \"model.joblib\")\n",
    "\n",
    "model_artifact.add_file(\"model.joblib\")\n",
    "\n",
    "wandb.save(\"model.joblib\")\n",
    "\n",
    "run.log_artifact(model_artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddee9e36",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec7d222",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üìù Register model in Hopsworks</span>\n",
    "\n",
    "One of the features in Hopsworks is the model registry. This is where we can store different versions of models and compare their performance. Models from the registry can then be served as API endpoints.\n",
    "\n",
    "Let's connect to the model registry using the [HSML library](https://docs.hopsworks.ai/machine-learning-api/latest) from Hopsworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d207dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d72c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(clf, 'model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd6099a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f672a8",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">‚öôÔ∏è Model Schema</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a57af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "input_schema = Schema(X_train)\n",
    "output_schema = Schema(y_train)\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)\n",
    "\n",
    "model_schema.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21b7021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "# Compute f1 score\n",
    "metrics = {\"fscore\": f1_score(y_test, y_pred_test, average='micro')}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81865d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_credit_card = [4467360740682089]\n",
    "model = mr.sklearn.create_model(\n",
    "    name=\"transactions_fraud_online_model\",\n",
    "    metrics=metrics,\n",
    "    description=\"Isolation forest anomaly detection model\",\n",
    "    input_example = test_credit_card,\n",
    "    model_schema=model_schema\n",
    ")\n",
    "\n",
    "model.save('model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f49359",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9673be2",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üöÄ Deploy model</span>\n",
    "### About Model Serving\n",
    "Models can be served via KFServing or \"default\" serving, which means a Docker container exposing a Flask server. For KFServing models, or models written in Tensorflow, you do not need to write a prediction file (see the section below). However, for sklearn models using default serving, you do need to proceed to write a prediction file.\n",
    "\n",
    "In order to use KFServing, you must have Kubernetes installed and enabled on your cluster.\n",
    "\n",
    "### Create the Prediction File\n",
    "In order to deploy a model, you need to write a Python file containing the logic to return a prediction from the model. Don't worry, this is usually a matter of just modifying some paths in a template script. An example can be seen in the code block below, where we have taken this Scikit-learn template script and changed two paths (see comments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbebcdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile predict_example.py\n",
    "import os\n",
    "import numpy as np\n",
    "import hsfs\n",
    "import joblib\n",
    "\n",
    "class Predict(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Initializes the serving state, reads a trained model\"\"\"        \n",
    "        # get feature store handle\n",
    "        fs_conn = hsfs.connection()\n",
    "        self.fs = fs_conn.get_feature_store()\n",
    "        \n",
    "        # get feature views\n",
    "        self.fv = self.fs.get_feature_view(\"transactions_fraud_online_fv\", 1)\n",
    "        \n",
    "        # initialise serving\n",
    "        self.fv.init_serving(1)\n",
    "\n",
    "        # load the trained model\n",
    "        self.model = joblib.load(os.environ[\"ARTIFACT_FILES_PATH\"] + \"/model.pkl\")\n",
    "        print(\"Initialization Complete\")\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\" Serves a prediction request usign a trained model\"\"\"\n",
    "        return self.model.predict(np.asarray(self.fv.get_feature_vector({\"cc_num\": inputs[0]})).reshape(1, -1)).tolist() # Numpy Arrays are not JSON serializable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e750238",
   "metadata": {},
   "source": [
    "If you wonder why we use the path Models/fraud_tutorial_model/1/model.pkl, it is useful to know that the Data Sets tab in the Hopsworks UI lets you browse among the different files in the project. Registered models will be found underneath the Models directory. Since we saved our model with the name fraud_tutorial_model, that's the directory we should look in. 1 is just the version of the model we want to deploy.\n",
    "\n",
    "This script needs to be put into a known location in the Hopsworks file system. Let's call the file predict_example.py and put it in the Models directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc353de0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "dataset_api = project.get_dataset_api()\n",
    "\n",
    "uploaded_file_path = dataset_api.upload(\"predict_example.py\", \"Models\", overwrite=True)\n",
    "\n",
    "predictor_script_path = os.path.join(\"/Projects\", project.name, uploaded_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51068ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_script_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d86842b",
   "metadata": {},
   "source": [
    "### on Windows, `predictor_script_path` may be like that:\n",
    "`'/Projects\\\\romankah\\\\Models/predict_example.py'`\n",
    "### Thats incorrect, you have to rewrite it to the correct format:\n",
    "`'/Projects/romankah/Models/predict_example.py'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9215cdd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb31da6e",
   "metadata": {},
   "source": [
    "## üì° Create the deployment\n",
    "Here, we fetch the model we want from the model registry and define a configuration for the deployment. For the configuration, we need to specify the serving type (default or KFserving) and in this case, since we use default serving and an sklearn model, we need to give the location of the prediction script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4521ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model name from the previous notebook.\n",
    "model = mr.get_model(\"transactions_fraud_online_model\", version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9a15bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give it any name you want\n",
    "deployment = model.deploy(\n",
    "    name=\"fraudonlinemodeldeployment\", \n",
    "    model_server=\"PYTHON\",\n",
    "    script_file=predictor_script_path,\n",
    "#     serving_tool = \"KSERVE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3235f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Deployment: \" + deployment.name)\n",
    "deployment.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb657a82",
   "metadata": {},
   "source": [
    "#### The deployment has now been registered. However, to start it you need to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ba894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43117d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f225699d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfe7464",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>üîÆ Predicting using deployment</span>\n",
    "Let's use the input example that we registered together with the model to query the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf5bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.input_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e4d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"inputs\": model.input_example\n",
    "}\n",
    "\n",
    "deployment.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a18bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d26d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f2f62e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de991b32",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üéÅ  Wrapping things up </span>\n",
    "\n",
    "We have now performed a simple training with training data that we have created in the feature store. This concludes the fisrt module and introduction to the core aspect of the Feature store. In the second module we will introduce streaming and external feature groups for a similar fraud use case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
