{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üë®üèª‚Äçüè´ Create Deployment </span>\n",
    "\n",
    "In this notebook, you'll create a deployment for your recommendation system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Start the timer\n",
    "notebook_start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üìù Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üîÆ Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Hopsworks Model Registry\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "dataset_api = project.get_dataset_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the 'query_model' from the Model Registry\n",
    "query_model = mr.get_model(\n",
    "    name=\"query_model\",\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#ff5f27\">üöÄ Recommender Model Deployment </span>\n",
    "\n",
    "üìù Includes the next steps:\n",
    "1. Generate query embedding from customer data.\n",
    "2. Find the closest candidate items to customer embedding using similarity search.\n",
    "3. Filter out items the customer has already bought.\n",
    "4. Retrieve article features for remaining candidate items.\n",
    "5. Score candidate items using the ranking model.\n",
    "6. Sort items by prediction scores in descending order.\n",
    "7. Return the ranked recommendations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile recommender_transformer.py\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import logging\n",
    "import hopsworks\n",
    "\n",
    "\n",
    "class Transformer(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        # Connect to the Hopsworks\n",
    "        project = hopsworks.login()\n",
    "        ms = project.get_model_serving()\n",
    "        mr = project.get_model_registry()\n",
    "\n",
    "        # Retrieve the 'customers' feature view\n",
    "        self.fs = project.get_feature_store()\n",
    "        self.customer_fv = self.fs.get_feature_view(\n",
    "            name=\"customers\", \n",
    "            version=1,\n",
    "        )\n",
    "        self.customer_fv.init_serving(1)\n",
    "        \n",
    "        # Retrieve 'transactions' feature group.\n",
    "        self.transactions_fg = self.fs.get_feature_group(\n",
    "            name=\"transactions\", \n",
    "            version=1,\n",
    "        )\n",
    "\n",
    "        # Retrieve the 'articles' feature view\n",
    "        self.articles_fv = self.fs.get_feature_view(\n",
    "            name=\"articles\",\n",
    "            version=1,\n",
    "        )  \n",
    "\n",
    "        # Get list of feature names for articles\n",
    "        self.articles_features = [feat.name for feat in self.articles_fv.schema]\n",
    "\n",
    "        # Retrieve the 'candidate_embeddings' feature view\n",
    "        self.candidate_index = self.fs.get_feature_view(\n",
    "            name=\"candidate_embeddings\",\n",
    "            version=1,\n",
    "        )\n",
    "\n",
    "        model = mr.get_model(\n",
    "            name=\"ranking_model\",\n",
    "            version=1,\n",
    "        )\n",
    "\n",
    "        # Download the saved model files to a local directory\n",
    "        saved_model_dir = model.download()\n",
    "\n",
    "        self.model = joblib.load(saved_model_dir + \"/ranking_model.pkl\")\n",
    "\n",
    "        self.ranking_fv = model.get_feature_view(init=False)\n",
    "        self.ranking_fv.init_batch_scoring(1)\n",
    "\n",
    "        # Get the names of features expected by the ranking model\n",
    "        self.ranking_model_feature_names = [\n",
    "            feature.name \n",
    "            for feature \n",
    "            in self.ranking_fv.schema \n",
    "            if feature.name != 'label'\n",
    "        ]\n",
    "\n",
    "\n",
    "    def preprocess(self, inputs):\n",
    "        # Check if the input data contains a key named \"instances\"\n",
    "        # and extract the actual data if present\n",
    "        inputs = inputs[\"instances\"] if \"instances\" in inputs else inputs\n",
    "        inputs = inputs[0]\n",
    "        \n",
    "        # Extract customer_id and transaction_date from the inputs\n",
    "        customer_id = inputs[\"customer_id\"]\n",
    "        transaction_date = inputs[\"date\"]\n",
    "        \n",
    "        # Extract month from the transaction_date\n",
    "        month_of_purchase = datetime.fromisoformat(inputs.pop(\"date\"))\n",
    "\n",
    "        # Get customer features\n",
    "        customer_features = self.customer_fv.get_feature_vector(\n",
    "            {\"customer_id\": customer_id},\n",
    "            return_type=\"pandas\",\n",
    "        )\n",
    "        \n",
    "        # Enrich inputs with customer age\n",
    "        inputs[\"age\"] = customer_features.age.values[0]  \n",
    "        \n",
    "        # Calculate the sine and cosine of the month_of_purchase\n",
    "        month_of_purchase = datetime.strptime(\n",
    "            transaction_date, \"%Y-%m-%dT%H:%M:%S.%f\"\n",
    "        ).month\n",
    "\n",
    "        # Calculate the sine and cosine components for the month_of_purchase using on-demand transformation present in \"ranking\" feature view.\n",
    "        feature_vector = self.ranking_fv._batch_scoring_server.compute_on_demand_features(\n",
    "            feature_vectors=pd.DataFrame([inputs]), request_parameters={\"month\": month_of_purchase}\n",
    "        ).to_dict(orient=\"records\")[0]\n",
    "\n",
    "        inputs[\"month_sin\"] = feature_vector[\"month_sin\"]\n",
    "        inputs[\"month_cos\"] = feature_vector[\"month_cos\"]\n",
    "\n",
    "        return {\"instances\": [inputs]}\n",
    "\n",
    "\n",
    "    def postprocess(self, query_outputs):\n",
    "\n",
    "        inputs = query_outputs[0]\n",
    "        \n",
    "        # Extract customer_id from inputs\n",
    "        customer_id = inputs[\"customer_id\"]\n",
    "\n",
    "        # Search for candidate items\n",
    "        neighbors = self.candidate_index.find_neighbors(\n",
    "            inputs[\"query_emb\"],\n",
    "            k=100,\n",
    "        )\n",
    "        neighbors = [neighbor[0] for neighbor in neighbors]\n",
    "\n",
    "        # Get IDs of items already bought by the customer\n",
    "        already_bought_items_ids = (\n",
    "            self.transactions_fg.select(\"article_id\").filter(\n",
    "                self.transactions_fg.customer_id==customer_id\n",
    "            ).read(dataframe_type=\"pandas\").values.reshape(-1).tolist()\n",
    "        )\n",
    "\n",
    "        # Filter candidate items to exclude those already bought by the customer\n",
    "        item_id_list = [\n",
    "            str(item_id)\n",
    "            for item_id in neighbors\n",
    "            if str(item_id) not in already_bought_items_ids\n",
    "        ]\n",
    "        item_id_df = pd.DataFrame({\"article_id\": item_id_list})\n",
    "\n",
    "        # Retrieve Article data for candidate items\n",
    "        articles_data = [\n",
    "            self.articles_fv.get_feature_vector({\"article_id\": item_id})\n",
    "            for item_id in item_id_list\n",
    "        ]\n",
    "\n",
    "        logging.info(\"‚úÖ Articles Data Retrieved!\")\n",
    "\n",
    "        articles_df = pd.DataFrame(\n",
    "            data=articles_data,\n",
    "            columns=self.articles_features,\n",
    "        )\n",
    "\n",
    "        # Join candidate items with their features\n",
    "        ranking_model_inputs = item_id_df.merge(\n",
    "            articles_df,\n",
    "            on=\"article_id\",\n",
    "            how=\"inner\",\n",
    "        )\n",
    "\n",
    "        logging.info(\"‚úÖ Inputs are almost ready!\")\n",
    "\n",
    "        # Add customer features\n",
    "        customer_features = self.customer_fv.get_feature_vector(\n",
    "                {\"customer_id\": customer_id},\n",
    "                return_type=\"pandas\",\n",
    "            )\n",
    "\n",
    "        ranking_model_inputs[\"age\"] = customer_features.age.values[0]\n",
    "        ranking_model_inputs[\"month_sin\"] = inputs[\"month_sin\"]\n",
    "        ranking_model_inputs[\"month_cos\"] = inputs[\"month_cos\"]\n",
    "\n",
    "        # Select only the features required by the ranking model\n",
    "        ranking_model_inputs = ranking_model_inputs[self.ranking_model_feature_names]\n",
    "\n",
    "        logging.info(\"‚úÖ Inputs are ready!\")\n",
    "\n",
    "        features = ranking_model_inputs.values.tolist()\n",
    "        article_ids = item_id_list\n",
    "\n",
    "        # Log the extracted features\n",
    "        logging.info(\"predict -> \" + str(features))\n",
    "\n",
    "        # Log the extracted article ids\n",
    "        logging.info(f'Article IDs: {article_ids}')\n",
    "        \n",
    "        logging.info(f\"üöÄ Predicting...\")\n",
    "\n",
    "        # Predict probabilities for the positive class\n",
    "        scores = self.model.predict_proba(features).tolist()\n",
    "        \n",
    "        # Get scores of positive class\n",
    "        scores = np.asarray(scores)[:,1].tolist() \n",
    "\n",
    "        logging.info(\"‚úÖ Predictions are ready!\")\n",
    "\n",
    "        # Merge prediction scores and corresponding article IDs into a list of tuples\n",
    "        ranking = list(zip(scores, article_ids))\n",
    "\n",
    "        # Sort the ranking list by score in descending order\n",
    "        ranking.sort(reverse=True)\n",
    "\n",
    "        # Return the sorted ranking list\n",
    "        return {\n",
    "            \"ranking\": ranking,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy transformer file into Hopsworks File System\n",
    "uploaded_file_path = dataset_api.upload(\n",
    "    \"recommender_transformer.py\", \n",
    "    \"Models\", \n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# Construct the path to the uploaded script\n",
    "transformer_script_path = os.path.join(\n",
    "    \"/Projects\", \n",
    "    project.name, \n",
    "    uploaded_file_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.transformer import Transformer\n",
    "\n",
    "recommender_deployment_name = \"recommenderdeployment\"\n",
    "\n",
    "# Define transformer\n",
    "recommender_transformer=Transformer(\n",
    "    script_file=transformer_script_path, \n",
    "    resources={\"num_instances\": 0},\n",
    ")\n",
    "\n",
    "# Deploy the query model\n",
    "recommender_deployment = query_model.deploy(\n",
    "    name=recommender_deployment_name,\n",
    "    description=\"Recommender deployment that generates query embeddings from customer and item features using the query model\",\n",
    "    resources={\"num_instances\": 0},\n",
    "    transformer=recommender_transformer,\n",
    "    environment=\"pandas-inference-pipeline\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the deployment and wait for it to be in a running state for up to 300 seconds\n",
    "recommender_deployment.start(await_running=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the next line if you want to see the logs\n",
    "# recommender_deployment.get_logs(component='transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"customer_id\": \"d327d0ad9e30085a436933dfbb7f77cf42e38447993a078ed35d93e3fd350ecf\",\n",
    "        \"date\": \"2022-11-15T12:16:25.330916\",\n",
    "    }\n",
    "]\n",
    "\n",
    "ranked_candidates = recommender_deployment.predict(inputs=data)\n",
    "ranked_candidates[\"predictions\"][\"ranking\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_recommendations(ranked_candidates, k=3):\n",
    "    return [candidate[-1] for candidate in ranked_candidates[\"ranking\"][:k]]\n",
    "\n",
    "\n",
    "# Retrieve article ids of the top recommended items\n",
    "recommendations = get_top_recommendations(ranked_candidates[\"predictions\"], k=3)\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the deployment\n",
    "recommender_deployment.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End the timer\n",
    "notebook_end_time = time.time()\n",
    "\n",
    "# Calculate and print the execution time\n",
    "notebook_execution_time = notebook_end_time - notebook_start_time\n",
    "print(f\"‚åõÔ∏è Notebook Execution time: {notebook_execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
