{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5db0af3",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 03: Model training & UI Exploration</span>\n",
    "\n",
    "<span style=\"font-width:bold; font-size: 1.4rem;\">In this last notebook, we will train a model on the dataset we created in the previous tutorial. We will train our model using standard Python and Scikit-learn, although it could just as well be trained with other machine learning frameworks such as PySpark, TensorFlow, and PyTorch. We will also show some of the exploration that can be done in Hopsworks, notably the search functions and the lineage. </span>\n",
    "\n",
    "## **üóíÔ∏è This notebook is divided in 3 main sections:** \n",
    "1. **Loading the training data**\n",
    "2. **Train the model**\n",
    "3. **Explore feature groups and views** via the UI.\n",
    "\n",
    "![tutorial-flow](../images/03_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79d97c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d8bfb5",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚ú® Load Training Data </span>\n",
    "\n",
    "First, we'll need to fetch the training dataset that we created in the previous notebook. We will use January - February data training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2702114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load data.\n",
    "feature_view = fs.get_feature_view(\"transactions_view\", 1)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = feature_view.get_train_validation_test_splits(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36070a3c",
   "metadata": {},
   "source": [
    "We will train a model to predict `fraud_label` given the rest of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94acc187",
   "metadata": {},
   "source": [
    "Let's check the distribution of our target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dc84cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fraud_label\n",
       "0              0.998545\n",
       "1              0.001455\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546c204",
   "metadata": {},
   "source": [
    "Notice that the distribution is extremely skewed, which is natural considering that fraudulent transactions make up a tiny part of all transactions. Thus we should somehow address the class imbalance. There are many approaches for this, such as weighting the loss function, over- or undersampling, creating synthetic data, or modifying the decision threshold. In this example, we'll use the simplest method which is to just supply a class weight parameter to our learning algorithm. The class weight will affect how much importance is attached to each class, which in our case means that higher importance will be placed on positive (fraudulent) samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fe274e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üèÉ Train Model</span>\n",
    "\n",
    "Next we'll train a model. Here, we set the class weight of the positive class to be twice as big as the negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70bcd17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight={0: 0.09999999999999998, 1: 0.9},\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model.\n",
    "pos_class_weight = 0.9\n",
    "clf = LogisticRegression(class_weight={0: 1.0 - pos_class_weight, 1: pos_class_weight}, solver='liblinear')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bbd9c3",
   "metadata": {},
   "source": [
    "Let's see how well it performs on our validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fbd02f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     21132\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           1.00     21157\n",
      "   macro avg       0.50      0.50      0.50     21157\n",
      "weighted avg       1.00      1.00      1.00     21157\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preds = clf.predict(X_val)\n",
    "\n",
    "print(classification_report(y_val, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e32237f",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">  Use the model to score transactions </span>\n",
    "We trained model based on January - February data. Now lets retrieve March data and score whether transactions are fraudulend or not   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b284826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: No training dataset version was provided to initialise batch scoring . Defaulting to version 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20 09:44:08,897 INFO: USE `robin100_featurestore`\n",
      "2022-06-20 09:44:09,915 INFO: WITH right_fg0 AS (SELECT *\n",
      "FROM (SELECT `fg1`.`category` `category`, `fg1`.`amount` `amount`, `fg1`.`age_at_transaction` `age_at_transaction`, `fg1`.`days_until_card_expires` `days_until_card_expires`, `fg1`.`loc_delta` `loc_delta`, `fg1`.`cc_num` `join_pk_cc_num`, `fg1`.`datetime` `join_evt_datetime`, `fg0`.`trans_volume_mstd` `trans_volume_mstd`, `fg0`.`trans_volume_mavg` `trans_volume_mavg`, `fg0`.`trans_freq` `trans_freq`, `fg0`.`loc_delta_mavg` `loc_delta_mavg`, RANK() OVER (PARTITION BY `fg1`.`cc_num`, `fg1`.`datetime` ORDER BY `fg0`.`datetime` DESC) pit_rank_hopsworks\n",
      "FROM `robin100_featurestore`.`transactions_1` `fg1`\n",
      "INNER JOIN `robin100_featurestore`.`transactions_4h_aggs_1` `fg0` ON `fg1`.`cc_num` = `fg0`.`cc_num` AND `fg1`.`datetime` >= `fg0`.`datetime`\n",
      "WHERE `fg1`.`datetime` >= 1641164401000 AND `fg1`.`datetime` <= 1648763999000) NA\n",
      "WHERE `pit_rank_hopsworks` = 1) (SELECT `right_fg0`.`category` `category`, `right_fg0`.`amount` `amount`, `right_fg0`.`age_at_transaction` `age_at_transaction`, `right_fg0`.`days_until_card_expires` `days_until_card_expires`, `right_fg0`.`loc_delta` `loc_delta`, `right_fg0`.`trans_volume_mstd` `trans_volume_mstd`, `right_fg0`.`trans_volume_mavg` `trans_volume_mavg`, `right_fg0`.`trans_freq` `trans_freq`, `right_fg0`.`loc_delta_mavg` `loc_delta_mavg`\n",
      "FROM right_fg0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "date_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "# Create training datasets based event time filter\n",
    "start_time = int(float(datetime.strptime(\"2022-01-03 00:00:01\", date_format).timestamp()) * 1000)\n",
    "end_time = int(float(datetime.strptime(\"2022-03-31 23:59:59\", date_format).timestamp()) * 1000)\n",
    "\n",
    "march_transactions = feature_view.get_batch_data(start_time = start_time,  end_time = end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98ade6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "      <th>age_at_transaction</th>\n",
       "      <th>days_until_card_expires</th>\n",
       "      <th>loc_delta</th>\n",
       "      <th>trans_volume_mstd</th>\n",
       "      <th>trans_volume_mavg</th>\n",
       "      <th>trans_freq</th>\n",
       "      <th>loc_delta_mavg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.003120</td>\n",
       "      <td>0.091597</td>\n",
       "      <td>0.139747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003120</td>\n",
       "      <td>0.003120</td>\n",
       "      <td>0.003120</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>0.091615</td>\n",
       "      <td>0.139474</td>\n",
       "      <td>0.122200</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>0.135041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.091622</td>\n",
       "      <td>0.139367</td>\n",
       "      <td>0.120125</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.132748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.091628</td>\n",
       "      <td>0.139291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.066374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.091725</td>\n",
       "      <td>0.137862</td>\n",
       "      <td>0.040270</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.044502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102997</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.357364</td>\n",
       "      <td>0.481294</td>\n",
       "      <td>0.228904</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.252957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102998</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.357399</td>\n",
       "      <td>0.480778</td>\n",
       "      <td>0.166719</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.184238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102999</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>0.357403</td>\n",
       "      <td>0.480721</td>\n",
       "      <td>0.166874</td>\n",
       "      <td>0.002875</td>\n",
       "      <td>0.002875</td>\n",
       "      <td>0.002875</td>\n",
       "      <td>0.184323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103000</th>\n",
       "      <td>0</td>\n",
       "      <td>0.010322</td>\n",
       "      <td>0.357470</td>\n",
       "      <td>0.479735</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.010322</td>\n",
       "      <td>0.010322</td>\n",
       "      <td>0.010322</td>\n",
       "      <td>0.001270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103001</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.357604</td>\n",
       "      <td>0.477760</td>\n",
       "      <td>0.166690</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.184206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103002 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        category    amount  age_at_transaction  days_until_card_expires  \\\n",
       "0              4  0.003120            0.091597                 0.139747   \n",
       "1              2  0.002173            0.091615                 0.139474   \n",
       "2              4  0.000008            0.091622                 0.139367   \n",
       "3              4  0.000047            0.091628                 0.139291   \n",
       "4              4  0.000659            0.091725                 0.137862   \n",
       "...          ...       ...                 ...                      ...   \n",
       "102997         0  0.000736            0.357364                 0.481294   \n",
       "102998         0  0.002816            0.357399                 0.480778   \n",
       "102999         0  0.002934            0.357403                 0.480721   \n",
       "103000         0  0.010322            0.357470                 0.479735   \n",
       "103001         0  0.000592            0.357604                 0.477760   \n",
       "\n",
       "        loc_delta  trans_volume_mstd  trans_volume_mavg  trans_freq  \\\n",
       "0        0.000000           0.003120           0.003120    0.003120   \n",
       "1        0.122200           0.002173           0.002173    0.002173   \n",
       "2        0.120125           0.000008           0.000008    0.000008   \n",
       "3        0.000000           0.000028           0.000028    0.000028   \n",
       "4        0.040270           0.000659           0.000659    0.000659   \n",
       "...           ...                ...                ...         ...   \n",
       "102997   0.228904           0.000736           0.000736    0.000736   \n",
       "102998   0.166719           0.002816           0.002816    0.002816   \n",
       "102999   0.166874           0.002875           0.002875    0.002875   \n",
       "103000   0.001149           0.010322           0.010322    0.010322   \n",
       "103001   0.166690           0.000592           0.000592    0.000592   \n",
       "\n",
       "        loc_delta_mavg  \n",
       "0             0.000000  \n",
       "1             0.135041  \n",
       "2             0.132748  \n",
       "3             0.066374  \n",
       "4             0.044502  \n",
       "...                ...  \n",
       "102997        0.252957  \n",
       "102998        0.184238  \n",
       "102999        0.184323  \n",
       "103000        0.001270  \n",
       "103001        0.184206  \n",
       "\n",
       "[103002 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "march_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf708c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(march_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9c42003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c6b712",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <span style=\"color:#ff5f27;\"> üëì  Exploration</span>\n",
    "In the Hopsworks feature store, the metadata allows for multiple levels of explorations and review. Here we will show a few of those capacities. \n",
    "\n",
    "### üîé <b>Search</b> \n",
    "Using the search function in the ui, you can query any aspect of the feature groups, feature_view and training data that was previously created.\n",
    "\n",
    "### üìä <b>Statistics</b> \n",
    "We can also enable statistics in one or all the feature groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b1eed95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics Job started successfully, you can follow the progress at https://c.app.hopsworks.ai/p/124/jobs/named/transactions_1_compute_stats_20062022074522/executions\n"
     ]
    }
   ],
   "source": [
    "trans_fg = fs.get_feature_group(\"transactions\", version = 1)\n",
    "trans_fg.statistics_config = {\n",
    "    \"enabled\": True,\n",
    "    \"histograms\": True,\n",
    "    \"correlations\": True\n",
    "}\n",
    "\n",
    "trans_fg.update_statistics_config()\n",
    "trans_fg.compute_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9d4ce0",
   "metadata": {},
   "source": [
    "![fg-statistics](../images/fg_statistics.gif)\n",
    "\n",
    "\n",
    "### ‚õìÔ∏è <b> Lineage </b> \n",
    "In all the feature groups and feature view you can look at the relation between each abstractions; what feature group created which training dataset and that is used in which model.\n",
    "This allows for a clear undestanding of the pipeline in relation to each element. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee42a342",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üéÅ  Wrapping things up </span>\n",
    "\n",
    "We have now performed a simple training with training data that we have created in the feature store. This concludes the fisrt module and introduction to the core aspect of the feauture store. In the second module we will introduce streaming and external feature groups for a similar fraud use case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
