{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83dd6e7e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üìù Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b0a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U kaleido # For Plotly Image export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8355be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "import joblib\n",
    "from features.price import plot_prediction_test\n",
    "from functions import predict_id\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbea0ad",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üîÆ Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e499f528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c6c942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "averages_fg = fs.get_feature_group(\n",
    "    name='averages',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "price_fg = fs.get_feature_group(\n",
    "    name='price',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e72db48",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üî™ Feature Selection </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0740ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for training data\n",
    "selected_features = price_fg.select_all() \\\n",
    "    .join(averages_fg.select_except(['date']))\n",
    "\n",
    "# Uncomment this if you would like to view your selected features\n",
    "# selected_features.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1334a4cb",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">ü§ñ Transformation Functions </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccb7d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transformation function\n",
    "min_max_scaler = fs.get_transformation_function(name=\"min_max_scaler\")\n",
    "\n",
    "# Define a list of feature names\n",
    "feature_names = [\n",
    "    'ma_7', 'ma_14', 'ma_30', 'daily_rate_of_change', 'volatility_30_day', 'ema_02', 'ema_05', 'rsi'\n",
    "]\n",
    "\n",
    "# Map features to transformations\n",
    "transformation_functions = {\n",
    "    feature_name: min_max_scaler\n",
    "    for feature_name in feature_names\n",
    "}\n",
    "transformation_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925ad679",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">‚öôÔ∏è Feature View Creation </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdfda5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create the 'price_fv' feature view\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name='price_fv',\n",
    "    version=1,\n",
    "    query=selected_features,\n",
    "    labels=[\"price\"],\n",
    "    transformation_functions=transformation_functions,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e1170",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üèãÔ∏è Training Dataset Creation </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554cbace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and testing sets\n",
    "X_train, X_test, y_train, y_test = feature_view.train_test_split(\n",
    "    description='Prices Dataset',  # Provide a description for the dataset split\n",
    "    train_start='2022-09-01',      # Start date for the training set\n",
    "    train_end='2023-07-01',        # End date for the training set\n",
    "    test_start='2023-07-01',       # Start date for the testing set\n",
    "    test_end=datetime.today().strftime(\"%Y-%m-%d\"),  # End date for the testing set (current date)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041666ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7315f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af817399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the training features by the 'date' column\n",
    "X_train = X_train.sort_values(\"date\")\n",
    "\n",
    "# Reindex the target 'y_train' to match the sorted order of 'X_train'\n",
    "y_train = y_train.reindex(X_train.index)\n",
    "\n",
    "# Sort the testing features by the 'date' column\n",
    "X_test = X_test.sort_values(\"date\")\n",
    "\n",
    "# Reindex the target 'y_test' to match the sorted order of 'X_test'\n",
    "y_test = y_test.reindex(X_test.index)\n",
    "\n",
    "# Extract and store the 'date' column as a separate DataFrame for both training and testing sets\n",
    "train_date = pd.DataFrame(X_train.pop(\"date\"))\n",
    "test_date = pd.DataFrame(X_test.pop(\"date\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7d0253",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üß¨ Modeling </span>\n",
    "\n",
    "We will use the XGBoost Regressor. XGBoost regressor is a powerful and highly effective machine learning algorithm for regression problems. XGBoost is known for its ability to handle complex relationships in the data, handle missing values, and provide accurate predictions. It's a popular choice in the data science community due to its robustness and excellent predictive performance, making it well-suited for our specific problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a999d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the XGBoost regressor\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE on the validation set\n",
    "mse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0f556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for a specific ID (ID=1) using the 'predict_id' function\n",
    "prediction_for_id = predict_id(\n",
    "    1, \n",
    "    X_test, \n",
    "    model,\n",
    ")\n",
    "\n",
    "# Generate a Plotly figure for visualizing the predictions\n",
    "fig = plot_prediction_test(\n",
    "    1, \n",
    "    X_train, \n",
    "    X_test, \n",
    "    y_train, \n",
    "    y_test, \n",
    "    train_date, \n",
    "    test_date, \n",
    "    prediction_for_id,\n",
    ")\n",
    "\n",
    "# Display the generated Plotly figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558799fa",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">‚öôÔ∏è Model Schema </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b490e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "# Create an input schema using the training features\n",
    "input_schema = Schema(X_train.values)\n",
    "\n",
    "# Create an output schema using the target variable\n",
    "output_schema = Schema(y_train)\n",
    "\n",
    "# Create a model schema using the input and output schemas\n",
    "model_schema = ModelSchema(\n",
    "    input_schema=input_schema, \n",
    "    output_schema=output_schema,\n",
    ")\n",
    "\n",
    "# Convert the model schema to a dictionary\n",
    "model_schema.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e8f511",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üìù Register model </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb397a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory for saving the model\n",
    "model_dir = \"price_model\"\n",
    "\n",
    "# Check if the directory exists, and create it if not\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "# Save the trained XGBoost model using joblib\n",
    "joblib.dump(model, f'{model_dir}/xgboost_price_model.pkl')\n",
    "\n",
    "# Write the generated Plotly figure image to the specified directory\n",
    "fig.write_image(f'{model_dir}/model_prediction.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782f9731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model registry from the project\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# Create a Python model in the model registry named 'xgboost_price_model'\n",
    "price_model = mr.python.create_model(\n",
    "    name=\"xgboost_price_model\", \n",
    "    metrics={\"MSE\": mse},           # Specify metrics (Mean Squared Error)\n",
    "    model_schema=model_schema,      # Provide the model schema\n",
    "    input_example=X_train.sample(), # Provide an example of the input data\n",
    "    description=\"Price Predictor\",  # Add a description for the model\n",
    ")\n",
    "\n",
    "# Save the model to the specified directory\n",
    "price_model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bfb99f",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üöÄ Model Deployment</span>\n",
    "\n",
    "**About Model Serving**\n",
    "\n",
    "Models can be served via KFServing or \"default\" serving, which means a Docker container exposing a Flask server. For KFServing models, or models written in Tensorflow, you do not need to write a prediction file (see the section below). However, for sklearn models using default serving, you do need to proceed to write a prediction file.\n",
    "\n",
    "In order to use KFServing, you must have Kubernetes installed and enabled on your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4017c8e4",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üìé Predictor script for Python models</span>\n",
    "\n",
    "Scikit-learn and XGBoost models are deployed as Python models, in which case you need to provide a Predict class that implements the predict method. The `predict()` method invokes the model on the inputs and returns the prediction as a list.\n",
    "\n",
    "The `init()` method is run when the predictor is loaded into memory, loading the model from the local directory it is materialized to, ARTIFACT_FILES_PATH.\n",
    "\n",
    "The directive **\"%%writefile\"** writes out the cell before to the given Python file. We will use the **predict_example.py** file to create a deployment for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a97ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile predict_example.py\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hsfs\n",
    "import joblib\n",
    "\n",
    "\n",
    "class Predict(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Initializes the serving state, reads a trained model\"\"\"        \n",
    "        # get feature store handle\n",
    "        fs_conn = hsfs.connection()\n",
    "        self.fs = fs_conn.get_feature_store()\n",
    "        \n",
    "        # get feature view\n",
    "        self.fv = self.fs.get_feature_view(\"price_fv\", 1)\n",
    "        \n",
    "        # initialize serving\n",
    "        self.fv.init_serving(1)\n",
    "\n",
    "        # load the trained model\n",
    "        self.model = joblib.load(os.environ[\"ARTIFACT_FILES_PATH\"] + \"/xgboost_price_model.pkl\")\n",
    "        print(\"Initialization Complete\")\n",
    "\n",
    "    \n",
    "    def predict(self, id_value):\n",
    "        \"\"\" Serves a prediction request usign a trained model\"\"\"\n",
    "        # Retrieve feature vectors\n",
    "        feature_vector = self.fv.get_feature_vector(\n",
    "            entry = {'id': id_value[0]}\n",
    "        )\n",
    "        return self.model.predict(np.asarray(feature_vector[1:]).reshape(1, -1)).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b979582c",
   "metadata": {},
   "source": [
    "This script needs to be put into a known location in the Hopsworks file system. Let's call the file predict_example.py and put it in the Models directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64048e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset API from the project\n",
    "dataset_api = project.get_dataset_api()\n",
    "\n",
    "# Upload the file \"predict_example.py\" to the \"Models\" dataset, overwriting if it already exists\n",
    "uploaded_file_path = dataset_api.upload(\"predict_example.py\", \"Models\", overwrite=True)\n",
    "\n",
    "# Create the full path to the uploaded predictor script\n",
    "predictor_script_path = os.path.join(\"/Projects\", project.name, uploaded_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7cea10",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf59ec95",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üöÄ Create the deployment</span>\n",
    "\n",
    "Here, you fetch the model you want from the model registry and define a configuration for the deployment. For the configuration, you need to specify the serving type (default or KFserving)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f98e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the 'price_model'\n",
    "deployment = price_model.deploy(\n",
    "    name=\"priceonlinemodeldeployment\",  # Specify the deployment name\n",
    "    script_file=predictor_script_path,  # Provide the path to the predictor script\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86154683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the deployment and wait for it up to 360 seconds\n",
    "deployment.start(await_running=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e5b6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current state of the deployment and describe it\n",
    "deployment_state = deployment.get_state().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea906d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict price for the 1 ID\n",
    "deployment.predict({'instances': [1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1354c27a",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
