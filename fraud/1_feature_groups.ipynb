{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96ab8e57",
   "metadata": {},
   "source": [
    "## Feature Groups\n",
    "\n",
    "In this series of tutorials, we will work with data related to credit card transactions. The end goal is to train and serve a model on the Hopsworks platform that can predict whether a credit card transaction is fraudulent or not.\n",
    "\n",
    "In this particular notebook you will learn how to:\n",
    "- Connect to the Hopsworks feature store.\n",
    "- Create feature groups and upload them to the feature store.\n",
    "\n",
    "![tutorial-flow](images/online_offline_fs.png)\n",
    "\n",
    "First of all we will load the data and do some feature engineering on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2eeee6",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "The data we will use comes from three different CSV files:\n",
    "\n",
    "- `credit_cards.csv`: credit card information such as expiration date and provider.\n",
    "- `transactions.csv`: transaction information such as timestamp, location, and the amount. Importantly, the binary `fraud_label` variable tells us whether a transaction was fraudulent or not.\n",
    "- `profiles.csv`: credit card user information such as birthdate and city of residence.\n",
    "\n",
    "We can conceptualize these CSV files as originating from separate data sources. All three files have a credit card number column `cc_num` in common, which we can use for joins.\n",
    "\n",
    "Let's go ahead and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "796876fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc_num</th>\n",
       "      <th>provider</th>\n",
       "      <th>expires</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4031433455074417</td>\n",
       "      <td>visa</td>\n",
       "      <td>02/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4436104537406320</td>\n",
       "      <td>visa</td>\n",
       "      <td>08/24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4571305563689391</td>\n",
       "      <td>visa</td>\n",
       "      <td>02/21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cc_num provider expires\n",
       "0  4031433455074417     visa   02/25\n",
       "1  4436104537406320     visa   08/24\n",
       "2  4571305563689391     visa   02/21"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from hops import hdfs\n",
    "\n",
    "credit_cards_df = pd.read_csv(\"hdfs:///Projects/{}/Jupyter/fraud_detection/data/credit_cards.csv\".format(hdfs.project_name()))\n",
    "credit_cards_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae158c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>mail</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>cc_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Teresa Smith</td>\n",
       "      <td>F</td>\n",
       "      <td>kevin70@yahoo.com</td>\n",
       "      <td>1972-11-07</td>\n",
       "      <td>Camarillo</td>\n",
       "      <td>US</td>\n",
       "      <td>4031433455074417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Luis Hays</td>\n",
       "      <td>M</td>\n",
       "      <td>kevinstewart@hotmail.com</td>\n",
       "      <td>1995-07-28</td>\n",
       "      <td>Troutdale</td>\n",
       "      <td>US</td>\n",
       "      <td>4436104537406320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kyle Clark</td>\n",
       "      <td>M</td>\n",
       "      <td>davidflores@gmail.com</td>\n",
       "      <td>1954-12-30</td>\n",
       "      <td>Fort Washington</td>\n",
       "      <td>US</td>\n",
       "      <td>4571305563689391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name sex                      mail  birthdate             City  \\\n",
       "0  Teresa Smith   F         kevin70@yahoo.com 1972-11-07        Camarillo   \n",
       "1     Luis Hays   M  kevinstewart@hotmail.com 1995-07-28        Troutdale   \n",
       "2    Kyle Clark   M     davidflores@gmail.com 1954-12-30  Fort Washington   \n",
       "\n",
       "  Country            cc_num  \n",
       "0      US  4031433455074417  \n",
       "1      US  4436104537406320  \n",
       "2      US  4571305563689391  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles_df = pd.read_csv(\"hdfs:///Projects/{}/Jupyter/fraud_detection/data/profiles.csv\".format(hdfs.project_name()), parse_dates=[\"birthdate\"])\n",
    "profiles_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4545cb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>datetime</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>fraud_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1dd7b2061b55605752f2341da8023052</td>\n",
       "      <td>2022-01-01 00:00:01</td>\n",
       "      <td>4118331283232304</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>47.45</td>\n",
       "      <td>40.72816</td>\n",
       "      <td>-74.07764</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7bea269b287488ccaab3518fb0b727ea</td>\n",
       "      <td>2022-01-01 00:00:01</td>\n",
       "      <td>4924509525462045</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>8.13</td>\n",
       "      <td>33.93113</td>\n",
       "      <td>-117.54866</td>\n",
       "      <td>Norco</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5c7ba1b8a82e0163c61e0b70a7edf1dd</td>\n",
       "      <td>2022-01-01 00:00:02</td>\n",
       "      <td>4329509775617760</td>\n",
       "      <td>Domestic Transport</td>\n",
       "      <td>91.95</td>\n",
       "      <td>40.34912</td>\n",
       "      <td>-111.90466</td>\n",
       "      <td>Saratoga Springs</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                tid            datetime            cc_num  \\\n",
       "0  1dd7b2061b55605752f2341da8023052 2022-01-01 00:00:01  4118331283232304   \n",
       "1  7bea269b287488ccaab3518fb0b727ea 2022-01-01 00:00:01  4924509525462045   \n",
       "2  5c7ba1b8a82e0163c61e0b70a7edf1dd 2022-01-01 00:00:02  4329509775617760   \n",
       "\n",
       "             category  amount  latitude  longitude              city country  \\\n",
       "0             Grocery   47.45  40.72816  -74.07764       Jersey City      US   \n",
       "1             Grocery    8.13  33.93113 -117.54866             Norco      US   \n",
       "2  Domestic Transport   91.95  40.34912 -111.90466  Saratoga Springs      US   \n",
       "\n",
       "   fraud_label  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_df = pd.read_csv(\n",
    "    \"hdfs:///Projects/{}/Jupyter/fraud_detection/data/transactions.csv.zip\".format(hdfs.project_name()),\n",
    "    parse_dates=[\"datetime\"])\n",
    "trans_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ee39bf",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Fraudulent transactions can differ from regular ones in many different ways. Typical red flags would for instance be a large transaction volume/frequency in the span of a few hours. It could also be the case that elderly people in particular are targeted by fraudsters. To facilitate model learning we will create additional features based on these patterns. In particular, we will create two types of features:\n",
    "1. Features that aggregate data from different data sources. This could for instance be the age of a customer at the time of a transaction, which combines the `birthdate` feature from `profiles.csv` with the `datetime` feature from `transactions.csv`.\n",
    "2. Features that aggregate data from multiple time steps. An example of this could be the transaction frequency of a credit card in the span of a few hours, which is computed using a window function.\n",
    "\n",
    "Let's start with the first category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ddc67b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_at_transaction</th>\n",
       "      <th>days_until_card_expires</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.346961</td>\n",
       "      <td>-579.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.058817</td>\n",
       "      <td>1856.999988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.780543</td>\n",
       "      <td>1154.999977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.740303</td>\n",
       "      <td>1825.999931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.717065</td>\n",
       "      <td>-214.000139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_at_transaction  days_until_card_expires\n",
       "0           30.346961              -579.000012\n",
       "1           31.058817              1856.999988\n",
       "2           45.780543              1154.999977\n",
       "3           52.740303              1825.999931\n",
       "4           87.717065              -214.000139"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute age at transaction.\n",
    "age_df = trans_df.merge(profiles_df, on=\"cc_num\", how=\"left\")\n",
    "trans_df[\"age_at_transaction\"] = (age_df[\"datetime\"] - age_df[\"birthdate\"]) / np.timedelta64(1, \"Y\")\n",
    "\n",
    "# Compute days until card expires.\n",
    "card_expiry_df = trans_df.merge(credit_cards_df, on=\"cc_num\", how=\"left\")\n",
    "card_expiry_df[\"expires\"] = pd.to_datetime(card_expiry_df[\"expires\"], format=\"%m/%y\")\n",
    "trans_df[\"days_until_card_expires\"] = (card_expiry_df[\"expires\"] - card_expiry_df[\"datetime\"]) / np.timedelta64(1, \"D\")\n",
    "\n",
    "trans_df[[\"age_at_transaction\", \"days_until_card_expires\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6687d5",
   "metadata": {},
   "source": [
    "Next, we create features that for each credit card aggregate data from multiple time steps.\n",
    "\n",
    "We start by computing the distance between consecutive transactions, which we will call `loc_delta`.\n",
    "Here we use the [Haversine distance](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.haversine_distances.html?highlight=haversine#sklearn.metrics.pairwise.haversine_distances) to quantify the distance between two longitude and latitude coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8a823f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians\n",
    "\n",
    "# Do some simple preprocessing.\n",
    "trans_df.sort_values(\"datetime\", inplace=True)\n",
    "trans_df[[\"longitude\", \"latitude\"]] = trans_df[[\"longitude\", \"latitude\"]].applymap(radians)\n",
    "\n",
    "def haversine(long, lat):\n",
    "    \"\"\"Compute Haversine distance between each consecutive coordinate in (long, lat).\"\"\"\n",
    "\n",
    "    long_shifted = long.shift()\n",
    "    lat_shifted = lat.shift()\n",
    "    long_diff = long_shifted - long\n",
    "    lat_diff = lat_shifted - lat\n",
    "\n",
    "    a = np.sin(lat_diff/2.0)**2\n",
    "    b = np.cos(lat) * np.cos(lat_shifted) * np.sin(long_diff/2.0)**2\n",
    "    c = 2*np.arcsin(np.sqrt(a + b))\n",
    "\n",
    "    return c\n",
    "\n",
    "\n",
    "trans_df[\"loc_delta\"] = trans_df.groupby(\"cc_num\")\\\n",
    "    .apply(lambda x : haversine(x[\"longitude\"], x[\"latitude\"]))\\\n",
    "    .reset_index(level=0, drop=True)\\\n",
    "    .fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f89a34f",
   "metadata": {},
   "source": [
    "Next we compute windowed aggregates. Here we will use 4-hour windows, but feel free to experiment with different window lengths by setting `window_len` below to a value of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32d198e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>trans_volume_mavg</th>\n",
       "      <th>trans_volume_mstd</th>\n",
       "      <th>trans_freq</th>\n",
       "      <th>loc_delta_mavg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>557272</th>\n",
       "      <td>8fcb8bb87f0edfe2464f49e0b3b49a31</td>\n",
       "      <td>63.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595763</th>\n",
       "      <td>c615c36e298e4ce00238484a93b581ae</td>\n",
       "      <td>585.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641178</th>\n",
       "      <td>f0150f187cc462f7f649a4a8e13af28f</td>\n",
       "      <td>48.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605906</th>\n",
       "      <td>bbd562425595518ec5d97ca41400aef9</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648097</th>\n",
       "      <td>1a348f9ce0477c264edd70cff9a46beb</td>\n",
       "      <td>11.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     tid  trans_volume_mavg  \\\n",
       "557272  8fcb8bb87f0edfe2464f49e0b3b49a31              63.97   \n",
       "595763  c615c36e298e4ce00238484a93b581ae             585.64   \n",
       "641178  f0150f187cc462f7f649a4a8e13af28f              48.72   \n",
       "605906  bbd562425595518ec5d97ca41400aef9               1.42   \n",
       "648097  1a348f9ce0477c264edd70cff9a46beb              11.82   \n",
       "\n",
       "        trans_volume_mstd  trans_freq  loc_delta_mavg  \n",
       "557272                0.0         1.0        0.000170  \n",
       "595763                0.0         1.0        0.000096  \n",
       "641178                0.0         1.0        0.000098  \n",
       "605906                0.0         1.0        0.000034  \n",
       "648097                0.0         1.0        0.000089  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_len = \"4h\"\n",
    "cc_group = trans_df.groupby(\"cc_num\")\n",
    "\n",
    "# Create dataframe for window aggregations.\n",
    "window_aggs_df = pd.DataFrame()\n",
    "window_aggs_df[\"tid\"] = trans_df[\"tid\"]\n",
    "\n",
    "# Moving average of transaction volume.\n",
    "window_aggs_df['trans_volume_mavg'] = cc_group[[\"datetime\", \"amount\"]]\\\n",
    "    .rolling(window_len, on=\"datetime\")\\\n",
    "    .mean()\\\n",
    "    .reset_index(level=0, drop=True)\\\n",
    "    .drop(columns=[\"datetime\"])\n",
    "\n",
    "# Moving standard deviation of transaction volume.\n",
    "window_aggs_df['trans_volume_mstd'] = cc_group[[\"datetime\", \"amount\"]]\\\n",
    "    .rolling(window_len, on=\"datetime\")\\\n",
    "    .std()\\\n",
    "    .reset_index(level=0, drop=True)\\\n",
    "    .drop(columns=[\"datetime\"])\\\n",
    "    .fillna(0)\n",
    "\n",
    "# Moving average of transaction frequency.\n",
    "window_aggs_df['trans_freq'] = cc_group[[\"datetime\", \"tid\"]]\\\n",
    "    .rolling(window_len, on=\"datetime\")\\\n",
    "    .count()\\\n",
    "    .reset_index(level=0, drop=True)\\\n",
    "    .drop(columns=[\"datetime\"])\n",
    "\n",
    "# Moving average of location difference between consecutive transactions.\n",
    "window_aggs_df[\"loc_delta_mavg\"] = cc_group[[\"datetime\", \"loc_delta\"]]\\\n",
    "    .rolling(window_len, on=\"datetime\")\\\n",
    "    .mean()\\\n",
    "    .reset_index(level=0, drop=True)\\\n",
    "    .drop(columns=[\"datetime\"])\n",
    "\n",
    "window_aggs_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88a0774",
   "metadata": {},
   "source": [
    "#### Creating Feature Groups\n",
    "\n",
    "A [feature group](https://docs.hopsworks.ai/feature-store-api/latest/generated/feature_group/) can be seen as a collection of conceptually related features. In our case, we will create a feature group for the transaction data and a feature group for the windowed aggregations on the transaction data. Both will have `tid` as primary key, which will allow us to join them when creating a dataset in the next tutorial.\n",
    "\n",
    "Feature groups can also be used to define a namespace for features. For instance, in a real-life setting we would likely want to experiment with different window lengths. In that case, we can create feature groups with identical schema for each window length. \n",
    "\n",
    "Before we can create a feature group we need to connect to our feature store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c78215f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "\n",
    "conn = hsfs.connection()\n",
    "fs = conn.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8ce94c",
   "metadata": {},
   "source": [
    "To create a feature group we need to give it a name and specify a primary key. It is also good to provide a description of the contents of the feature group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6611c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO do we really need event_time??\n",
    "# Not sure if we will actually do a point in time split...,\n",
    "# or if it's needed for the chronological split.\n",
    "\n",
    "trans_fg = fs.create_feature_group(\n",
    "    name=\"transactions\",\n",
    "    description=\"Transaction data.\",\n",
    "    primary_key=['tid'],\n",
    "    online_enabled=True,\n",
    "    event_time=['datetime']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee81597f",
   "metadata": {},
   "source": [
    "Here we have also set `online_enabled=True`, which enables low latency access to the data. A full list of arguments can be found in the [documentation](https://docs.hopsworks.ai/feature-store-api/latest/generated/api/feature_store_api/#create_feature_group).\n",
    "\n",
    "At this point, we have only specified some metadata for the feature group. It does not store any data or even have a schema defined for the data. To make the feature group persistent we populate it with its associated data using the `save` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc7b2b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_fg.save(trans_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1920f4",
   "metadata": {},
   "source": [
    "Let's do the same thing for the feature group with windowed aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b134c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_aggs_fg = fs.create_feature_group(\n",
    "    name=f\"transactions_{window_len}_aggs\",\n",
    "    description=f\"Aggregate transaction data over {window_len} windows.\",\n",
    "    primary_key=[\"tid\"],\n",
    "    online_enabled=True,\n",
    ")\n",
    "window_aggs_fg.save(window_aggs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9981014",
   "metadata": {},
   "source": [
    "You should now be able to inspect the feature groups in the Hopsworks UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc2d23b",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "In the next notebook we will use our feature groups to create a dataset we can train a model on."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}