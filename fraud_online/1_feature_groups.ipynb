{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "debc8314",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"../images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 01: Load, Engineer & Connect</span>\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/logicalclocks/hopsworks-tutorials/blob/master/fraud_online/1_feature_groups.ipynb)\n",
    "\n",
    "**Note**: you may get an error when installing hopsworks on Colab, and it is safe to ignore it.\n",
    "\n",
    "This is the first part of the quick start series of tutorials about Hopsworks Feature Store. As part of this first module, you will work with data related to credit card transactions. \n",
    "The objective of this tutorial is to demonstrate how to work with the **Hopworks Feature Store**  for online data with a goal of training and deploying a model that can predict fraudulent transactions.\n",
    "\n",
    "\n",
    "## üóíÔ∏è This notebook is divided in 3 sections:\n",
    "1. Loading the data and feature engineeing,\n",
    "2. Connect to the Hopsworks Feature Store,\n",
    "3. Create feature groups and upload them to the Feature Store.\n",
    "\n",
    "![tutorial-flow](../images/01_featuregroups.png)\n",
    "\n",
    "First of all you will load the data and do some feature engineering on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63616634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Mute warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfde2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U hopsworks --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38b023c",
   "metadata": {},
   "source": [
    "First of all you will load the data and do some feature engineering on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ad6b6b",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üíΩ Loading the Data </span>\n",
    "\n",
    "The data you will use comes from 2 different CSV files:\n",
    "\n",
    "- `transactions.csv`: events containing information about when a credit card was used, such as a timestamp, location, and the amount spent. A boolean fraud_label variable (True/False) tells us whether a transaction was fraudulent or not.\n",
    "- `profiles.csv`: credit card user information such as birthdate and city of residence.\n",
    "\n",
    "In a production system, these CSV files would originate from separate data sources or tables, and probably separate data pipelines. **These files have a common credit card number column cc_num, which you will use later to join features together from the different datasets.**\n",
    "\n",
    "Now, you can go ahead and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b9ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_df = pd.read_csv(\"https://repo.hops.works/master/hopsworks-tutorials/data/card_fraud_online/profiles.csv\", parse_dates=[\"birthdate\"])\n",
    "profiles_df.columns = [\"name\", \"gender\", \"mail\", \"birthdate\", \"City\", \"Country\", \"cc_num\"]\n",
    "profiles_df = profiles_df[[\"cc_num\", \"gender\"]]\n",
    "profiles_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eb13d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df = pd.read_csv(\"https://repo.hops.works/master/hopsworks-tutorials/data/card_fraud_online/transactions.csv\", parse_dates=[\"datetime\"])\n",
    "trans_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee728353",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df = trans_df[trans_df.category == \"Cash Withdrawal\"].reset_index(level=0, drop=True)\n",
    "trans_df[\"country\"] = trans_df[\"country\"].fillna(\"US\")\n",
    "profiles_df = profiles_df[profiles_df.cc_num.isin(trans_df.cc_num.unique())].reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1970d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df.sort_values([\"datetime\",\"cc_num\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cca817",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c67522",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üõ†Ô∏è Feature Engineering </span>\n",
    "\n",
    "Fraudulent transactions can differ from regular ones in many different ways. Typical red flags would for instance be a large transaction volume/frequency in the span of a few hours. It could also be the case that elderly people in particular are targeted by fraudsters. To facilitate model learning you will create additional features based on these patterns. In particular, you will create two types of features:\n",
    "1. **Features that aggregate data from different data sources**. This could for instance be the age of a customer at the time of a transaction, which combines the `birthdate` feature from `profiles.csv` with the `datetime` feature from `transactions.csv`.\n",
    "2. **Features that aggregate data from multiple time steps**. An example of this could be the transaction frequency of a credit card in the span of a few hours, which is computed using a window function.\n",
    "\n",
    "Let's start with the first category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983ef759",
   "metadata": {},
   "source": [
    "Now you are ready to start by computing the distance between consecutive transactions, lets call it `loc_delta`.\n",
    "Here you will use the [Haversine distance](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.haversine_distances.html?highlight=haversine#sklearn.metrics.pairwise.haversine_distances) to quantify the distance between two longitude and latitude coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering.\n",
    "trans_df.sort_values(\"datetime\", inplace=True)\n",
    "trans_df[[\"longitude\", \"latitude\"]] = trans_df[[\"longitude\", \"latitude\"]].applymap(radians)\n",
    "\n",
    "def haversine(long, lat, shift):\n",
    "    \"\"\"Compute Haversine distance between each consecutive coordinate in (long, lat).\"\"\"\n",
    "\n",
    "    long_shifted = long.shift(shift)\n",
    "    lat_shifted = lat.shift(shift)\n",
    "    long_diff = long_shifted - long\n",
    "    lat_diff = lat_shifted - lat\n",
    "\n",
    "    a = np.sin(lat_diff/2.0)**2\n",
    "    b = np.cos(lat) * np.cos(lat_shifted) * np.sin(long_diff/2.0)**2\n",
    "    c = 2*np.arcsin(np.sqrt(a + b))\n",
    "\n",
    "    return c\n",
    "\n",
    "def time_delta(datetime_value, shift):\n",
    "    \"\"\"Compute time difference between each consecutive transaction.\"\"\"\n",
    "\n",
    "    time_shifted = datetime_value.shift(shift)\n",
    "    return time_shifted\n",
    "\n",
    "trans_df[\"loc_delta_t_plus_1\"] = trans_df.groupby(\"cc_num\")\\\n",
    "    .apply(lambda x : haversine(x[\"longitude\"], x[\"latitude\"], 1))\\\n",
    "    .reset_index(level=0, drop=True)\\\n",
    "    .fillna(0)\n",
    "\n",
    "trans_df[\"loc_delta_t_minus_1\"] = trans_df.groupby(\"cc_num\")\\\n",
    "    .apply(lambda x : haversine(x[\"longitude\"], x[\"latitude\"], -1))\\\n",
    "    .reset_index(level=0, drop=True)\\\n",
    "    .fillna(0)\n",
    "\n",
    "trans_df[\"time_delta_t_minus_1\"] = trans_df.groupby(\"cc_num\")\\\n",
    "    .apply(lambda x : time_delta(x[\"datetime\"],  -1))\\\n",
    "    .reset_index(level=0, drop=True)\n",
    "\n",
    "trans_df[\"time_delta_t_minus_1\"] = (trans_df.time_delta_t_minus_1 - trans_df.datetime )/ np.timedelta64(1, 'D')\n",
    "trans_df[\"time_delta_t_minus_1\"] = trans_df.time_delta_t_minus_1.fillna(0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7456ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df = trans_df[[\"tid\", \"datetime\", \"cc_num\", \"amount\", \"country\", \"fraud_label\",\n",
    "                     \"loc_delta_t_plus_1\", \"loc_delta_t_minus_1\", \"time_delta_t_minus_1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaf551d-6495-420f-a878-d4be39e38add",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df = trans_df.drop_duplicates(subset=['cc_num', 'datetime']) \\\n",
    "               .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b65c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7e126d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be723483",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üì° Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da57c80c",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> ü™Ñ Creating Feature Groups </span>\n",
    "\n",
    "A [feature group](https://docs.hopsworks.ai/3.0/concepts/fs/feature_group/fg_overview/) can be seen as a collection of conceptually related features. In this case, you will create a feature group for the transaction data and a feature group for the windowed aggregations on the transaction data. Both will have `cc_num` as primary key, which will allow you to join them when creating a dataset in the next tutorial.\n",
    "\n",
    "Feature groups can also be used to define a namespace for features. For instance, in a real-life setting you would likely want to experiment with different window lengths. In that case, you can create feature groups with identical schema for each window length. \n",
    "\n",
    "Before you can create a feature group you need to connect to Hopsworks feature store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce63afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ec5ccf-056d-48fb-baa2-0bc6e0cdf0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704da9d2",
   "metadata": {},
   "source": [
    "To create a feature group you need to give it a name and specify a primary key. It is also good to provide a description of the contents of the feature group and a version number, if it is not defined it will automatically be incremented to `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21eb1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_fg = fs.get_or_create_feature_group(\n",
    "    name=\"transactions_fraud_online_fg\",\n",
    "    version=1,\n",
    "    description=\"Transaction data\",\n",
    "    primary_key=['cc_num'],\n",
    "    event_time='datetime',\n",
    "    online_enabled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c339bd87",
   "metadata": {},
   "source": [
    "Here you have also set `online_enabled=True`, which enables low latency access to the data. A full list of arguments can be found in the [documentation](https://docs.hopsworks.ai/feature-store-api/latest/generated/api/feature_store_api/#create_feature_group).\n",
    "\n",
    "At this point, you have only specified some metadata for the feature group. It does not store any data or even have a schema defined for the data. To make the feature group persistent you need to populate it with its associated data using the `insert` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4955fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_fg.insert(trans_df, write_options={\"wait_for_job\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db676d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_descriptions = [\n",
    "    {\"name\": \"tid\", \"description\": \"Transaction id\"},\n",
    "    {\"name\": \"datetime\", \"description\": \"Transaction time\"},\n",
    "    {\"name\": \"cc_num\", \"description\": \"Number of the credit card performing the transaction\"},\n",
    "    {\"name\": \"amount\", \"description\": \"Dollar amount of the transaction\"},\n",
    "    {\"name\": \"country\", \"description\": \"Country in which the transaction was made\"},\n",
    "    {\"name\": \"fraud_label\", \"description\": \"Whether the transaction was fraudulent or not\"},\n",
    "    {\"name\": \"loc_delta_t_minus_1\", \"description\": \"Location of previous transaction\"},\n",
    "    {\"name\": \"time_delta_t_minus_1\", \"description\": \"Time of previous transaction\"},    \n",
    "]\n",
    "\n",
    "for desc in feature_descriptions: \n",
    "    trans_fg.update_feature_description(desc[\"name\"], desc[\"description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a616b7f",
   "metadata": {},
   "source": [
    "You can move on and do the same thing for the profile and label feature groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20af4024",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_fg = fs.get_or_create_feature_group(\n",
    "    name=\"profile_fraud_online_fg\",\n",
    "    version=1,\n",
    "    description=\"Credit card holder demographic data\",\n",
    "    primary_key=['cc_num'],\n",
    "    online_enabled=True\n",
    ")\n",
    "profile_fg.insert(profiles_df, write_options={\"wait_for_job\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed0619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_descriptions = [\n",
    "    {\"name\": \"cc_num\", \"description\": \"Number of the credit card performing the transaction\"},\n",
    "    {\"name\": \"gender\", \"description\": \"Gender of the credit card holder\"},\n",
    "]\n",
    "\n",
    "for desc in feature_descriptions: \n",
    "    profile_fg.update_feature_description(desc[\"name\"], desc[\"description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45a9e20",
   "metadata": {},
   "source": [
    "Click on the hyperlink printed in the cell output above to inspect your feature group in the UI.\n",
    "\n",
    "![fg-overview](../images/fg_overview.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58652612-f30e-4556-b415-53ab940380bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### <span style=\"color:#ff5f27;\"> üëì  Exploration</span>\n",
    "In the Hopsworks feature store, the metadata allows for multiple levels of explorations and review. Here you will explore a few of those capacities. \n",
    "\n",
    "### <span style=\"color:#ff5f27;\"> üîé Search</span>\n",
    "Using the search function in the UI, you can query any aspect of the feature groups, feature_view and training data that was previously created.\n",
    "\n",
    "### <span style=\"color:#ff5f27;\"> üìä Statistics</span>\n",
    "You can also enable statistics in one or all the feature groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2a980b-4e05-4fb1-ab25-da593a215d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_fg = fs.get_or_create_feature_group(\"transactions_fraud_online_fg\", version=1)\n",
    "trans_fg.statistics_config = {\n",
    "    \"enabled\": True,\n",
    "    \"histograms\": True,\n",
    "    \"correlations\": True\n",
    "}\n",
    "\n",
    "trans_fg.update_statistics_config()\n",
    "trans_fg.compute_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d777a4-02c4-443f-88d7-4822b2861faf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "![fg-statistics](../images/fg_statistics.gif)\n",
    "\n",
    "\n",
    "### ‚õìÔ∏è <b> Lineage </b> \n",
    "In all the feature groups and feature view you can look at the relation between each abstractions; what feature group created which training dataset and that is used in which model.\n",
    "This allows for a clear undestanding of the pipeline in relation to each element. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d232d6",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 02 Training Data & Feature views </span>\n",
    "\n",
    "In the following notebook you will use our feature groups to create a dataset you can train a model on.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/logicalclocks/hopsworks-tutorials/blob/master/fraud_online/2_training_dataset_and_modeling.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1ddeae6eefc765c17da80d38ea59b893ab18c0c0904077a035ef84cfe367f83"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
