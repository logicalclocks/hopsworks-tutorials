{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17f991f3",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"../../images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 03: Training Dataset and Modeling</span>\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/logicalclocks/hopsworks-tutorials/blob/master/advanced_tutorials/bitcoin/3_training_dataset_and_modeling.ipynb)\n",
    "\n",
    "<span style=\"font-width:bold; font-size: 1.4rem;\">This is the third part of advanced tutorials about Hopsworks Feature Store. This notebook explains how to read from a feature group, create training dataset within the feature store, train a model, register it in Hopsworks Model Registry and then use for batch predictions.</span>\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into the following sections: \n",
    "\n",
    "1. Fetch Feature Groups.\n",
    "2. Define Transformation functions.\n",
    "3. Create Feature Views.\n",
    "4. Create Training Dataset with training, validation and test splits.\n",
    "5. Train the model.\n",
    "6. Register model in Hopsworks model registry.\n",
    "7. Online model deployment.\n",
    "8. Use the deployment to make a prediciton.\n",
    "9. Retrieve batch data.\n",
    "10. Batch prediction using deployment.\n",
    "\n",
    "\n",
    "\n",
    "![part2](../../images/02_training-dataset.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb26879f",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üìù Imports</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce9346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "from functions import convert_unix_to_date\n",
    "\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "import inspect \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbfb4b9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d58833",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üì° Connecting to the Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a94824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea412aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_price_fg = fs.get_or_create_feature_group(\n",
    "    name='bitcoin_price',\n",
    "    version=1\n",
    ")\n",
    "\n",
    "# btc_price_fg.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fe1379",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_textblob_fg = fs.get_or_create_feature_group(\n",
    "    name='bitcoin_tweets_textblob',\n",
    "    version=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9377661",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_vader_fg = fs.get_or_create_feature_group(\n",
    "    name='bitcoin_tweets_vader',\n",
    "    version=1\n",
    ")\n",
    "\n",
    "# tweets_vader_fg.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1177d12e",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> üñç Feature View Creation and Retrieving </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2966e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Query Preparation\n",
    "query = btc_price_fg.select_except([\"date\"]) \\\n",
    "               .join(tweets_textblob_fg.select([\"subjectivity\",\"polarity\"])) \\\n",
    "               .join(tweets_vader_fg.select(\"compound\"))\n",
    "\n",
    "final_df = query.read()\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c11153-651f-4cc5-b876-71f41c3a9f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa931945",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_transform = final_df.columns\n",
    "columns_to_transform = columns_to_transform.tolist()\n",
    "columns_to_transform.remove(\"unix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef0a265-3101-4a16-abd1-be5942f21264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the transformation functions.\n",
    "min_max_scaler = fs.get_transformation_function(name=\"min_max_scaler\")\n",
    "\n",
    "# Map features to transformation functions.\n",
    "transformation_functions = {col: min_max_scaler for col in columns_to_transform}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f368df",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name='bitcoin_feature_view',\n",
    "    version=1,\n",
    "    transformation_functions=transformation_functions,\n",
    "    query=query\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c29d8a4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è Training Dataset Creation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84394f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can combine different datetime formats.\n",
    "td_version, td_job = feature_view.create_train_test_split(\n",
    "    train_start=final_df.unix.min(),\n",
    "    train_end=int(np.percentile(final_df.unix, 80)), # get the date that represents 80th percentile\n",
    "    test_start=int(np.percentile(final_df.unix, 81)), # get the date that represents 81th percentile\n",
    "    test_end=final_df.unix.max(),\n",
    "    data_format = \"csv\",\n",
    "    coalesce = True,\n",
    "    write_options = {'wait_for_job': True},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09505c0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\">ü™ù Training Dataset Retrieval</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d274bbb7-6d9d-4960-a368-6a80e4075501",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = feature_view.get_train_test_split(\n",
    "    training_dataset_version=td_version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc385fe6-a333-4724-9ea0-f581a3cb203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26654b81-b599-4187-aa9e-955476e63ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490d3fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets remove redundant column \"unix\"\n",
    "X_train.drop(columns=[\"unix\"], inplace=True)\n",
    "X_test.drop(columns=[\"unix\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb27c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train[[\"close\"]]\n",
    "y_test = X_test[[\"close\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40620977",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\">ü§ñ Time series model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e922a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets define Tensorflow Dataset as we are going to train keras tensorflow model\n",
    "\n",
    "def windowed_dataset(dataset, target, window_size, batch_size):\n",
    "    ds = dataset.window(window_size, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda x: x.batch(window_size))\n",
    "    ds = ds.map(lambda window: tf.reshape(window[-1:], [-1, 33]))\n",
    "        \n",
    "    target_ds = target.window(window_size, shift=1, drop_remainder=True)\n",
    "    target_ds = target_ds.flat_map(lambda window: window.batch(window_size))\n",
    "    target_ds = target_ds.map(lambda window: window[-1:])\n",
    "    \n",
    "    ds = tf.data.Dataset.zip((ds, target_ds))\n",
    "    ds = ds.batch(batch_size,True)\n",
    "    ds = ds.prefetch(1)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18517f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices(tf.cast(X_train.values, tf.float32)) \n",
    "training_target = tf.data.Dataset.from_tensor_slices(y_train.values.flatten().tolist()) \n",
    "training_dataset = training_dataset.repeat(500)\n",
    "training_dataset = windowed_dataset(training_dataset, training_target, window_size=2, batch_size=16)\n",
    "training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3908b7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices(tf.cast(X_test.values, tf.float32))\n",
    "validation_target = tf.data.Dataset.from_tensor_slices(y_test.values.flatten().tolist()) \n",
    "training_dataset = training_dataset.repeat(500)\n",
    "test_dataset = windowed_dataset(test_dataset, validation_target, window_size=2, batch_size=16)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfcae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim):\n",
    "    inputs = tf.keras.layers.Input(shape=(input_dim[0],input_dim[1]))\n",
    "    x = tf.keras.layers.Conv1D(filters = 128, kernel_size=1, padding='same', kernel_initializer=\"uniform\")(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)    \n",
    "    x = tf.keras.layers.MaxPooling1D(pool_size=2, padding='same')(x)\n",
    "    x = tf.keras.layers.Conv1D(filters = input_dim[1], kernel_size= 1,padding='same',  kernel_initializer=\"uniform\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)    \n",
    "    x = tf.keras.layers.MaxPooling1D(pool_size=2, padding='same')(x)    \n",
    "\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(33, activation=\"relu\", kernel_initializer=\"uniform\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(1, activation=\"relu\", kernel_initializer=\"uniform\")(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    model.summary()\n",
    "    model.compile(loss='mse',optimizer='adam',metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01761fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model([1, X_train.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ef7d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "start = timer()\n",
    "history = model.fit(training_dataset,\n",
    "                    epochs=10,\n",
    "                    verbose=0,\n",
    "                    steps_per_epoch=500,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=1,                    \n",
    "                   )\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982d91c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e62a7f",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'>‚öñÔ∏è Model Validation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2f23c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = history_dict['mae']\n",
    "val_loss_values = history_dict['val_mae']\n",
    "\n",
    "loss_values50 = loss_values\n",
    "val_loss_values50 = val_loss_values\n",
    "epochs = range(1, len(loss_values50) + 1)\n",
    "plt.plot(epochs, loss_values50, 'b',color = 'blue', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values50, 'b',color='red', label='Validation loss')\n",
    "plt.rc('font', size = 18)\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.xticks(epochs)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15,7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c11499",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_scaled = model.predict(X_test.values.reshape(-1, 1, X_test.shape[1]))\n",
    "y_pred_scaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bba72de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect \n",
    "# Recall that you applied transformation functions, such as min max scaler and laber encoder. \n",
    "# Now you want to transform them back to human readable format.\n",
    "feature_view.init_serving(1)\n",
    "td_transformation_functions = feature_view._single_vector_server._transformation_functions\n",
    "\n",
    "y_pred = pd.DataFrame(y_pred_scaled, columns=[\"close\"])\n",
    "\n",
    "for feature_name in td_transformation_functions:\n",
    "    if feature_name == \"close\":\n",
    "        td_transformation_function = td_transformation_functions[feature_name]\n",
    "        sig, foobar_locals = inspect.signature(td_transformation_function.transformation_fn), locals()\n",
    "        param_dict = dict([(param.name, param.default) for param in sig.parameters.values() if param.default != inspect._empty])\n",
    "        if td_transformation_function.name == \"min_max_scaler\":\n",
    "            y_pred[feature_name] = y_pred[feature_name].map(lambda x: x*(param_dict[\"max_value\"]-param_dict[\"min_value\"])+param_dict[\"min_value\"])\n",
    "            y_test[feature_name] = y_test[feature_name].map(lambda x: x*(param_dict[\"max_value\"]-param_dict[\"min_value\"])+param_dict[\"min_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20c5432-19d5-4968-a102-328c600d3cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb54dc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['darkslategrey']\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "ax.plot(y_test, 'black')\n",
    "ax.plot(y_pred, 'orange')\n",
    "ax.set_ylabel('$price$')\n",
    "ax.set_xlabel('$time$')\n",
    "ax.grid(True)\n",
    "ax.legend([\"actual\", \"pred\"])\n",
    "\n",
    "\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabdebb9",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## <span style='color:#ff5f27'>üóÑ Model Registry</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ff88e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "# The 'bitcoin_price_model' directory will be saved to the model registry\n",
    "model_dir = \"bitcoin_price_model\"\n",
    "if os.path.isdir(model_dir) == False:\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "fig.savefig(model_dir + \"/chart.png\") \n",
    "\n",
    "print('Exporting trained model to: {}'.format(model_dir))\n",
    "    \n",
    "tf.saved_model.save(model, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d54efe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = project.get_model_registry()\n",
    "\n",
    "metrics={'loss': history_dict['val_mae'][0]} \n",
    "\n",
    "tf_model = mr.tensorflow.create_model(\n",
    "    name=\"bitcoin_price_model\", \n",
    "    metrics=metrics,\n",
    "    input_example=X_train.sample(), \n",
    "    description=\"Bitcoin daily price prediction model.\")\n",
    "\n",
    "tf_model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98bbb11",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\">üöÄ Model Deployment</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63894db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile btc_model_transformer.py\n",
    "\n",
    "import os\n",
    "import hsfs\n",
    "import numpy as np\n",
    "\n",
    "class Transformer(object):\n",
    "    \n",
    "    def __init__(self):        \n",
    "        # get feature store handle\n",
    "        fs_conn = hsfs.connection()\n",
    "        self.fs = fs_conn.get_feature_store()\n",
    "        \n",
    "        # get feature views\n",
    "        self.fv = self.fs.get_feature_view(\"bitcoin_feature_view\", 1)\n",
    "        \n",
    "        # initialise serving\n",
    "        self.fv.init_serving(1)\n",
    "\n",
    "    def flat2gen(self, alist):\n",
    "        for item in alist:\n",
    "            if isinstance(item, list):\n",
    "                for subitem in item: yield subitem\n",
    "            else:\n",
    "                yield item\n",
    "        \n",
    "    def preprocess(self, inputs):\n",
    "        feature_vector = self.fv.get_feature_vector({\"unix\": inputs[\"inputs\"]})\n",
    "        feature_vector = [*feature_vector[:9], *feature_vector[10:]]\n",
    "        return { \"inputs\" :  np.array(list(self.flat2gen(feature_vector))).reshape(-1, 1, len(feature_vector)).tolist() }\n",
    "\n",
    "    def postprocess(self, outputs):\n",
    "        return outputs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4df257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from hsml.transformer import Transformer\n",
    "dataset_api = project.get_dataset_api()\n",
    "\n",
    "uploaded_file_path = dataset_api.upload(\"btc_model_transformer.py\", \"Models\", overwrite=True)\n",
    "transformer_script_path = os.path.join(\"/Projects\", project.name, uploaded_file_path)\n",
    "transformer_script = Transformer(script_file=transformer_script_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611abd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can retrieve the model using code like this\n",
    "tf_model = mr.get_model(\"bitcoin_price_model\", version = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fd6742",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = tf_model.deploy(\n",
    "    name=\"btcmodeldeployment\",\n",
    "    serving_tool=\"KSERVE\",\n",
    "    transformer=transformer_script\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91570d5",
   "metadata": {},
   "source": [
    "The deployment has now been registered. Lets retrieve it from Hopsworks for demonstration purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cc82e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = project.get_model_serving()\n",
    "\n",
    "# get deployment object\n",
    "deployment = ms.get_deployment(\"btcmodeldeployment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c98b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Deployment: \" + deployment.name)\n",
    "deployment.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda5ca8e",
   "metadata": {},
   "source": [
    "To start it you need to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead8293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.start(await_running=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1477bb",
   "metadata": {},
   "source": [
    "For trouble shooting one can use get_logs method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de5eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13bbab5",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\">üîÆ Predicting</span>\n",
    "\n",
    "Using the deployment let's use the input example that we registered together with the model to query the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cf8c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08889a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For trouble shooting one you can use get_logs method.\n",
    "deployment.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe78327",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\"> ‚ú® Load Batch Data of last days</span>\n",
    "\n",
    "First, you will need to fetch the training dataset that you created in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf2a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view.init_batch_scoring(training_dataset_version=1)\n",
    "\n",
    "batch_data = feature_view.get_batch_data().drop('unix',axis=1)\n",
    "batch_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0748e0ef",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\">üöÄ Use the model to predict electricity prices</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1dafb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mr.get_model(\"bitcoin_price_model\", version=1)\n",
    "model_dir = model.download()\n",
    "\n",
    "loaded_model = tf.saved_model.load(model_dir)\n",
    "serving_function = loaded_model.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da030f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = serving_function(tf.constant(batch_data.values.reshape(-1, batch_data.shape[0], batch_data.shape[1]), tf.float32))['dense_1'].numpy()\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbcbcb9",
   "metadata": {},
   "source": [
    "Recall that you applied transformation functions, such as min max scaler and laber encoder. \n",
    "\n",
    "Now you want to transform them back to human readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fb3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view.init_serving(1)\n",
    "td_transformation_functions = feature_view._single_vector_server._transformation_functions\n",
    "\n",
    "pred_y = pd.DataFrame(predictions, columns=[\"close\"])\n",
    "\n",
    "for feature_name in td_transformation_functions:\n",
    "    if feature_name == \"close\":\n",
    "        td_transformation_function = td_transformation_functions[feature_name]\n",
    "        sig, foobar_locals = inspect.signature(td_transformation_function.transformation_fn), locals()\n",
    "        param_dict = dict([(param.name, param.default) for param in sig.parameters.values() if param.default != inspect._empty])\n",
    "        if td_transformation_function.name == \"min_max_scaler\":\n",
    "            pred_y[feature_name] = pred_y[feature_name].map(lambda x: x*(param_dict[\"maX_testue\"]-param_dict[\"min_value\"])+param_dict[\"min_value\"])\n",
    "            \n",
    "pred_y.head()        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf100f24",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <span style=\"color:#ff5f27;\">ü•≥ <b> Next Steps  </b> </span>\n",
    "Congratulations you've now completed the Bitcoin price prediction tutorial for Managed Hopsworks.\n",
    "\n",
    "Check out our other tutorials on ‚û° https://github.com/logicalclocks/hopsworks-tutorials\n",
    "\n",
    "Or documentation at ‚û° https://docs.hopsworks.ai"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
