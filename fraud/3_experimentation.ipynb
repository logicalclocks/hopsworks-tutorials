{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c2b55c5",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization with Maggy\n",
    "\n",
    "### **Note: currently this notebook needs to be run with a PySpark kernel to work properly!*\n",
    "\n",
    "In this notebook, we'll use the [Maggy](https://maggy.ai/master/) library from Hopsworks to run experiments with hyperparameter tuning. In particular we will:\n",
    "\n",
    "- Load a training dataset from the feature store.\n",
    "- Train models on the dataset using different hyperparameters.\n",
    "\n",
    "![tutorial-flow](images/maggy_hp.png)\n",
    "\n",
    "We will train our model using standard Python and Scikit-learn, although it could just as well be trained with other machine learning frameworks such as PySpark, TensorFlow, and PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8005bc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th></tr><tr><td>5</td><td>application_1653397815695_0015</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"/hopsworks-api/yarnui/https://hopsworks0.logicalclocks.com:8089/proxy/application_1653397815695_0015/\">Link</a></td><td><a target=\"_blank\" href=\"/hopsworks-api/yarnui/https://hopsworks0.logicalclocks.com:8044/node/containerlogs/container_1653397815695_0015_01_000001/fv_test__meb10000\">Link</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "Connected. Call `.close()` to terminate connection gracefully."
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "\n",
    "conn = hsfs.connection()\n",
    "fs = conn.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a0ef714",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.get_feature_view(\"transactions_view\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3865671",
   "metadata": {},
   "source": [
    "As we described in the previus notebook feature view contains information about associating a label feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "822190de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fraud_label']"
     ]
    }
   ],
   "source": [
    "feature_view.label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca061bd",
   "metadata": {},
   "source": [
    "### Load Training Data\n",
    "\n",
    "First, we'll need to fetch the training dataset that we created in the previous notebook. Since we're running this notebook in a PySpark Kernel we'll get Spark Dataframes, which we'll need to convert back to Pandas Dataframes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a81932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, td_df = feature_view.get_training_dataset_splits({'train': 80, 'validation': 20}, start_time=None, end_time=None, version = 1) #read_options = dict(delimiter=\",\", header=\"true\", inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28c420b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|fraud_label|category|              amount|  age_at_transaction|days_until_card_expires|           loc_delta|   trans_volume_mstd|   trans_volume_mavg|          trans_freq|      loc_delta_mavg|\n",
      "+-----------+--------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|          0|       0|                 0.0|0.010738427139679882|     0.8505302684170075| 0.02495461846742725|                 0.0|                 0.0|                 0.0|0.026887824635134464|\n",
      "|          0|       0|                 0.0| 0.04726333986338846|     0.9438083228159196|0.035718227936116044|                 0.0|                 0.0|                 0.0| 0.03848527879829653|\n",
      "|          0|       0|                 0.0| 0.06364627025859768|    0.13203780990994793|4.386304300642104...|                 0.0|                 0.0|                 0.0|4.726106351198057E-5|\n",
      "|          0|       0|                 0.0| 0.34052327285159345|    0.20848505075465618| 0.21190213302017483|                 0.0|                 0.0|                 0.0| 0.22831795244212458|\n",
      "|          0|       0|                 0.0|  0.9546559471559991|     0.8749147177997035| 0.18391138698262133|                 0.0|                 0.0|                 0.0|   0.198158794855857|\n",
      "|          0|       0|3.336858167844633E-7|  0.3639988999473287|     0.6644432458260995| 0.09309499878177417|3.336858167844633E-7|3.336858167844633E-7|3.336858167844633E-7| 0.10030696341519688|\n",
      "|          0|       0|3.336858167844633E-7| 0.37449447713231104|     0.4589207953531482|  0.2462215185832252|3.336858167844633E-7|3.336858167844633E-7|3.336858167844633E-7|  0.2652960221252724|\n",
      "|          0|       0|3.336858167844633E-7|  0.5738862239685815|    0.20509525821430938|0.023091671964264107| 0.13303386143562984| 0.13303386143562984| 0.13303386143562984|0.019678017419098096|\n",
      "|          0|       0|3.336858167844633E-7|  0.6124008855095087|    0.27880679104558176|  0.1666811160749806|5.505815976943645E-6|5.505815976943645E-6|5.505815976943645E-6|  0.1795745381501317|\n",
      "|          0|       0|3.336858167844633E-7|  0.8177932864116284|     0.3687573790828675| 0.11731515080234864|3.336858167844633E-7|3.336858167844633E-7|3.336858167844633E-7| 0.12640342331561746|\n",
      "|          0|       0|3.336858167844633E-7|  0.8352609965955536|     0.7357381554762336|  0.0435149639761897| 0.01052428381847358| 0.01052428381847358| 0.01052428381847358| 0.08642524466199204|\n",
      "|          0|       0|3.336858167844633E-7|  0.8501567210213514|     0.9480995862636478| 0.13463766018054532|3.336858167844633E-7|3.336858167844633E-7|3.336858167844633E-7|  0.1450678879721046|\n",
      "|          0|       0|6.673716335689265E-7| 0.03014879554914455|     0.4379646233369229| 0.20700430818892954|6.673716335689265E-7|6.673716335689265E-7|6.673716335689265E-7| 0.22304069864126963|\n",
      "|          0|       0|6.673716335689265E-7| 0.03170823593542415|     0.6915750426178242| 0.23910482366459831|7.633063058944598E-4|7.633063058944598E-4|7.633063058944598E-4| 0.17586230121737387|\n",
      "|          0|       0|6.673716335689265E-7|0.042524477534651293|     0.2018521479362567| 0.18277228752989902|6.673716335689265E-7|6.673716335689265E-7|6.673716335689265E-7|  0.1969314506523485|\n",
      "|          0|       0|6.673716335689265E-7| 0.07100721757385152|     0.7629769908276218|  0.1150871930526537|6.673716335694007E-7|6.673716335694007E-7|6.673716335694007E-7| 0.12400286819006044|\n",
      "|          0|       0|6.673716335689265E-7| 0.33260799033760413|    0.28464955948544335| 0.09178176806241485|6.673716335689265E-7|6.673716335689265E-7|6.673716335689265E-7| 0.09889199819207817|\n",
      "|          0|       0|6.673716335689265E-7|  0.3407196368466336|     0.1633081065982541| 0.20587654159722768|6.673716335689265E-7|6.673716335689265E-7|6.673716335689265E-7| 0.22182556524275174|\n",
      "|          0|       0|6.673716335689265E-7| 0.34381736619988196|     0.5099567153436616| 0.10339382289530943|6.673716335689265E-7|6.673716335689265E-7|6.673716335689265E-7| 0.11140362582557502|\n",
      "|          0|       0|6.673716335689265E-7| 0.38846191100876615|    0.10459860143520329| 0.16837649070820204|6.673716335689265E-7|6.673716335689265E-7|6.673716335689265E-7| 0.18142042767557737|\n",
      "+-----------+--------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "td_df[\"train\"].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "711dc35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- category: integer (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- age_at_transaction: double (nullable = true)\n",
      " |-- days_until_card_expires: double (nullable = true)\n",
      " |-- loc_delta: double (nullable = true)\n",
      " |-- trans_volume_mstd: double (nullable = true)\n",
      " |-- trans_volume_mavg: double (nullable = true)\n",
      " |-- trans_freq: double (nullable = true)\n",
      " |-- loc_delta_mavg: double (nullable = true)"
     ]
    }
   ],
   "source": [
    "td_df[\"train\"].printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3e3027f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fraud_label  category  amount  ...  trans_volume_mavg  trans_freq  loc_delta_mavg\n",
      "0            0         0     0.0  ...                0.0         0.0        0.026888\n",
      "1            0         0     0.0  ...                0.0         0.0        0.038485\n",
      "2            0         0     0.0  ...                0.0         0.0        0.000047\n",
      "3            0         0     0.0  ...                0.0         0.0        0.228318\n",
      "4            0         0     0.0  ...                0.0         0.0        0.198159\n",
      "\n",
      "[5 rows x 10 columns]"
     ]
    }
   ],
   "source": [
    "X_train = td_df[\"train\"].toPandas()\n",
    "X_val = td_df['validation'].toPandas()\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a615a",
   "metadata": {},
   "source": [
    "We will train a model to predict `fraud_label` given the rest of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a2dfd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = feature_view.label[0]\n",
    "\n",
    "y_train = X_train.pop(target)\n",
    "y_val = X_val.pop(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044937d8",
   "metadata": {},
   "source": [
    "Let's check the distribution of our target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba31a453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998476\n",
      "1    0.001524\n",
      "Name: fraud_label, dtype: float64"
     ]
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0363235",
   "metadata": {},
   "source": [
    "Notice that the distribution is extremely skewed, which is natural considering that fraudulent transactions make up a tiny part of all transactions. Thus we should somehow address the class imbalance. There are many approaches for this, such as weighting the loss function, over- or undersampling, creating synthetic data, or modifying the decision threshold. In this example, we'll use the simplest method which is to just supply a class weight parameter to our learning algorithm. The class weight will affect how much importance is attached to each class, which in our case means that higher importance will be placed on positive (fraudulent) samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2422b757",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization\n",
    "\n",
    "In the following example, we'll use a simple logistic regression model and do a hyperparameter search over class weights. Since our dataset is unbalanced we will evaluate each hyperparameter configuration using the *F1-score* rather than *accuracy*.\n",
    "\n",
    "First, we define a training function that will return an evaluation score given a hyperparameter configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56c1ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def training_function(pos_class_weight):\n",
    "    clf = LogisticRegression(class_weight={0: 1.0 - pos_class_weight, 1: pos_class_weight}, solver='liblinear')\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_val)\n",
    "    score = f1_score(y_val, preds)\n",
    "    return {'metric': score} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eae985",
   "metadata": {},
   "source": [
    "Note that this code assumes that the `X_train`, `y_train` etc variables already exist in the namespace.\n",
    "\n",
    "Let's test the code to see that it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56a4f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = training_function(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7951d22",
   "metadata": {},
   "source": [
    "Now let's see if we can find a value for `class_weight` that gives us a better score.\n",
    "\n",
    "To do this we'll define a search space, which represents the set of possible values we want to consider for our hyperparameters. We'll also need to define datatypes for the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc82292d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter added: pos_class_weight"
     ]
    }
   ],
   "source": [
    "from maggy import Searchspace\n",
    "\n",
    "sp = Searchspace(pos_class_weight=('DOUBLE', [0.1, 0.9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa284bb4",
   "metadata": {},
   "source": [
    "Next we'll define a configuration for our hyperparameter search. Some important parameters are:\n",
    "- `num_trials`: Number of models to train. You should set this based on how much time you are willing to spend. We'll just do five trials here to showcase the functionality.\n",
    "- `optimizer`: Strategy used to determine the next parameter value to try. We will just use grid search, but you can read about alternatives [here](https://maggy.ai/master/hpo/strategies/).\n",
    "- `direction`: Should be set to `max` if the output of `train_fn` should be maximized, otherwise `min`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2e182b",
   "metadata": {},
   "source": [
    "Now we can run the `lagom` method, which tries to find the best value. Lagom is a Swedish word that means \"just right\". The function is \"lagom\" in the way it uses your resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fc1071d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0330d0ab6ea447dc8a8c46962790be81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Maggy experiment', max=2.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Maggy Experiment: fraud_lr, application_1653397815695_0015, run 1\n",
      "\n",
      "------ RandomSearch Results ------ direction(max) \n",
      "BEST combination {\"pos_class_weight\": 0.1646589884655028} -- metric 0.0\n",
      "WORST combination {\"pos_class_weight\": 0.1646589884655028} -- metric 0.0\n",
      "AVERAGE metric -- 0.0\n",
      "EARLY STOPPED Trials -- 0\n",
      "Total job time 0 hours, 0 minutes, 37 seconds\n",
      "\n",
      "Finished Experiment\n"
     ]
    }
   ],
   "source": [
    "from maggy import experiment\n",
    "result = experiment.lagom(train_fn=training_function, \n",
    "                          searchspace=sp,\n",
    "                          optimizer='randomsearch', \n",
    "                          direction='max',\n",
    "                          num_trials=2,\n",
    "                          name='fraud_lr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01c137c",
   "metadata": {},
   "source": [
    "The function returns a dict with results from our experiment. Of special interest is of course the `best_config` dict, which contains the best hyperparameters found. Let's save this dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f2af3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_id': '841c28760f2c697d', 'best_val': 0.0, 'best_hp': {'pos_class_weight': 0.1646589884655028}, 'worst_id': '841c28760f2c697d', 'worst_val': 0.0, 'worst_hp': {'pos_class_weight': 0.1646589884655028}, 'avg': 0.0, 'metric_list': [0.0, 0.0], 'num_trials': 2, 'early_stopped': 0}"
     ]
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d1c0403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"best_params.pickle\", \"wb\") as f:\n",
    "    pickle.dump(result[\"best_hp\"], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a21497",
   "metadata": {},
   "source": [
    "You can also upload this file to your cluster using the *hopsworks* library. To do this you would run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbe38a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Resources/best_params.pickle\n",
      "Uploading: 100.000%|##########| 43/43 elapsed<00:00 remaining<00:00"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "hopsworks_conn = hopsworks.connection()\n",
    "project = hopsworks_conn.get_project()\n",
    "dataset_api = project.get_dataset_api()\n",
    "\n",
    "uploaded_file_path = dataset_api.upload(\"best_params.pickle\", \"Resources\")\n",
    "print(uploaded_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dbbe3d",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "In the next notebook, we'll look at how to register a model to the [Hopsworks Model Registry](https://docs.hopsworks.ai/machine-learning-api/latest), which enables us to version control our models and easily create APIs for them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}