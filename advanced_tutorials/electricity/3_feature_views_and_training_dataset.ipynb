{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07578271",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\">**Hopsworks Feature Store** </span> <span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 03: Training Data & Feature views</span>\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/logicalclocks/hopsworks-tutorials/blob/master/advanced_tutorials/eletricity/3_feature_views_and_training_dataset.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "**Note**: you may get an error when installing hopsworks on Colab, and it is safe to ignore it.\n",
    "\n",
    "This is the second part of the quick start series of tutorials about Hopsworks Feature Store. This notebook explains how to read from a feature group and create training dataset within the feature store\n",
    "\n",
    "## üóíÔ∏è In this notebook we will see how to create a training dataset from the feature groups:\n",
    "1. **Select the features** we want to train our model on,\n",
    "2. **How the features should be preprocessed,**\n",
    "3. **Create a dataset split** for training and validation data.\n",
    "\n",
    "![02_training-dataset](../../images/02_training-dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf4a7fa",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üì° Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d28042",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U hopsworks --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6fe84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0c75e0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f990065",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">ü™ù Data retrieving from Feature Groups</span>\n",
    "\n",
    "Let's start by selecting all the features you want to include for model training/inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c84be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature groups.\n",
    "meteorological_measurements_fg = fs.get_or_create_feature_group(\n",
    "    name = 'meteorological_measurements',\n",
    "    version = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9c31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_prices_fg = fs.get_or_create_feature_group(\n",
    "    name = 'electricity_prices',\n",
    "    version = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed73cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "swedish_holidays_fg = fs.get_or_create_feature_group(\n",
    "    name = 'swedish_holidays',\n",
    "    version = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c3e5f6",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üñç Feature View Creation and Retrieving </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e991e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for training data.\n",
    "fg_query = electricity_prices_fg.select_all()\\\n",
    "                        .join(\n",
    "                            meteorological_measurements_fg.select_except([\"timestamp\"])\n",
    "                        )\\\n",
    "                        .join(\n",
    "                            swedish_holidays_fg.select_all()\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb8c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this if you would like to view query results\n",
    "fg_query.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5869c48",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> ü§ñ Transformation Functions</span>\n",
    "\n",
    "Hopsworks Feature Store provides functionality to attach transformation functions to feature views and comes with built-in transformation functions such as `min_max_scaler`, `standard_scaler`, `robust_scaler` and `label_encoder`.\n",
    "\n",
    "You will preprocess our data using *min-max scaling* on numerical features and *label encoding* on categorical features. To do this you simply define a mapping between our features and transformation functions. This ensures that transformation functions such as *min-max scaling* are fitted only on the training data (and not the validation/test data), which ensures that there is no data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6198f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transformation functions.\n",
    "standard_scaler = fs.get_transformation_function(name = 'standard_scaler')\n",
    "label_encoder = fs.get_transformation_function(name = 'label_encoder')\n",
    "\n",
    "price_areas = [\"se1\", \"se2\", \"se3\", \"se4\"]\n",
    "\n",
    "#Map features to transformations.\n",
    "mapping_transformers = {}\n",
    "for area in price_areas:\n",
    "    mapping_transformers[f\"price_{area}\"] = standard_scaler\n",
    "    mapping_transformers[f\"mean_temp_per_day_{area}\"] = standard_scaler\n",
    "    mapping_transformers[f\"mean_wind_speed_{area}\"] = standard_scaler\n",
    "    mapping_transformers[f\"precipitaton_amount_{area}\"] = standard_scaler\n",
    "    mapping_transformers[f\"total_sunshine_time_{area}\"] = standard_scaler\n",
    "    mapping_transformers[f\"mean_cloud_perc_{area}\"] = standard_scaler    \n",
    "    mapping_transformers[f\"precipitaton_type_{area}\"] = label_encoder\n",
    "\n",
    "mapping_transformers[\"type_of_day\"] = label_encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda7d172",
   "metadata": {},
   "source": [
    "`Feature Views` stands between **Feature Groups** and **Training Dataset**. –°ombining **Feature Groups** we can create **Feature Views** which store a metadata of our data. Having **Feature Views** we can create **Training Dataset**.\n",
    "\n",
    "The Feature Views allows schema in form of a query with filters, define a model target feature/label and additional transformation functions.\n",
    "\n",
    "In order to create Feature View we can use `FeatureStore.create_feature_view()` method.\n",
    "\n",
    "We can specify next parameters:\n",
    "\n",
    "- `name` - name of a feature group.\n",
    "\n",
    "- `version` - version of a feature group.\n",
    "\n",
    "- `labels`- our target variable.\n",
    "\n",
    "- `transformation_functions` - functions to transform our features.\n",
    "\n",
    "- `query` - query object with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd75ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.create_feature_view(\n",
    "    name = 'electricity_feature_view',\n",
    "    version = 1,\n",
    "    transformation_functions = mapping_transformers,\n",
    "    query = fg_query\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59705f29",
   "metadata": {},
   "source": [
    "For now `Feature View` is saved in Hopsworks and we can retrieve it using `FeatureStore.get_feature_view()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1b2a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.get_feature_view(\n",
    "    name = 'electricity_feature_view',\n",
    "    version = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dc6f5d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è Training Dataset Creation</span>\n",
    "\n",
    "In Hopsworks training data is a query where the projection (set of features) is determined by the parent FeatureView with an optional snapshot on disk of the data returned by the query.\n",
    "\n",
    "**Training Dataset  may contain splits such as:** \n",
    "* Training set - the subset of training data used to train a model.\n",
    "* Validation set - the subset of training data used to evaluate hparams when training a model\n",
    "* Test set - the holdout subset of training data used to evaluate a mode\n",
    "\n",
    "To create training dataset we use `FeatureView.create_training_data()` method.\n",
    "\n",
    "Here are some importand things:\n",
    "\n",
    "- It will inherit the name of FeatureView.\n",
    "\n",
    "- The feature store currently supports the following data formats for\n",
    "training datasets: **tfrecord, csv, tsv, parquet, avro, orc**.\n",
    "\n",
    "- We can choose necessary format using **data_format** parameter.\n",
    "\n",
    "- **start_time** and **end_time** in order to filter dataset in specific time range.\n",
    "\n",
    "- We can create **train, test** splits using `create_train_test_split()`. \n",
    "\n",
    "- We can create **train,validation, test** splits using `create_train_validation_test_splits()` methods.\n",
    "\n",
    "- The only thing is that we should specify desired ratio of splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9d987a",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> ‚õ≥Ô∏è Dataset with train, test and validation splits</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa89bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training datasets based event time filter\n",
    "td_jan2021_feb2022_version, td_job = feature_view.create_training_data(\n",
    "        start_time=\"20210101\",\n",
    "        end_time=\"20220228\",    \n",
    "        description='Electricity price prediction training dataset jan2021/feb2022',\n",
    "        data_format=\"csv\",\n",
    "        coalesce=True,\n",
    "        write_options={'wait_for_job': False},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72fc15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training datasets based event time filter\n",
    "td_spring2022, td_job = feature_view.create_training_data(\n",
    "    start_time=\"20220301\",\n",
    "    end_time=\"20220531\",    \n",
    "    description='Electricity price prediction training dataset March/May 2022',\n",
    "    data_format=\"csv\",\n",
    "    coalesce=True,\n",
    "    write_options={'wait_for_job': False},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd376a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training datasets based event time filter\n",
    "td_summer2022, td_job = feature_view.create_training_data(\n",
    "    start_time=\"20220601\",\n",
    "    end_time=\"20220909\",    \n",
    "    description='Electricity price prediction training dataset June/August 2022',\n",
    "    data_format=\"csv\",\n",
    "    coalesce=True,\n",
    "    write_options={'wait_for_job': True},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248aeb38",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b95674",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 04 </span>\n",
    "\n",
    "In the next notebook you will train a model on the Training dataset, that was created in this notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
