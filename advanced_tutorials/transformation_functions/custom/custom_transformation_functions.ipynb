{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c382383",
   "metadata": {},
   "source": [
    "# <span style=\"color:#ff5f27\"> üë®üèª‚Äçüè´ Custom Transformation Functions Registration</span>\n",
    "\n",
    "In this tutorial you will learn how to **write custom transformation functions for feature view** and **register Keras model** using Hopsworks Model Registry, and use retrieved model in **training and inference pipelines**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3994e496",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üóÑÔ∏è Table of Contents</span>\n",
    "- [üìù Imports](#1)\n",
    "- [‚õ≥Ô∏è Feature Pipeline](#t1)\n",
    "    - [üíΩ Loading Data](#2)\n",
    "    - [üîÆ Connecting to Hopsworks Feature Store](#3)\n",
    "    - [ü™Ñ Creating Feature Groups](#4)\n",
    "- [‚õ≥Ô∏è Training Pipeline](#t2)\n",
    "    - [üë©üèª‚Äçüî¨ Custom Transformation Functions](#12)\n",
    "    - [‚úçüèª Registering Custom Transformation Functions in Hopsworks](#5)\n",
    "    - [üñç Feature View Creation](#6)\n",
    "    - [üß¨ Modeling](#7)\n",
    "    - [üíæ Saving the Model in the Model Registry](#8)\n",
    "- [‚õ≥Ô∏è Inference Pipeline](#t3)\n",
    "    - [üìÆ Retrieving the Model from the Model Registry](#9)\n",
    "    - [üë®üèª‚Äç‚öñÔ∏è Batch Prediction](#10)\n",
    "    - [üë®üèª‚Äç‚öñÔ∏è Real-time Predictions](#11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8743b40",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## <span style='color:#ff5f27'> üìù Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e0c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd        # For data manipulation and analysis using DataFrames\n",
    "import numpy as np         # For numerical computations and arrays\n",
    "import os                  # For operating system-related functions\n",
    "import joblib              # For saving and loading model files\n",
    "\n",
    "import xgboost as xgb      # For using the XGBoost machine learning library\n",
    "from sklearn.metrics import accuracy_score  # For evaluating model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a7e1a",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='t1'></a>\n",
    "# <span style=\"color:#ff5f27;\">‚õ≥Ô∏è Feature Pipeline </span>\n",
    "\n",
    "In this section you will load data, create a Hopsworks feature group and insert your dataset into created feature group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626ca429",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## <span style=\"color:#ff5f27;\"> üíΩ Loading Data </span>\n",
    "\n",
    "To begin with, let's load a dataset which contains air quality measurements for different  cities from 2013-01-01 to 2023-04-11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7aaf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_original = pd.read_csv(\"https://repo.hops.works/dev/davit/air_quality/backfill_pm2_5_eu.csv\")\n",
    "df_original.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd04249",
   "metadata": {},
   "source": [
    "Now let's add a target variable to the DataFrame. For simplicity and for demonstration purposes you will randomly assign either a 0 or a 1 to each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e9dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a binary target column\n",
    "df_original['target'] = np.random.choice([0, 1], size=len(df_original))\n",
    "df_original.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd983ab",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## <span style=\"color:#ff5f27;\"> üîÆ Connecting to Hopsworks Feature Store </span>\n",
    "\n",
    "The next step is to login to the Hopsworks platform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f77b7b",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## <span style=\"color:#ff5f27;\">ü™Ñ Creating Feature Groups</span>\n",
    "\n",
    "Now you need to create a Feature Group and insert your dataset.\n",
    "\n",
    "You will use `.get_or_create_feature_group()` method of the feature store object.\n",
    "\n",
    "You can read about **Feature Groups** [here](https://docs.hopsworks.ai/3.2/concepts/fs/feature_group/fg_overview/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3a1093",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group = fs.get_or_create_feature_group(\n",
    "    name='feature_group_online',\n",
    "    description='Online Feature Group',\n",
    "    version=1,\n",
    "    primary_key=['city_name', 'date'],\n",
    "    online_enabled=True,\n",
    ")    \n",
    "feature_group.insert(df_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d4d483",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='t2'></a>\n",
    "# <span style=\"color:#ff5f27;\">‚õ≥Ô∏è Training Pipeline </span>\n",
    "\n",
    "In the **Training Pipeline** you will register custom transformation functions in the Hopsworks Feature Store, apply custom transformation functions to specific columns in the feature view, create a train-test split and train the XGBClassifier. Then you will register your trained model in the Hopsworks Model Registry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38330c2",
   "metadata": {},
   "source": [
    "<a name='12'></a>\n",
    "## <span style=\"color:#ff5f27;\">üë©üèª‚Äçüî¨ Custom Transformation Functions</span>\n",
    "\n",
    "In the `transformations.py` file you can find the custom `encode_city_name` and `scale_pm2_5` transformation functions which will be registered in the Hopsworks Feature Store and then attached to feature view during feature view creation for further data transformation.\n",
    "\n",
    "Let's import them and see how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694da24d",
   "metadata": {},
   "source": [
    "If you are running on Hopsworks, custom transformation functions need to be registered in the feature store to make them accessible for feature view creation. To register them in the feature store, they either have to be part of the library installed in Hopsworks or attached when starting a Jupyter notebook or Hopsworks job.\n",
    "\n",
    "Uncomment the next cell to install `transformations` file with custom transformation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d460963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/logicalclocks/hopsworks-tutorials/master/advanced_tutorials/transformation_functions/custom/transformations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b67080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformations import encode_city_name, scale_pm2_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd50770",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_name = 'Madrid'\n",
    "encoded_city_name = encode_city_name(city_name)\n",
    "print(\"‚õ≥Ô∏è Encoded City Name:\", encoded_city_name)  # Output: Encoded City Name: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efc5c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm2_5_value = 13.0\n",
    "scaled_pm2_5 = scale_pm2_5(pm2_5_value)\n",
    "print(\"‚õ≥Ô∏è Scaled PM2.5 Value:\", scaled_pm2_5)  # Output: Scaled PM2.5 Value: 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b79ff3",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## <span style=\"color:#ff5f27;\"> ‚úçüèª Registering Custom Transformation Functions in Hopsworks</span>\n",
    "\n",
    "The next step is to **register custom transformation functions** in Hopsworks Feature Store.\n",
    "\n",
    "You can check existing transformation functions in feature store using the `.get_transformation_functions()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e9ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check existing transformation functions\n",
    "fns = [fn.name for fn in fs.get_transformation_functions()]\n",
    "fns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3c9e22",
   "metadata": {},
   "source": [
    "You can register your transformation function using the `.create_transformation_function()` method with the next parameters:\n",
    "\n",
    "- `transformation_function` - your custom transformation function.\n",
    "\n",
    "- `output_type` - python or numpy output type that will be inferred as pyspark.sql.types type.\n",
    "\n",
    "- `version` - version of your custom transformation function.\n",
    "\n",
    "Then don't forget to use the `.save()` method in order to persist transformation function in backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875367b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register encode_city_name in Hopsworks\n",
    "if \"encode_city_name\" not in fns:\n",
    "    encoder = fs.create_transformation_function(\n",
    "        encode_city_name, \n",
    "        output_type=int,\n",
    "        version=1,\n",
    "    )\n",
    "    encoder.save()\n",
    "    \n",
    "# Register scale_pm2_5 in Hopsworks\n",
    "if \"scale_pm2_5\" not in fns:\n",
    "    scaler = fs.create_transformation_function(\n",
    "        scale_pm2_5, \n",
    "        output_type=float,\n",
    "        version=1,\n",
    "    )\n",
    "    scaler.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4242b9e",
   "metadata": {},
   "source": [
    "Now let's check if your custom transformation functions are present in the feature store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a3b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check it your transformation functions are present in the feature store\n",
    "fns = [fn.name for fn in fs.get_transformation_functions()]\n",
    "fns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6e3352",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "## <span style=\"color:#ff5f27;\"> üñç Feature View Creation</span>\n",
    "\n",
    "In this part you will retrieve your custom transformation functions from the feature store, build a Query object and create a feature view.\n",
    "\n",
    "To retrieve your custom transformation function you need to use the `.get_transformation_function()` method by specifying the **name** and **version** of required transformation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dd6ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve encode_city_name transformation function\n",
    "encoder = fs.get_transformation_function(\n",
    "    name=\"encode_city_name\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "# Retrieve scale_pm2_5 transformation function\n",
    "scaler = fs.get_transformation_function(\n",
    "    name=\"scale_pm2_5\",\n",
    "    version=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95df4a6f",
   "metadata": {},
   "source": [
    "In Hopsworks Feature Store, a Query object allows you to select specific features from a feature group.\n",
    "\n",
    "`feature_group.select_except(['date'])` selects all columns from the feature group except for the 'date' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f4dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Query object\n",
    "query = feature_group.select_except(['date'])\n",
    "query.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df294d0e",
   "metadata": {},
   "source": [
    "After creating the Query object, you will create a feature view.\n",
    "\n",
    "A feature view is a logical representation of data which can be used for real-time serving or batch processing. \n",
    "\n",
    "You can read more about **Feature Views** [here](https://docs.hopsworks.ai/3.2/concepts/fs/feature_view/fv_overview/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1791335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create a feature view\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name='serving_fv',\n",
    "    version=1,\n",
    "    query=query,\n",
    "    # Apply your custom transformation functions to necessary columns\n",
    "    transformation_functions={\n",
    "        \"city_name\": encoder,\n",
    "        \"pm2_5\": scaler,\n",
    "    },\n",
    "    labels=['target'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f554ced8",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è Training Dataset Creation</span>\n",
    "The next step is to create the train-test split of your data.\n",
    "\n",
    "Let's clarify the next parameters of the `.create_train_test_split()` method:\n",
    "\n",
    "- test_size=0.1: This parameter specifies the size of the test set relative to the entire dataset. In this case, the test set will contain 10% of the data, and the train set will have the remaining 90%.\n",
    "\n",
    "- description='Description of the dataset': A brief description provided for the train-test split dataset, explaining its purpose or any other relevant information.\n",
    "\n",
    "- data_format='csv': This parameter specifies the format in which the train-test split dataset will be stored. Here, it is set to 'csv', meaning the dataset will be saved in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb20081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train-test split dataset\n",
    "td_version, job = feature_view.create_train_test_split(\n",
    "    test_size=0.1,\n",
    "    description='Description of the dataset',\n",
    "    data_format='csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1502740c",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">ü™ù Training Dataset Retrieval</span>\n",
    "\n",
    "To retrieve your train_test_split you can use the `.get_train_test_split()` method of the feature_view object.\n",
    "\n",
    "The parameter `training_dataset_version` specifies the version number of the train-test split dataset to retrieve. \n",
    "\n",
    "`td_version` is the version number that was obtained when the train-test split dataset was created in a previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a938b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the train-test split\n",
    "X_train, X_test, y_train, y_test = feature_view.get_train_test_split(\n",
    "    training_dataset_version=td_version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a830bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8342245",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09cf48d",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "## <span style=\"color:#ff5f27;\">üß¨ Modeling</span>\n",
    "\n",
    "As a machine learning algorithm you will use the XGBClassifier.\n",
    "\n",
    "Let's initialize it, fit on train data and then evaluate using Accuracy Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5019a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize XGBClassifier\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Fit the classifier\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"üëÆüèª‚Äç‚ôÇÔ∏è Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bedc3e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üóÑ Model Registry</span>\n",
    "\n",
    "In Hopsworks, the Model Registry is a crucial component used to manage and version machine learning models. It acts as a centralized repository where trained models can be stored, tracked, and shared among team members.\n",
    "\n",
    "By calling `project.get_model_registry()`, the code retrieves a reference to the Model Registry associated with the current Hopsworks project. This reference allows the user to interact with the Model Registry and perform operations such as registering, versioning, and accessing trained machine learning models.\n",
    "With the Model Registry, data scientists and machine learning engineers can effectively collaborate, track model changes, and easily deploy the best-performing models to production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a73fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbde875",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">‚öôÔ∏è Model Schema</span>\n",
    "\n",
    "The next step is to **define input and output schema** of a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c52621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "input_schema = Schema(X_train.values)\n",
    "output_schema = Schema(y_train)\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)\n",
    "\n",
    "model_schema.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f6cb84",
   "metadata": {},
   "source": [
    "<a name='8'></a>\n",
    "### <span style=\"color:#ff5f27;\">üíæ Saving the Model</span>\n",
    "\n",
    "Now you are ready to register your model in the Hopsworks Moder Registry.\n",
    "\n",
    "To begin with, let's create the `xgb_model` model directory and save the trained model in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a18cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"xgb_model\"\n",
    "\n",
    "if os.path.isdir(model_dir) == False:\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(xgb_classifier, model_dir + '/xgb_classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c4dd90",
   "metadata": {},
   "source": [
    "To register your model in the Hopsworks model registry you can use `.create_model()` method with the next parameters:\n",
    "\n",
    "- name=\"xgb_model\": The name of the model.\n",
    "\n",
    "- metrics={\"Accuracy\": accuracy}: The model's performance metrics are specified as a dictionary, with \"Accuracy\" as the key and the value being the accuracy score computed earlier in the code. This metric represents the accuracy of the model's predictions on the test data.\n",
    "\n",
    "- description=\"XGB model\": A brief description of the model.\n",
    "\n",
    "- input_example=X_train.sample(): An example input from the training data (X_train) is used to demonstrate the expected format of the model's input data. It is randomly sampled from X_train.\n",
    "\n",
    "- model_schema=model_schema: The model schema, which represents the data input and output structure of the model, is specified using the previously defined model_schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7415dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model in the model registry\n",
    "model = mr.python.create_model(\n",
    "    name=\"xgb_model\",\n",
    "    metrics={\"Accuracy\": accuracy}, \n",
    "    description=\"XGB model\",\n",
    "    input_example=X_train.sample(),\n",
    "    model_schema=model_schema\n",
    ")\n",
    "\n",
    "model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fcad3c",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='t3'></a>\n",
    "# <span style=\"color:#ff5f27;\">‚õ≥Ô∏è Inference Pipeline </span>\n",
    "\n",
    "In the **Inference Pipeline** section, you will retrieve your model from Hopsworks Model Registry and utilize this model to make predictions on both Batch Data and Online Feature Vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4e238f",
   "metadata": {},
   "source": [
    "<a name='9'></a>\n",
    "## <span style=\"color:#ff5f27;\"> üìÆ Retrieving the Model from Model Registry </span>\n",
    "\n",
    "To retrieve a previously registered machine learning model from the Hopsworks Model Registry you need to use the `.get_model()` method with the next parameters:\n",
    "\n",
    "- name=\"xgb_model\": The name of the model to be retrieved.\n",
    "\n",
    "- version=1: The version number of the model to be retrieved.\n",
    "\n",
    "Then you will download the model from the Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b287444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve your model from the model registry\n",
    "retrieved_model = mr.get_model(\n",
    "    name=\"xgb_model\",\n",
    "    version=1\n",
    ")\n",
    "saved_model_dir = retrieved_model.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9854b853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the XGB model\n",
    "retrieved_xgboost_model = joblib.load(saved_model_dir + \"/xgb_classifier.pkl\")\n",
    "retrieved_xgboost_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e2e23e",
   "metadata": {},
   "source": [
    "<a name='10'></a>\n",
    "## <span style=\"color:#ff5f27;\"> üë®üèª‚Äç‚öñÔ∏è Batch Prediction </span>\n",
    "\n",
    "Batch prediction is a process in which a trained machine learning model is used to make predictions on a large set of data all at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fbe4ff",
   "metadata": {},
   "source": [
    "To retrieve batch data from the feature view you need to use `init_batch_scoring` method of the feature view object.\n",
    "\n",
    "`training_dataset_version` parameter specifies the version number of the training dataset that will be used for scoring.\n",
    "\n",
    "Then you can use the `.get_batch_data()` method to retrieve batch data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94123860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise feature view to retrieve batch data\n",
    "feature_view.init_batch_scoring(training_dataset_version=td_version)\n",
    "\n",
    "# Retrieve batch data\n",
    "batch_data = feature_view.get_batch_data()\n",
    "batch_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed400e3c",
   "metadata": {},
   "source": [
    "Now let's use retrieved model to predict batch data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b96bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict batch data using retrieved model\n",
    "predictions_batch = retrieved_xgboost_model.predict(batch_data)\n",
    "predictions_batch[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf4631d",
   "metadata": {},
   "source": [
    "<a name='11'></a>\n",
    "## <span style=\"color:#ff5f27;\"> üë®üèª‚Äç‚öñÔ∏è Real-time Predictions</span>\n",
    "\n",
    "**Real-time Predictions** is a process of using a trained machine learning model to make predictions on feature vector(s) in real-time. \n",
    "\n",
    "To begin with, let's create `to_df` function which will transform a feature vector(s) list into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2317eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(feature_vector):\n",
    "    \"\"\"\n",
    "    Convert a feature vector or a list of feature vectors into a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        feature_vector (a list, or list of lists): \n",
    "            A feature vector or a list of feature vectors. A feature vector is \n",
    "            represented as a list containing two elements: the first \n",
    "            element corresponds to the city name (categorical feature), and the \n",
    "            second element corresponds to the PM2.5 value (numerical feature).\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame representing the feature vector(s). \n",
    "        The DataFrame will have two columns: 'city_name' for the city names \n",
    "        and 'pm2_5' for the corresponding PM2.5 values.\n",
    "\n",
    "    Example:\n",
    "        >>> feature_vector = ['New York', 15.3]\n",
    "        >>> to_df(feature_vector)\n",
    "           city_name  pm2_5\n",
    "        0  New York   15.3\n",
    "\n",
    "        >>> multiple_vectors = [['New York', 15.3], ['Los Angeles', 10.7]]\n",
    "        >>> to_df(multiple_vectors)\n",
    "          city_name  pm2_5\n",
    "        0  New York   15.3\n",
    "        1  Los Angeles 10.7\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the input is a list of feature vectors\n",
    "    if isinstance(feature_vector[0], list): \n",
    "        # Separate the city names and PM2.5 values into separate lists\n",
    "        city_names = [vector[0] for vector in feature_vector]\n",
    "        pm2_5_values = [vector[1] for vector in feature_vector]\n",
    "        \n",
    "        # Create a DataFrame with 'city_name' and 'pm2_5' columns from the lists\n",
    "        data = pd.DataFrame(\n",
    "            {\n",
    "                'city_name': city_names,\n",
    "                'pm2_5': pm2_5_values,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Return the DataFrame representing multiple feature vectors\n",
    "        return data\n",
    "\n",
    "    # If only one feature vector is provided, create a DataFrame for it\n",
    "    data = pd.DataFrame(\n",
    "            {\n",
    "                'city_name': [feature_vector[0]],\n",
    "                'pm2_5': [feature_vector[1]],\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    # Return the DataFrame representing a single feature vector\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1686bcff",
   "metadata": {},
   "source": [
    "The next step is to initialize the feature view for serving and then retrieve a feature vector with specified primary keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdb19e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise feature view to retrieve feature vector\n",
    "feature_view.init_serving(1)\n",
    "\n",
    "# Retrieve a feature vector\n",
    "feature_vector = feature_view.get_feature_vector(\n",
    "    entry = {\n",
    "        \"city_name\": 'Amsterdam',\n",
    "        \"date\": '2013-01-01',\n",
    "    }\n",
    ")\n",
    "feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63b32bf",
   "metadata": {},
   "source": [
    "Let's apply `to_df` function in order to transform the feature vector into pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac308069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform feature vector to pandas dataframe\n",
    "feature_vector_df = to_df(feature_vector)\n",
    "feature_vector_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e581a8e",
   "metadata": {},
   "source": [
    "Now you can use your model to predict the feature vector dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dfdbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict feature vector dataframe using retrieved model\n",
    "prediction_feature_vector = retrieved_xgboost_model.predict(feature_vector_df)\n",
    "prediction_feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e82837",
   "metadata": {},
   "source": [
    "In addition, you can retrieve several feature vectors. Just pass primary keys as a list of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac541e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature vectors from feature store\n",
    "feature_vectors = feature_view.get_feature_vectors(\n",
    "    entry = [\n",
    "        {\"city_name\": 'Amsterdam', \"date\": '2013-01-01'},\n",
    "        {\"city_name\": 'Amsterdam', \"date\": '2014-01-01'},\n",
    "    ]\n",
    ")\n",
    "feature_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9c135e",
   "metadata": {},
   "source": [
    "Apply `to_df` function in order to transform feature vectors into pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert feature vectors to pandas dataframe\n",
    "feature_vectors_df = to_df(feature_vectors)\n",
    "feature_vectors_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a5d21a",
   "metadata": {},
   "source": [
    "Now you can use your model to predict the dataframe which contains feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee7ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict dataframe of feature vectors using retrieved model\n",
    "prediction_feature_vectors = retrieved_xgboost_model.predict(feature_vectors_df)\n",
    "prediction_feature_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1149b1",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
