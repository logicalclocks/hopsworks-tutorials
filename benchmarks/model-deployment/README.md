# Benchmarking a Deployment on Hopsworks

This repository benchmarks a deployment running inside **Hopsworks** using [Locust](https://locust.io/).

## Benchmarking Steps

1. **Create a Deployment**
   - Run all the provided notebooks to set up your deployment inside Hopsworks.

2. **Configure Target Host**
   - Add the **host name** and **IP address** of your deployment in [`locustfile.py`](https://github.com/manu-sj/benchmark-deployments/blob/async-predict/locust/locustfile.py#L12).
   - You can find this information in the Hopsworks **Deployment UI**.

3. **Add Hopsworks API Key**
   - Insert your Hopsworks API key into the same [`locustfile.py`](https://github.com/manu-sj/benchmark-deployments/blob/async-predict/locust/locustfile.py#L12).
   - Generate the API key by following [this guide](https://docs.hopsworks.ai/latest/user_guides/projects/api_key/create_api_key/).

4. **Build the Locust Docker Image**
   - Use the provided [Dockerfile](https://github.com/manu-sj/benchmark-deployments/blob/async-predict/locust/Dockerfile) to build a Locust image.
   - Push the image to your preferred container registry.

5. **Update Kubernetes Manifests**
   - Update the image URL in both:
     - [`master-deployment.yaml`](https://github.com/manu-sj/benchmark-deployments/blob/async-predict/locust/kubernetes-locust/master-deployment.yaml#L28)
     - [`slave-deployment.yaml`](https://github.com/manu-sj/benchmark-deployments/blob/async-predict/locust/kubernetes-locust/slave-deployment.yaml#L28)

6. **Deploy Locust**
   - Run the [deployment script](https://github.com/manu-sj/benchmark-deployments/blob/async-predict/locust/kubernetes-locust/deploy.sh) to deploy Locust master and worker nodes.
   - This will deploy into a Kubernetes namespace named `locust`.
   - **Note:** Ensure you have `kubectl` access to the cluster.

7. **Access Locust UI**
   - Once deployed, port-forward port `8089` from the `locust-master` service to your local machine.
   - Access the Locust Web UI at [http://localhost:8089](http://localhost:8089) to run and monitor your load tests.


## Benchmarks

One benchmark that has been performed targets **5000 RPS** with a **P99 latency below 50 ms**. This performance level can be achieved on Hopsworks 4.1 using the following configuration:

1. **RonDB REST Servers [(RDRS)](https://docs.rondb.com/rondb_rest_api/)**  
   - Replicas: 2  
   - CPU Limits: 4  
   - CPU Requests: 4

2. **Istio Ingress Gateways**  
   - Replicas: 3  
   - CPU Limits: 4  
   - CPU Requests: 4

3. **Predictors**  
   - Replicas: 30  
   - CPU Limits: 1  
   - CPU Requests: 1

The high number of replicas for predictors is necessary to mitigate the effects of Python's [Global Interpreter Lock (GIL)](https://wiki.python.org/moin/GlobalInterpreterLock). This allows for greater parallelism and lower latency, especially at high RPS.

You can view the full benchmark report generated by Locust [here](https://github.com/manu-sj/benchmark-deployments/blob/async-predict/locust_reports/locust_report_5k_rps_25_batch_size.pdf).
